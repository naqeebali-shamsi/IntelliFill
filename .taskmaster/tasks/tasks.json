{
  "master": {
    "tasks": [
      {
        "id": "187",
        "title": "Implement JWT Secret Startup Validation",
        "description": "Add startup validation in backend config to check for JWT_SECRET and JWT_REFRESH_SECRET environment variables, fail hard if missing with clear error message and exit code 1 (REQ-004)",
        "details": "In quikadmin/src/config/index.ts, add validation function using process.env checks. Use crypto.randomBytes(64).toString('hex') as example in error message. Remove all hardcoded fallbacks from supabase-auth.routes.ts. Ensure cookie-parser@^1.4.6 is installed for cookie handling. Implementation:\n```typescript\nconst validateJWTSecrets = () => {\n  const required = ['JWT_SECRET', 'JWT_REFRESH_SECRET'];\n  for (const key of required) {\n    if (!process.env[key] || process.env[key].length < 64) {\n      console.error(`FATAL: ${key} not set or too short. Set ${key}=<64+ char random string like ${crypto.randomBytes(64).toString('hex').slice(0,32)}...>`);\n      process.exit(1);\n    }\n  }\n};\nvalidateJWTSecrets();\n``` Call at app startup before routes. Update .env.example with both vars.",
        "testStrategy": "Unit test config validation: mock missing env vars → expect exit(1) and correct error message. Integration test: start server without env vars → verify crash with correct log. Test with valid 64+ char secrets → server starts successfully.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Add JWT secrets validation function to config",
            "description": "Create validateJWTSecrets function in quikadmin/src/config/index.ts that checks for JWT_SECRET and JWT_REFRESH_SECRET environment variables",
            "dependencies": [],
            "details": "Implement the provided code snippet using process.env checks and crypto.randomBytes(64).toString('hex') for error message example. Ensure function validates length >= 64 characters.",
            "status": "pending",
            "testStrategy": "Unit test: mock missing/invalid env vars → verify console.error called and process.exit(1) triggered",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Call validation function at app startup",
            "description": "Invoke validateJWTSecrets() at the earliest point in app startup before any routes are registered",
            "dependencies": [1],
            "details": "Add validateJWTSecrets(); call in the main server startup sequence, ideally right after environment loading but before express app initialization and route mounting.",
            "status": "pending",
            "testStrategy": "Integration test: start server without env vars → verify immediate crash with exit code 1 and correct error message",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Remove hardcoded JWT fallbacks from routes",
            "description": "Eliminate all hardcoded JWT secret fallbacks from supabase-auth.routes.ts file",
            "dependencies": [1],
            "details": "Search for and remove any default/fallback JWT_SECRET or JWT_REFRESH_SECRET values in supabase-auth.routes.ts. Ensure the app now strictly requires environment variables.",
            "status": "pending",
            "testStrategy": "Code review: verify no hardcoded secrets remain. Test startup without env vars → confirm proper validation failure",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Install and configure cookie-parser dependency",
            "description": "Add cookie-parser@^1.4.6 to package.json and ensure it's properly imported for cookie handling",
            "dependencies": [],
            "details": "Run npm install cookie-parser@^1.4.6. Verify it's imported and initialized in the main express app with app.use(cookieParser()).",
            "status": "pending",
            "testStrategy": "Verify package.json includes correct version. Test cookie reading in auth routes → confirm req.cookies works correctly",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Update .env.example with required JWT variables",
            "description": "Add JWT_SECRET and JWT_REFRESH_SECRET entries to .env.example with generation instructions",
            "dependencies": [1],
            "details": "Include both variables in .env.example file with comments explaining they must be 64+ character random strings generated via crypto.randomBytes(64).toString('hex').",
            "status": "pending",
            "testStrategy": "Manual verification: check .env.example contains both vars with proper instructions and example generation command",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T11:23:18.134Z"
      },
      {
        "id": "188",
        "title": "Standardize localStorage Keys and Add Migration",
        "description": "Consolidate all localStorage keys to 'intellifill-backend-auth' and add one-time migration from old keys (REQ-002)",
        "details": "In stores/index.ts and migrationUtils.ts, standardize to single key. Add migration logic:\n```typescript\nconst migrateAuthStorage = () => {\n  const oldKeys = ['intellifill-auth', 'auth-storage'];\n  const newKey = 'intellifill-backend-auth';\n  for (const oldKey of oldKeys) {\n    if (localStorage.getItem(oldKey)) {\n      localStorage.setItem(newKey, localStorage.getItem(oldKey)!);\n      localStorage.removeItem(oldKey);\n    }\n  }\n  localStorage.removeItem('migration-complete');\n};\n// Call once on first app load\nif (!localStorage.getItem('migration-complete')) {\n  migrateAuthStorage();\n  localStorage.setItem('migration-complete', 'true');\n}\n``` Update all cleanup/export functions to use new key. Remove refreshToken from Zustand partialize.",
        "testStrategy": "Unit tests: simulate old keys → verify migration to new key and cleanup. E2E test: populate old keys → reload → verify data in new key only. Test idempotency: run migration twice → no data loss.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create migrationUtils.ts with migrateAuthStorage function",
            "description": "Implement the migration logic to copy data from old keys to new key and clean up old keys.",
            "dependencies": [],
            "details": "Create migrationUtils.ts file with the provided migrateAuthStorage function that handles oldKeys ['intellifill-auth', 'auth-storage'] to 'intellifill-backend-auth'. Include removal of 'migration-complete' flag. Ensure safe handling with null checks.",
            "status": "pending",
            "testStrategy": "Unit test: mock localStorage with old keys → verify data copied to new key and old keys removed.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Add one-time migration trigger in app initialization",
            "description": "Call migration logic once on first app load using migration-complete flag.",
            "dependencies": [1],
            "details": "In stores/index.ts or main app entry, add the check: if (!localStorage.getItem('migration-complete')) { migrateAuthStorage(); localStorage.setItem('migration-complete', 'true'); }. Place at earliest app initialization point.",
            "status": "pending",
            "testStrategy": "Unit test: simulate first load → verify migration runs once; second load → verify skipped.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Update stores/index.ts to use new localStorage key",
            "description": "Replace all instances of old localStorage keys with 'intellifill-backend-auth' in stores/index.ts.",
            "dependencies": [1],
            "details": "Search and replace all getItem/setItem/removeItem calls using old keys with the new unified key 'intellifill-backend-auth'. Update any Zustand persist configurations to use the new name.",
            "status": "pending",
            "testStrategy": "Unit test: verify store persistence reads/writes only new key after migration.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Update cleanup and export functions to use new key",
            "description": "Modify all cleanup/export functions throughout codebase to reference the standardized key.",
            "dependencies": [1, 3],
            "details": "Globally update logout, session clear, data export functions to use 'intellifill-backend-auth'. Ensure no references to old keys remain in cleanup logic. Check auth-related utilities.",
            "status": "pending",
            "testStrategy": "Integration test: trigger logout → verify only new key cleared, no old keys remain.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Remove refreshToken from Zustand partialize configuration",
            "description": "Update backendAuthStore to exclude refreshToken from localStorage persistence.",
            "dependencies": [1, 3],
            "details": "In backendAuthStore.ts, modify persist partialize to include only { user, accessToken, tokenExpiresAt }. Ensure refreshToken cleared on login/refresh and stored only in cookies.",
            "status": "pending",
            "testStrategy": "E2E test: login → verify no refreshToken in localStorage, session works on reload via cookie.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T11:54:32.725Z"
      },
      {
        "id": "189",
        "title": "Fix Session Initialization Race Conditions",
        "description": "Refactor initialization to run only once using useRef flag and useCallback memoization (REQ-003)",
        "details": "In App.tsx and ProtectedRoute.tsx, use useRef for initialization flag:\n```typescript\nconst initRef = useRef(false);\nconst initialize = useCallback(async () => {\n  if (initRef.current) return;\n  initRef.current = true;\n  try {\n    await initializeStores();\n  } finally {\n    initRef.current = false;\n  }\n}, []);\nuseEffect(() => {\n  initialize();\n}, [initialize]);\n``` Remove duplicate calls from ProtectedRoute.tsx. Use existing useIsMounted hook to prevent state updates after unmount. Add console.warn if duplicate detected.",
        "testStrategy": "E2E test: rapid page reloads (10x) → verify single /api/auth/v2/me call per reload. Console log analysis: no race warnings. Network tab: no duplicate API calls.",
        "priority": "high",
        "dependencies": ["188"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement useRef flag in App.tsx",
            "description": "Add useRef initialization flag and memoized initialize function in App.tsx to prevent multiple initialization calls",
            "dependencies": [],
            "details": "Use provided code pattern: create initRef = useRef(false), useCallback for initialize() with early return if initRef.current true, set true before await initializeStores(), false in finally block. Add useEffect to trigger initialize.",
            "status": "pending",
            "testStrategy": "Verify console shows no duplicate warnings during rapid re-renders. Check network tab for single /api/auth/v2/me call.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Integrate useIsMounted hook in App.tsx",
            "description": "Wrap initialization logic with existing useIsMounted hook to prevent state updates after component unmount",
            "dependencies": [1],
            "details": "Import useIsMounted from hooks library. Use useIsMountedEffect or similar wrapper around state updates in initialize function to avoid memory leaks and stale updates.",
            "status": "pending",
            "testStrategy": "Unmount component during initialization → verify no React warnings about updating unmounted component.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add duplicate detection warning in App.tsx",
            "description": "Implement console.warn logging when duplicate initialization attempts are detected",
            "dependencies": [1],
            "details": "In initialize useCallback, add console.warn('Duplicate initialization detected') when initRef.current is already true before returning early. Include timestamp and component name.",
            "status": "pending",
            "testStrategy": "Trigger multiple concurrent initialize calls → verify warning appears exactly once per duplicate attempt.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Remove initialization from ProtectedRoute.tsx",
            "description": "Eliminate all duplicate initializeStores() calls from ProtectedRoute.tsx",
            "dependencies": [1],
            "details": "Search for initializeStores(), useEffect with initialization, or similar patterns in ProtectedRoute.tsx. Remove completely since App.tsx now handles centralized initialization.",
            "status": "pending",
            "testStrategy": "Verify ProtectedRoute.tsx contains no initializeStores() calls. Test navigation → single API call from App.tsx only.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "E2E test session initialization race conditions",
            "description": "Create E2E tests for rapid page reloads verifying single initialization per reload",
            "dependencies": [1, 2, 3, 4],
            "details": "Write Playwright test: 10x rapid page reloads, expect exactly 1 /api/auth/v2/me call per reload cycle. Verify no console warnings. Check network tab for no duplicates.",
            "status": "pending",
            "testStrategy": "Run test suite → verify passes consistently across browsers. Test edge cases: network failure, slow initialization, concurrent navigation.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T12:06:28.408Z"
      },
      {
        "id": "190",
        "title": "Implement Token Validation on Rehydration",
        "description": "Modify onRehydrateStorage to automatically call initialize() for backend validation (REQ-001)",
        "details": "In backendAuthStore.ts Zustand store:\n```typescript\nconst useBackendAuthStore = create<BackendAuthState>()(\n  persist(\n    // store config\n    {\n      onRehydrateStorage: (state) => {\n        return (state, error) => {\n          if (!error && state) {\n            initialize(); // Auto-validate with backend\n          }\n        };\n      },\n    },\n    { name: 'intellifill-backend-auth' }\n  )\n);\n``` Add loading state during validation. Implement 10s timeout using existing useTimeout hook.",
        "testStrategy": "E2E test: login → page reload → verify /api/auth/v2/me called → dashboard shown (valid token) or login shown (invalid). Verify loading spinner during validation.",
        "priority": "high",
        "dependencies": ["188", "189"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Add loading state to BackendAuthState interface",
            "description": "Extend the BackendAuthState TypeScript interface to include a loading boolean property for tracking rehydration validation status.",
            "dependencies": [],
            "details": "In backendAuthStore.ts, update the BackendAuthState interface to include `loading: boolean` with initial value false. This enables components to show loading spinner during token validation.",
            "status": "pending",
            "testStrategy": "Unit test: Verify interface includes loading property and initial state is false.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Update onRehydrateStorage to set loading state",
            "description": "Modify the onRehydrateStorage callback to set loading state to true before calling initialize() and handle the complete callback.",
            "dependencies": [1],
            "details": "In the onRehydrateStorage return function, add `set({ loading: true })` before `initialize()`, then in initialize() completion/error handlers set `loading: false`. Ensure both success and error paths clear loading state.",
            "status": "pending",
            "testStrategy": "Unit test: Mock rehydration → verify loading becomes true → mock initialize complete → verify loading false.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate useTimeout hook for 10s validation timeout",
            "description": "Implement 10-second timeout logic using the existing useTimeout hook to force logout if backend validation doesn't complete.",
            "dependencies": [2],
            "details": "In the store, create a timeout mechanism that calls logout() after 10s if loading is still true. Use useTimeout hook pattern adapted for Zustand store context, clearing timeout on validation complete.",
            "status": "pending",
            "testStrategy": "Unit test: Mock initialize delay >10s → verify timeout triggers logout and loading cleared.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Update initialize() to handle loading state management",
            "description": "Modify the existing initialize() function to accept and manage the store's loading state in its success/error callbacks.",
            "dependencies": [2],
            "details": "Pass store setter to initialize() or use getState/set from Zustand context. Ensure initialize() completion (success or /api/auth/v2/me failure) calls set({ loading: false }) regardless of validation outcome.",
            "status": "pending",
            "testStrategy": "Integration test: Call initialize() → verify loading toggles correctly on success and 401 error paths.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add E2E test for rehydration token validation flow",
            "description": "Create end-to-end test verifying the complete rehydration validation flow including loading state and timeout.",
            "dependencies": [3],
            "details": "E2E test sequence: 1) Login with valid token 2) Page reload 3) Verify loading spinner appears 4) Verify /api/auth/v2/me called 5) Verify dashboard for valid token or login for invalid 6) Test 10s timeout → login screen.",
            "status": "pending",
            "testStrategy": "Cypress/Playwright: Test valid token → dashboard + loading spinner. Test expired token → login screen. Test network timeout → login after 10s.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T12:10:13.440Z"
      },
      {
        "id": "191",
        "title": "Add Initialization Timeout Guard",
        "description": "Wrap initialize() with 10-second timeout using useTimeout hook (REQ-008)",
        "details": "In ProtectedRoute.tsx:\n```typescript\nconst { startTimeout, isTimingOut, resetTimeout } = useTimeout(10000, () => {\n  toast.error('Session initialization timed out. Please check your connection and try again.', {\n    action: { label: 'Retry', onClick: () => window.location.reload() }\n  });\n});\nuseEffect(() => {\n  startTimeout();\n  initialize().finally(() => resetTimeout());\n}, []);\nif (isLoading || isTimingOut) return <LoadingSpinner message={isTimingOut ? 'Initializing...' : 'Validating session...'} />;\n``` Use existing hooks library useTimeout.",
        "testStrategy": "E2E test: mock slow backend (>10s) → verify timeout error and retry button. Test fast init (<2s) → no timeout. Test retry → reinitializes successfully.",
        "priority": "high",
        "dependencies": ["189", "190"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Import useTimeout hook",
            "description": "Add the useTimeout hook import statement to ProtectedRoute.tsx from the existing hooks library.",
            "dependencies": [],
            "details": "Add import at the top of ProtectedRoute.tsx: import { useTimeout } from '@/hooks/useTimeout'; or wherever the existing hooks library exports it. Verify the exact import path matches project structure.",
            "status": "pending",
            "testStrategy": "Verify no TypeScript import errors in IDE. Check bundle includes hook without tree-shaking issues.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Add useTimeout hook declaration",
            "description": "Declare the useTimeout hook with 10-second timeout and toast error callback in ProtectedRoute.tsx component.",
            "dependencies": [1],
            "details": "Add exactly this code: const { startTimeout, isTimingOut, resetTimeout } = useTimeout(10000, () => { toast.error('Session initialization timed out. Please check your connection and try again.', { action: { label: 'Retry', onClick: () => window.location.reload() } }); }); Ensure toast is imported.",
            "status": "pending",
            "testStrategy": "Unit test: verify hook returns expected methods. Console log hook values on render.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Wrap initialize() call with timeout logic",
            "description": "Create useEffect that starts timeout before initialize() and resets it after completion using finally().",
            "dependencies": [2],
            "details": "Add useEffect: useEffect(() => { startTimeout(); initialize().finally(() => resetTimeout()); }, []); Ensure initialize() is properly imported/available from parent task dependencies (189/190). Empty dependency array for mount-only execution.",
            "status": "pending",
            "testStrategy": "Verify useEffect runs once on mount. Check initialize() called after startTimeout(). Console log sequence.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Update loading spinner condition",
            "description": "Modify loading spinner render condition to show during isLoading OR isTimingOut states.",
            "dependencies": [3],
            "details": "Replace existing loading condition with: if (isLoading || isTimingOut) return <LoadingSpinner message={isTimingOut ? 'Initializing...' : 'Validating session...'} />; Ensure LoadingSpinner component handles both messages correctly.",
            "status": "pending",
            "testStrategy": "Manual test: trigger both isLoading=true and isTimingOut=true states, verify correct messages display.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add E2E timeout tests",
            "description": "Implement comprehensive E2E tests for timeout scenarios including slow backend, fast init, and retry functionality.",
            "dependencies": [4],
            "details": "Create Cypress/Playwright tests: 1) Mock backend >10s → verify timeout toast + retry button appears. 2) Fast init <2s → no timeout. 3) Click retry → page reloads and reinitializes. Use network throttling for slow backend simulation.",
            "status": "pending",
            "testStrategy": "E2E: Mock slow backend (>10s) → verify timeout error and retry button. Test fast init (<2s) → no timeout. Test retry → reinitializes successfully. Network tab verification.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T12:13:41.869Z"
      },
      {
        "id": "192",
        "title": "Fix Session Persistence E2E Test",
        "description": "Unskip and fix auth.spec.ts session persistence test (REQ-010)",
        "details": "In auth.spec.ts, unskip test and fix assertions:\n```typescript\nit('restores session on page reload', async ({ page }) => {\n  // Login\n  await login(page);\n  // Reload\n  await page.reload();\n  // Verify loading spinner shown\n  await expect(page.locator('[data-testid=\"loading-spinner\"]')).toBeVisible({ timeout: 15000 });\n  // Verify dashboard visible, no login flash\n  await expect(page.locator('[data-testid=\"dashboard\"]')).toBeVisible();\n  await expect(page.locator('[data-testid=\"login-form\"]')).not.toBeVisible();\n  // Verify /me API called\n  await expect(page.waitForResponse('/api/auth/v2/me')).toPass();\n});\n``` Mock backend to return valid session.",
        "testStrategy": "Run test suite → verify passes consistently. Test invalid token → redirects to login. Test network failure → timeout error shown.",
        "priority": "high",
        "dependencies": ["190"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Unskip the session persistence test",
            "description": "Locate the 'restores session on page reload' test in auth.spec.ts and remove the skip marker (it.skip or test.skip) to enable execution.",
            "dependencies": [],
            "details": "Search for the test by name in auth.spec.ts file. Remove .skip() call or change it.skip to it. Verify test appears in Cypress runner without skip indicator.",
            "status": "pending",
            "testStrategy": "Run Cypress test suite and confirm the test is listed as runnable, not skipped.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Set up backend mocking for /api/auth/v2/me endpoint",
            "description": "Create Cypress intercept to mock the /api/auth/v2/me response returning valid session data after login.",
            "dependencies": [1],
            "details": "Use cy.intercept('GET', '/api/auth/v2/me', { statusCode: 200, body: { user: { id: 1, email: 'test@example.com' }, token: 'valid-token' } }).as('me-api'); Ensure mock returns before page reload assertions.",
            "status": "pending",
            "testStrategy": "Verify network tab shows mocked response with 200 status and valid user data during test execution.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement and verify login + reload sequence",
            "description": "Ensure login(page) completes successfully, followed by page.reload(), then verify loading spinner visibility with 15s timeout.",
            "dependencies": [1, 2],
            "details": "Keep existing code: await login(page); await page.reload(); await expect(page.locator('[data-testid=\"loading-spinner\"]')).toBeVisible({ timeout: 15000 }); Add logging if spinner timeout occurs.",
            "status": "pending",
            "testStrategy": "Watch for spinner element appearance in test replay. Test fails if spinner never appears within timeout.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add dashboard and login form visibility assertions",
            "description": "After spinner verification, assert dashboard is visible and login form is hidden to confirm no login flash.",
            "dependencies": [1, 2, 3],
            "details": "Add assertions: await expect(page.locator('[data-testid=\"dashboard\"]')).toBeVisible(); await expect(page.locator('[data-testid=\"login-form\"]')).not.toBeVisible(); Increase timeout if elements slow to appear.",
            "status": "pending",
            "testStrategy": "Screenshot comparison: dashboard visible, login form absent. Run test 3x to verify consistency.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Verify /api/auth/v2/me API call and finalize test",
            "description": "Confirm the mocked /me API is called after reload using waitForResponse, then run full test suite validation.",
            "dependencies": [1, 2, 3, 4],
            "details": "Add: await expect(page.waitForResponse('/api/auth/v2/me')).toPass(); Run entire suite: npm run test:e2e. Test invalid token case separately by modifying mock to 401.",
            "status": "pending",
            "testStrategy": "Network tab: exactly one /me call post-reload. Full suite passes. Invalid token mock redirects to login form.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T20:22:01.834Z"
      },
      {
        "id": "193",
        "title": "Backend: Add httpOnly Cookie Support to Login/Register",
        "description": "Update login/register endpoints to set refreshToken in httpOnly cookie (REQ-005 Phase 2)",
        "details": "In supabase-auth.routes.ts, ensure cookie-parser middleware:\n```typescript\napp.use(cookieParser());\n\n// Login endpoint\napp.post('/api/auth/v2/login', async (req, res) => {\n  // ... auth logic\n  const refreshToken = await generateRefreshToken();\n  res.cookie('refreshToken', refreshToken, {\n    httpOnly: true,\n    secure: process.env.NODE_ENV === 'production',\n    sameSite: 'strict',\n    maxAge: 604800000, // 7 days\n    path: '/api/auth'\n  });\n  res.json({ success: true, data: { user, tokens: { accessToken, expiresIn } } });\n});\n``` Remove refreshToken from response body. Same for register endpoint.",
        "testStrategy": "Integration test: POST /login → verify Set-Cookie header with correct flags. Browser test: login → inspect cookies → verify httpOnly refreshToken present.",
        "priority": "high",
        "dependencies": ["187"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Verify and Add cookie-parser Middleware",
            "description": "Ensure cookie-parser middleware is properly installed and configured in the Express app before auth routes.",
            "dependencies": [],
            "details": "Check package.json for 'cookie-parser' dependency, install if missing. In main app file or routes file, add app.use(cookieParser()) before mounting supabase-auth.routes.ts. Import cookieParser from 'cookie-parser'.",
            "status": "pending",
            "testStrategy": "Verify req.cookies is available in a test route by logging req.cookies after middleware.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Update Login Endpoint for httpOnly Cookie",
            "description": "Modify POST /api/auth/v2/login to set refreshToken in httpOnly cookie and remove from response body.",
            "dependencies": [1],
            "details": "In supabase-auth.routes.ts, generate refreshToken, call res.cookie('refreshToken', refreshToken, {httpOnly: true, secure: process.env.NODE_ENV === 'production', sameSite: 'strict', maxAge: 604800000, path: '/api/auth'}). Update res.json to exclude refreshToken: {success: true, data: {user, tokens: {accessToken, expiresIn}}}",
            "status": "pending",
            "testStrategy": "Integration test: POST /login with credentials → verify 200 response, Set-Cookie header contains refreshToken with httpOnly=true, secure flag correct for env, and refreshToken absent from JSON body.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Update Register Endpoint for httpOnly Cookie",
            "description": "Apply identical httpOnly cookie changes to POST /api/auth/v2/register endpoint as done for login.",
            "dependencies": [1],
            "details": "Locate register endpoint in supabase-auth.routes.ts, add refreshToken cookie setting with same options as login. Remove refreshToken from response JSON body, keeping only user data and accessToken.",
            "status": "pending",
            "testStrategy": "Integration test: POST /register with user data → verify Set-Cookie header with correct flags, no refreshToken in response body, user created successfully.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Remove refreshToken from All Auth Responses",
            "description": "Audit and clean up any remaining instances where refreshToken appears in JSON responses across auth endpoints.",
            "dependencies": [2, 3],
            "details": "Search codebase for 'refreshToken' in res.json calls within auth routes. Ensure only accessToken and user data returned. Update any documentation or frontend expectations if needed.",
            "status": "pending",
            "testStrategy": "Run full auth flow tests (login/register) → grep responses for 'refreshToken' → confirm absence. Manual inspection of response schemas.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add Integration Tests for Cookie Implementation",
            "description": "Create comprehensive tests verifying cookie setting, security flags, and response changes for login/register.",
            "dependencies": [2, 3, 4],
            "details": "Use supertest for POST /login and /register tests. Assert Set-Cookie header presence, parse for httpOnly=true, secure=(env-based), sameSite=strict, maxAge=604800000. Verify 401 without creds. Browser test: login → devtools → confirm httpOnly refreshToken cookie.",
            "status": "pending",
            "testStrategy": "CI/CD tests pass: 100% coverage of cookie flags, edge cases (no creds, prod env secure=true), cross-browser cookie inspection.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T20:29:16.915Z"
      },
      {
        "id": "194",
        "title": "Backend: Implement Cookie-Based Refresh Endpoint",
        "description": "Update refresh endpoint to read refreshToken from cookie, not body (REQ-005 Phase 2)",
        "details": "In supabase-auth.routes.ts:\n```typescript\napp.post('/api/auth/v2/refresh', async (req, res) => {\n  const refreshToken = req.cookies.refreshToken;\n  if (!refreshToken) {\n    return res.status(401).json({ success: false, error: 'No refresh token' });\n  }\n  // Validate and rotate refresh token\n  const newTokens = await refreshSession(refreshToken);\n  res.cookie('refreshToken', newTokens.refreshToken, {\n    httpOnly: true,\n    secure: process.env.NODE_ENV === 'production',\n    sameSite: 'strict',\n    maxAge: 604800000,\n    path: '/api/auth'\n  });\n  res.json({ success: true, data: { tokens: { accessToken: newTokens.accessToken, expiresIn: 3600 } } });\n});\n``` Support both cookie and body during migration phase.",
        "testStrategy": "Integration test: POST /refresh with cookie → verify new accessToken and updated cookie. Test missing cookie → 401. Test expired refreshToken → 401.",
        "priority": "high",
        "dependencies": ["193"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Verify cookie-parser middleware configuration",
            "description": "Ensure cookie-parser middleware is properly configured in the Express app to read cookies from refresh endpoint requests.",
            "dependencies": [],
            "details": "Check that `app.use(cookieParser());` is present before auth routes in supabase-auth.routes.ts. Install cookie-parser if missing via `npm i cookie-parser`. Test cookie reading with a simple endpoint.",
            "status": "pending",
            "testStrategy": "Unit test: Mock req.cookies object and verify middleware parses correctly. Integration test: Send cookie in request and verify it's accessible in handler.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement dual refreshToken extraction logic",
            "description": "Update refresh endpoint to read refreshToken from cookie first, then fallback to request body during migration phase.",
            "dependencies": [1],
            "details": "Modify handler: `let refreshToken = req.cookies?.refreshToken || req.body?.refreshToken;`. Add validation: if (!refreshToken) return 401. Preserve existing refreshSession() call.",
            "status": "pending",
            "testStrategy": "Integration tests: 1) Cookie only → success. 2) Body only → success. 3) Both → prefers cookie. 4) Neither → 401 error.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Update refresh token cookie setting with correct options",
            "description": "Ensure new refreshToken cookie is set with secure httpOnly options matching login/register endpoints.",
            "dependencies": [2],
            "details": "Use exact same cookie options as Task 193: httpOnly: true, secure: NODE_ENV==='production', sameSite: 'strict', maxAge: 604800000 (7 days), path: '/api/auth'. Clear old cookie if present.",
            "status": "pending",
            "testStrategy": "Verify Set-Cookie header contains all security flags. Test in production/staging envs for secure flag. Browser devtools: inspect cookie attributes post-refresh.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Preserve existing response format and error handling",
            "description": "Maintain backward-compatible JSON response structure and add specific error messages for missing/expired tokens.",
            "dependencies": [2],
            "details": "Response: { success: true, data: { tokens: { accessToken, expiresIn: 3600 } } }. Errors: 'No refresh token', handle refreshSession() failures with 401. Log errors for debugging.",
            "status": "pending",
            "testStrategy": "Test happy path → correct JSON structure. Test refreshSession() throws → 401 with error message. Verify expiresIn is always 3600.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add comprehensive integration tests for refresh endpoint",
            "description": "Create integration tests covering all refresh endpoint scenarios including cookie precedence and migration support.",
            "dependencies": [3],
            "details": "Use supertest: 1) Valid cookie → new tokens + updated cookie. 2) Valid body → success (migration). 3) No token → 401. 4) Expired token → 401. 5) Cookie + body → cookie wins.",
            "status": "pending",
            "testStrategy": "Full test suite with 100% coverage of endpoint logic. Mock refreshSession() for predictable responses. Test cookie flags in Set-Cookie headers. Run against staging env.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T20:33:00.365Z"
      },
      {
        "id": "195",
        "title": "Frontend: Remove Refresh Token from localStorage",
        "description": "Update frontend stores to exclude refreshToken from persistence (REQ-005 Phase 2)",
        "details": "In backendAuthStore.ts, update persist config:\n```typescript\nconst useBackendAuthStore = create(\n  persist(\n    (set, get) => ({\n      // state without refreshToken\n    }), {\n      name: 'intellifill-backend-auth',\n      partialize: (state) => ({ \n        user: state.user, \n        accessToken: state.accessToken, \n        tokenExpiresAt: state.tokenExpiresAt \n        // exclude refreshToken\n      })\n    }\n  )\n);\n``` Clear any existing refreshTokens on login/refresh.",
        "testStrategy": "Browser devtools: login → verify no refreshToken in localStorage, only in cookies. E2E test: page reload → session still works via cookie.",
        "priority": "high",
        "dependencies": ["188", "194"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Update persist partialize config to exclude refreshToken",
            "description": "Modify the partialize function in backendAuthStore.ts to exclude refreshToken from localStorage persistence while keeping user, accessToken, and tokenExpiresAt.",
            "dependencies": [],
            "details": "Update the persist config exactly as specified: partialize: (state) => ({ user: state.user, accessToken: state.accessToken, tokenExpiresAt: state.tokenExpiresAt }) - ensure refreshToken is completely omitted from the returned object.",
            "status": "pending",
            "testStrategy": "Check store state in Redux DevTools - verify refreshToken exists in memory but is absent from partialize output.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Ensure store state definition excludes refreshToken persistence",
            "description": "Update the Zustand store creator to properly handle refreshToken in memory only, without any persistence configuration that includes it.",
            "dependencies": [1],
            "details": "In the create(persist((set, get) => ({ ... }))) - ensure the initial state shape supports refreshToken in memory but relies solely on the partialize from subtask 1 for persistence.",
            "status": "pending",
            "testStrategy": "Verify store can set/get refreshToken in memory via get().refreshToken and set({refreshToken: 'test'}) without errors.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Clear existing refreshTokens from localStorage on login",
            "description": "Implement cleanup logic in the login action to remove any pre-existing refreshToken from localStorage immediately upon successful login.",
            "dependencies": [1, 2],
            "details": "In the login handler: after successful login, explicitly call localStorage.removeItem('intellifill-backend-auth') or use store rehydration to overwrite with new partialized state excluding refreshToken.",
            "status": "pending",
            "testStrategy": "Manually add refreshToken to localStorage → login → verify key is cleared or overwritten without refreshToken.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Clear existing refreshTokens from localStorage on token refresh",
            "description": "Add cleanup logic in refreshTokenIfNeeded to ensure localStorage never contains refreshToken after refresh operations.",
            "dependencies": [1, 2, 3],
            "details": "In refreshTokenIfNeeded(): after successful refresh, ensure the store state update uses partialize (no manual localStorage writes) and consider explicit localStorage cleanup if legacy data exists.",
            "status": "pending",
            "testStrategy": "Trigger refresh flow → check localStorage before/after → confirm no refreshToken persists.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Verify implementation with browser testing and E2E validation",
            "description": "Test the complete implementation to confirm refreshToken is excluded from localStorage while session functionality remains intact.",
            "dependencies": [1, 2, 3, 4],
            "details": "Follow test strategy: Browser devtools Application tab → login → verify no refreshToken in localStorage (only cookies). Page reload → session works via cookie refresh mechanism.",
            "status": "pending",
            "testStrategy": "1. Login → DevTools → localStorage → no refreshToken. 2. Page reload → auto-refresh works. 3. E2E: simulate expiry → refresh succeeds via cookies only.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T20:34:45.813Z"
      },
      {
        "id": "196",
        "title": "Update Frontend Refresh Logic for Cookies",
        "description": "Modify refreshTokenIfNeeded() to send empty body (cookie auto-sent) (REQ-005 Phase 2)",
        "details": "In backendAuthStore.ts:\n```typescript\nconst refreshTokenIfNeeded = async () => {\n  if (Date.now() < get().tokenExpiresAt - 2 * 60 * 1000) return; // 2min early\n  \n  try {\n    const response = await fetch('/api/auth/v2/refresh', {\n      method: 'POST',\n      credentials: 'include', // Send cookies\n      body: JSON.stringify({}) // Empty body\n    });\n    \n    if (response.ok) {\n      const data = await response.json();\n      set({ accessToken: data.data.tokens.accessToken, tokenExpiresAt: Date.now() + data.data.tokens.expiresIn * 1000 });\n    } else {\n      logout();\n    }\n  } catch (error) {\n    toast.error('Unable to refresh session. Please save your work.', {\n      action: { label: 'Retry', onClick: () => refreshTokenIfNeeded() }\n    });\n  }\n};\n``` Always include credentials: 'include'.",
        "testStrategy": "E2E test: wait until near expiry → verify refresh called with credentials: 'include' and empty body → new accessToken received.",
        "priority": "high",
        "dependencies": ["195"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Locate and Open backendAuthStore.ts File",
            "description": "Navigate to the backendAuthStore.ts file in the project and open it in the code editor for modification.",
            "dependencies": [],
            "details": "Find the file containing the refreshTokenIfNeeded function, typically in the stores or auth directory. Verify the current implementation matches the provided code snippet with the existing body: JSON.stringify({}).",
            "status": "pending",
            "testStrategy": "Manual verification: Confirm file opens and function signature is visible.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Update refreshTokenIfNeeded Fetch Request",
            "description": "Modify the fetch call in refreshTokenIfNeeded to ensure empty body is sent with credentials: 'include'.",
            "dependencies": [1],
            "details": "Replace or confirm the fetch options: method: 'POST', credentials: 'include', body: JSON.stringify({}). Ensure no other body content is added and comment clearly indicates cookie auto-sent behavior.",
            "status": "pending",
            "testStrategy": "Unit test: Mock fetch call and verify request options include credentials: 'include' and body is '{}'.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Verify Token Parsing and State Update Logic",
            "description": "Confirm response parsing and state update logic correctly handles new access token and expiry.",
            "dependencies": [2],
            "details": "Check if (response.ok) block correctly extracts data.data.tokens.accessToken and sets tokenExpiresAt: Date.now() + data.data.tokens.expiresIn * 1000. Add comments for clarity.",
            "status": "pending",
            "testStrategy": "Unit test: Mock successful response with token data and verify set() is called with correct values.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Validate Error Handling and Logout Behavior",
            "description": "Ensure error handling in refreshTokenIfNeeded properly triggers logout and shows toast notification.",
            "dependencies": [2],
            "details": "Verify !response.ok calls logout() and catch block displays toast.error with 'Unable to refresh session. Please save your work.' and Retry action that recalls refreshTokenIfNeeded.",
            "status": "pending",
            "testStrategy": "Unit test: Mock failed response (non-ok) and error throw, verify logout() called and toast triggered.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Run E2E Tests and Commit Changes",
            "description": "Execute end-to-end tests for token refresh and commit the updated backendAuthStore.ts.",
            "dependencies": [3, 4],
            "details": "Run E2E test: simulate near token expiry, verify /api/auth/v2/refresh called with credentials: 'include' and empty body, confirm new accessToken received and stored. Commit with message referencing REQ-005 Phase 2.",
            "status": "pending",
            "testStrategy": "E2E test: Wait until 2min before expiry → verify fetch request → assert new accessToken and updated tokenExpiresAt.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T20:36:35.197Z"
      },
      {
        "id": "197",
        "title": "Add Token Refresh Test Suite",
        "description": "Create comprehensive E2E tests for proactive/reactive refresh flows (REQ-011)",
        "details": "Create token-refresh.spec.ts:\n```typescript\n// Proactive refresh (before 2min threshold)\nit('proactively refreshes token', async ({ page }) => {\n  await mockTokenExpiry(page, Date.now() + 1 * 60 * 1000); // 1min\n  await page.waitForResponse('/api/auth/v2/refresh');\n});\n\n// Reactive refresh (401 error)\nit('reactively refreshes on 401', async ({ page }) => {\n  await mock401Response(page);\n  await expect(page.waitForResponse('/api/auth/v2/refresh')).toPass();\n});\n\n// Failed refresh → logout\nit('logs out on refresh failure', async ({ page }) => {\n  await mockRefreshFail(page);\n  await expect(page.locator('[data-testid=\"login-form\"]')).toBeVisible();\n});\n``` Test concurrent prevention using shared promise.",
        "testStrategy": "Run full test suite → all refresh scenarios pass. Verify no double refresh calls. Test edge cases: expired refresh token, network failure.",
        "priority": "medium",
        "dependencies": ["196"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create token-refresh.spec.ts file structure",
            "description": "Set up the Playwright test file with describe block, beforeEach hooks for login and initial token setup.",
            "dependencies": [],
            "details": "Create token-refresh.spec.ts with describe('Token Refresh Flows', () => { beforeEach(async ({ page }) => { await loginUser(page); await mockValidToken(page, Date.now() + 10 * 60 * 1000); }); }); Add test tags for E2E reporting.",
            "status": "pending",
            "testStrategy": "Verify file structure loads without syntax errors in Playwright test runner",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement proactive refresh test case",
            "description": "Write test for proactive token refresh triggered before 2-minute expiry threshold.",
            "dependencies": [1],
            "details": "Implement it('proactively refreshes token', async ({ page }) => { await mockTokenExpiry(page, Date.now() + 1 * 60 * 1000); await page.waitForResponse('/api/auth/v2/refresh'); expect(await getTokenExpiry(page)).toBeGreaterThan(Date.now() + 15 * 60 * 1000); }); Verify new token expiry >15min.",
            "status": "pending",
            "testStrategy": "Mock 1min expiry → verify single /refresh call → new token expiry >15min",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement reactive refresh on 401 test",
            "description": "Test automatic refresh triggered by 401 Unauthorized response on API call.",
            "dependencies": [1],
            "details": "Add it('reactively refreshes on 401', async ({ page }) => { await mock401Response(page, '/api/protected-endpoint'); await expect(page.waitForResponse('/api/auth/v2/refresh')).toPass({ timeout: 5000 }); await expect(page.waitForResponse('/api/protected-endpoint')).toPass(); }); Verify retry succeeds.",
            "status": "pending",
            "testStrategy": "Mock 401 → verify refresh called → verify retry API succeeds with 200",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement refresh failure logout test",
            "description": "Test user logout when refresh endpoint returns failure (401/500).",
            "dependencies": [1],
            "details": "Create it('logs out on refresh failure', async ({ page }) => { await mockRefreshFail(page); await expect(page.locator('[data-testid=\"login-form\"]')).toBeVisible({ timeout: 10000 }); await expect(page.locator('[data-testid=\"protected-content\"]')).toBeHidden(); }); Verify session cleared.",
            "status": "pending",
            "testStrategy": "Mock refresh 401 → verify login form visible → verify protected content hidden",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add concurrent refresh prevention test",
            "description": "Test shared promise prevents multiple simultaneous refresh calls using race condition simulation.",
            "dependencies": [2, 3],
            "details": "Implement it('prevents concurrent refresh calls', async ({ page }) => { const promises = Array(5).fill(0).map(() => mockNearExpiry(page)); await Promise.all(promises); const responses = await page.waitForResponse('/api/auth/v2/refresh', { timeout: 10000 }); expect(responses.length).toBe(1); }); Use shared promise verification.",
            "status": "pending",
            "testStrategy": "Trigger 5 concurrent expiry conditions → verify exactly 1 refresh call made",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T20:38:02.092Z"
      },
      {
        "id": "198",
        "title": "Implement Proactive Refresh Error Notifications",
        "description": "Show toast notifications for refresh failures with retry option (REQ-007)",
        "details": "Already partially implemented in task 196. Enhance toast:\n```typescript\nif (!response.ok || !data.success) {\n  toast.error('Session refresh failed. Save your work and retry.', {\n    id: 'refresh-error',\n    duration: 10000,\n    action: [\n      {\n        label: 'Retry',\n        onClick: () => refreshTokenIfNeeded(),\n      },\n      {\n        label: 'Logout',\n        onClick: logout,\n      },\n    ],\n  });\n  // Retry 3x with exponential backoff\n  let retries = 0;\n  const maxRetries = 3;\n  const retryWithBackoff = async () => {\n    retries++;\n    if (retries >= maxRetries) {\n      toast.error('Multiple refresh attempts failed. Logging out...', { id: 'refresh-fatal' });\n      logout();\n      return;\n    }\n    await new Promise(r => setTimeout(r, 1000 * Math.pow(2, retries)));\n    refreshTokenIfNeeded();\n  };\n}\n``` Use sonner/react-hot-toast for toasts.",
        "testStrategy": "E2E test: mock refresh failure → verify toast appears with Retry/Logout buttons. Test retry → calls refresh again. Test 3 failures → auto-logout.",
        "priority": "medium",
        "dependencies": ["196"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Refactor Inline Retry Logic into Separate Hook",
            "description": "Extract the inline retry logic with exponential backoff into a reusable custom hook to improve code organization and testability.",
            "dependencies": [],
            "details": "Create useAutoRetryRefresh hook that handles up to 3 retries with exponential backoff (1s, 2s, 4s). Return loading state and success/failure status. Remove inline retries from the existing error handler.",
            "status": "pending",
            "testStrategy": "Unit test hook: mock refreshTokenIfNeeded failures → verify 3 retries with correct delays → verify returns failure after max retries.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Enhance Toast Notification Content and UX",
            "description": "Improve toast message clarity, add progress indication for retries, and ensure sonner/react-hot-toast best practices are followed.",
            "dependencies": [1],
            "details": "Update toast.error message to 'Session refresh failed. Auto-retrying...' with dynamic retry count. Add loading spinner during retries using toast.loading(). Ensure duration=10000 and unique IDs. Follow UX best practices: clear messaging, simple actions.",
            "status": "pending",
            "testStrategy": "Visual regression test: verify toast appears with correct message, Retry/Logout buttons, and 10s duration. Test auto-dismiss behavior.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate Auto-Retry Hook with Error Handler",
            "description": "Replace existing toast + inline retry code with the new useAutoRetryRefresh hook integration.",
            "dependencies": [1, 2],
            "details": "In refresh error block: show initial toast, then call useAutoRetryRefresh(). Update Retry button to trigger manual retry via hook. Ensure Logout action remains available. Dismiss 'refresh-error' toast on retry success.",
            "status": "pending",
            "testStrategy": "Integration test: trigger refresh failure → verify hook called → verify sequential retries → verify toast updates.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add Comprehensive Error State Management",
            "description": "Implement global refresh failure state in auth store with loading indicators and user guidance.",
            "dependencies": [3],
            "details": "Add isRefreshing and refreshFailed states to backendAuthStore. Show app-wide loading overlay during retries. Display persistent banner if refresh permanently fails before auto-logout. Ensure smooth UX transitions.",
            "status": "pending",
            "testStrategy": "E2E test: refresh failure → verify loading spinner → verify banner after max retries → verify auto-logout after fatal error.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement Complete E2E Test Coverage",
            "description": "Write comprehensive tests covering all refresh failure scenarios as specified in original test strategy.",
            "dependencies": [4],
            "details": "Create Cypress/Playwright tests: 1) Mock refresh failure → verify toast with Retry/Logout 2) Click Retry → verify refreshTokenIfNeeded called 3) 3 failures → verify 'refresh-fatal' toast → auto-logout. Test edge cases: network errors, 401 responses.",
            "status": "pending",
            "testStrategy": "Run full test suite: verify 100% pass rate. Test manual Retry button → single refresh call. Test Logout → immediate redirect to /login.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T20:39:35.012Z"
      },
      {
        "id": "199",
        "title": "Add Race Condition and Edge Case Tests",
        "description": "Add E2E tests for rapid reloads and edge cases (REQ-012, REQ-013)",
        "details": "Extend auth.spec.ts:\n```typescript\n// Race condition test\nit('handles rapid reloads without races', async ({ page, browser }) => {\n  await login(page);\n  for (let i = 0; i < 10; i++) {\n    await page.reload({ waitUntil: 'networkidle' });\n    await expect(page.locator('[data-testid=\"dashboard\"]')).toBeVisible({ timeout: 5000 });\n  }\n});\n\n// Edge cases\nit('clears invalid token', async ({ page }) => {\n  await page.addInitScript(() => {\n    localStorage.setItem('intellifill-backend-auth', JSON.stringify({ accessToken: 'invalid' }));\n  });\n  await page.goto('/');\n  await expect(page.locator('[data-testid=\"login-form\"]')).toBeVisible();\n});\n```",
        "testStrategy": "Run tests → 100% pass rate. Verify rapid reloads show no console errors. Test offline → timeout error. Test expired during session → refresh triggered.",
        "priority": "medium",
        "dependencies": ["192", "197"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Add Race Condition Rapid Reload Test",
            "description": "Implement the E2E test for handling rapid reloads without race conditions in auth.spec.ts as provided in the task details.",
            "dependencies": [],
            "details": "Copy the provided test code into auth.spec.ts: login, perform 10 rapid reloads with networkidle wait, verify dashboard visibility each time with 5000ms timeout. Ensure test uses Playwright fixtures page and browser.",
            "status": "pending",
            "testStrategy": "Run test 10x, verify 100% pass rate, check browser console for no race warnings or duplicate API calls to /api/auth/v2/me.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Add Invalid Token Clearing Test",
            "description": "Implement the E2E test for clearing invalid tokens by simulating localStorage with invalid auth token.",
            "dependencies": [],
            "details": "Add the provided test code to auth.spec.ts: use page.addInitScript to set invalid accessToken in localStorage, goto '/', expect login-form to be visible indicating token cleared.",
            "status": "pending",
            "testStrategy": "Verify login form appears, no dashboard shown, check network tab for no successful auth calls, console shows no errors.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add Offline Mode Edge Case Test",
            "description": "Create new E2E test for offline scenario where auth operations should timeout appropriately.",
            "dependencies": [1, 2],
            "details": "In auth.spec.ts, use browser.newContext({ offline: true }), attempt login or reload after login, expect timeout error on dashboard locator or API calls, timeout after 10s.",
            "status": "pending",
            "testStrategy": "Set offline context, verify timeout errors logged, no infinite hangs, test passes when expecting failure due to offline.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add Expired Token During Session Test",
            "description": "Implement test simulating token expiration mid-session triggering automatic refresh.",
            "dependencies": [1, 2],
            "details": "Mock expired token via initScript after login, perform page interaction/reload, verify refresh token call triggered and dashboard remains visible, login form does not appear.",
            "status": "pending",
            "testStrategy": "Check network tab for refresh token API call, verify single /api/auth/v2/me after refresh, no fallback to login, 100% pass rate.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Run Full Test Suite and Validate Coverage",
            "description": "Execute all auth.spec.ts tests, validate against REQ-012/REQ-013, ensure 100% pass rate and no regressions.",
            "dependencies": [1, 2, 3, 4],
            "details": "Run npx playwright test auth.spec.ts --headed, review console/network for races/duplicates/errors, update test strategy docs, commit with message referencing REQ-012, REQ-013.",
            "status": "pending",
            "testStrategy": "100% pass rate required, verify rapid reloads: single init per reload, no console errors, offline/expired handle gracefully per specs.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T20:51:32.727Z"
      },
      {
        "id": "200",
        "title": "Implement Token Cache Invalidation on Logout",
        "description": "Call tokenCache.invalidateToken() during logout (REQ-006)",
        "details": "In supabase-auth.routes.ts logout endpoint:\n```typescript\napp.post('/api/auth/v2/logout', async (req, res) => {\n  const refreshToken = req.cookies.refreshToken;\n  if (refreshToken) {\n    await tokenCache.invalidateToken(refreshToken); // Non-blocking\n    res.clearCookie('refreshToken');\n  }\n  res.json({ success: true });\n});\n``` Frontend logout also clears localStorage:\n```typescript\nconst logout = () => {\n  localStorage.clear();\n  window.location.href = '/login';\n};\n``` Make cache invalidation fire-and-forget with 500ms timeout.",
        "testStrategy": "Integration test: login → logout → verify cache cleared (subsequent /me calls hit Supabase). Test concurrent logouts → no errors.",
        "priority": "medium",
        "dependencies": ["194"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Update logout endpoint to make invalidation non-blocking",
            "description": "Modify the backend logout endpoint to call tokenCache.invalidateToken() without awaiting it, ensuring the response is sent immediately.",
            "dependencies": [],
            "details": "In supabase-auth.routes.ts, remove 'await' from tokenCache.invalidateToken(refreshToken) to make it fire-and-forget. Keep cookie clearing and success response synchronous for fast logout.",
            "status": "pending",
            "testStrategy": "Verify endpoint responds <100ms even if cache op hangs. Test with mock slow invalidateToken() → response still fast.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement 500ms timeout wrapper for cache invalidation",
            "description": "Create a utility function that wraps tokenCache.invalidateToken() with Promise.race() to timeout after 500ms and prevent hanging requests.",
            "dependencies": [1],
            "details": "Create timeoutInvalidateToken(refreshToken) using Promise.race([tokenCache.invalidateToken(refreshToken), new Promise((_, reject) => setTimeout(() => reject(new Error('timeout')), 500))]). Log timeout errors.",
            "status": "pending",
            "testStrategy": "Unit test: mock invalidateToken hanging → verify timeout fires at exactly 500ms. Test normal case → completes without timeout.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate timeout wrapper into logout endpoint",
            "description": "Replace direct cache invalidation call with the new timeout wrapper in the logout endpoint.",
            "dependencies": [2],
            "details": "Update POST /api/auth/v2/logout to use timeoutInvalidateToken(refreshToken) instead of direct call. Ensure it remains non-blocking with try-catch for timeout handling.",
            "status": "pending",
            "testStrategy": "Integration test: simulate slow cache → verify endpoint still responds fast, timeout logged but user unaffected.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add logging for cache invalidation success/failure",
            "description": "Implement structured logging for cache invalidation attempts, timeouts, and successes during logout.",
            "dependencies": [3],
            "details": "Add console.error for timeouts with refreshToken hash (not full token), console.log for successful invalidations. Use structured format: {event: 'token_invalidation', status: 'timeout/success', tokenHash: '...'}",
            "status": "pending",
            "testStrategy": "Manual test: logout → check server logs show success. Simulate timeout → verify timeout log appears without crashing endpoint.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Create integration tests for logout cache invalidation",
            "description": "Write comprehensive tests verifying cache invalidation works correctly on logout with timeout protection.",
            "dependencies": [4],
            "details": "Test suite: 1) login→logout→/me hits Supabase (cache cleared); 2) concurrent logouts (no errors); 3) slow cache simulation (timeout works); 4) no refreshToken (fast success response).",
            "status": "pending",
            "testStrategy": "Full E2E: login → logout → verify subsequent /me calls bypass cache and hit Supabase directly. Load test: 100 concurrent logouts → no errors, all caches cleared.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T20:41:21.280Z"
      },
      {
        "id": "201",
        "title": "Improve Loading States with Stages",
        "description": "Add substates to distinguish rehydration vs backend validation (REQ-009)",
        "details": "In store:\n```typescript\ntype LoadingStage = 'idle' | 'rehydrating' | 'validating' | 'ready';\nloadingStage: LoadingStage;\n```\nIn ProtectedRoute.tsx:\n```typescript\nconst stage = useBackendAuthStore(s => s.loadingStage);\nconst messages = {\n  rehydrating: 'Restoring session...',\n  validating: 'Validating with server...',\n  ready: 'Loading dashboard...'\n};\nreturn <LoadingSpinner message={messages[stage] || 'Loading...'} />;\n```\nUpdate initialize to set stages appropriately.",
        "testStrategy": "Manual test: page reload → verify spinner messages change: 'Restoring...' → 'Validating...' → dashboard. E2E test: verify no flash of wrong content.",
        "priority": "low",
        "dependencies": ["190", "191"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Update BackendAuthStore with LoadingStage state",
            "description": "Add the LoadingStage type and loadingStage property to the Zustand store used by backend authentication.",
            "dependencies": [],
            "details": "Define type LoadingStage = 'idle' | 'rehydrating' | 'validating' | 'ready'; Add loadingStage: LoadingStage to store state. Initialize as 'idle'. Export selector useBackendAuthStore(s => s.loadingStage).",
            "status": "pending",
            "testStrategy": "Unit test: verify store initializes with loadingStage='idle', selector returns correct value.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Add stage transition actions to store",
            "description": "Create actions in the store to set loadingStage to 'rehydrating', 'validating', and 'ready'.",
            "dependencies": [1],
            "details": "Add store methods: setRehydrating(), setValidating(), setReady(). Each updates loadingStage to respective value. Ensure actions are exported from store.",
            "status": "pending",
            "testStrategy": "Unit test: call each action and verify loadingStage updates correctly in store state.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Update ProtectedRoute.tsx to use staged messages",
            "description": "Modify ProtectedRoute component to read loadingStage and display appropriate spinner messages.",
            "dependencies": [1],
            "details": "Use const stage = useBackendAuthStore(s => s.loadingStage); Define messages object with rehydrating, validating, ready keys. Render <LoadingSpinner message={messages[stage] || 'Loading...'} />.",
            "status": "pending",
            "testStrategy": "Unit test: render with different stage props, verify correct message displayed in LoadingSpinner.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Update initialize function with stage transitions",
            "description": "Modify the initialize function to set appropriate loading stages during rehydration and validation.",
            "dependencies": [2],
            "details": "In initialize(): setRehydrating() before local storage/session check, setValidating() before backend refresh call, setReady() on successful completion or final state.",
            "status": "pending",
            "testStrategy": "Unit test: mock initialize flow, verify actions called in sequence: rehydrating → validating → ready.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add manual and E2E tests for loading stages",
            "description": "Implement testing strategy to verify spinner messages change correctly during page load.",
            "dependencies": [3, 4],
            "details": "Manual: page reload and check message sequence. E2E: use Cypress/Playwright to assert spinner text changes 'Restoring session...' → 'Validating with server...' → dashboard loads without wrong content flash.",
            "status": "pending",
            "testStrategy": "E2E test: intercept network calls, verify no content flash, message sequence correct. Manual verification on prod-like environment.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T21:01:31.064Z"
      },
      {
        "id": "202",
        "title": "Refactor to Use Existing Hooks Library",
        "description": "Replace custom logic with useTimeout, useIsMounted, useFetch from hooks library (REQ-014)",
        "details": "Audit all auth components:\n- Replace custom setTimeout with useTimeout\n- Wrap API calls with useFetch AbortController\n- Use useIsMounted for cleanup\n```typescript\nconst { data, error, isLoading } = useFetch('/api/auth/v2/me', {\n  refetchOnWindowFocus: false\n});\nuseIsMountedEffect(() => {\n  if (data) setUser(data.user);\n});\n``` Remove custom implementations, rely on hooks/index.ts.",
        "testStrategy": "Code review: verify no custom timeout/AbortController/useEffect cleanup logic remains. Component tests: verify hooks prevent memory leaks.",
        "priority": "low",
        "dependencies": ["191", "196"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Audit Auth Components for Custom Logic",
            "description": "Review all authentication-related components to identify custom setTimeout, AbortController, and useEffect cleanup implementations.",
            "dependencies": [],
            "details": "Scan files like Login.tsx, AuthProvider.tsx, ProtectedRoute.tsx for manual setTimeout calls, fetch with AbortController, and useEffect without proper cleanup. Document locations in a checklist.\n<info added on 2026-01-02T21:05:15.177Z>\nAudit completed. No custom setTimeout, AbortController, or problematic useEffect cleanup logic found in auth components. Login.tsx, Register.tsx, and ForgotPassword.tsx contain no manual implementations. AuthCallback.tsx and ResetPassword.tsx are already refactored to use the useTimeout hook from the usehooks-ts library. ProtectedRoute.tsx, backendAuthStore.ts, and authService.ts follow established patterns using Zustand and the standard API wrapper. No further refactoring is required as the codebase already aligns with the target architecture.\n</info added on 2026-01-02T21:05:15.177Z>",
            "status": "done",
            "testStrategy": "Manual code review: grep for 'setTimeout', 'AbortController', 'useEffect' in auth files.",
            "parentId": "undefined",
            "updatedAt": "2026-01-02T21:05:15.273Z"
          },
          {
            "id": 2,
            "title": "Replace Custom setTimeout with useTimeout Hook",
            "description": "Refactor all identified custom setTimeout logic in auth components to use the useTimeout hook from hooks/index.ts.",
            "dependencies": [1],
            "details": "Import useTimeout from hooks/index.ts. Replace setTimeout(callback, delay) with useTimeout(callback, delay). Ensure proper cleanup by verifying hook handles clearTimeout internally.",
            "status": "done",
            "testStrategy": "Component tests: Verify timeout callbacks execute after delay and are cleared on unmount. Check no memory leaks.",
            "parentId": "undefined",
            "updatedAt": "2026-01-02T21:05:27.938Z"
          },
          {
            "id": 3,
            "title": "Refactor API Calls to Use useFetch Hook",
            "description": "Replace manual fetch calls in auth components with useFetch('/api/auth/v2/me', { refetchOnWindowFocus: false }).",
            "dependencies": [1],
            "details": "Update all auth API endpoints to useFetch pattern. Destructure { data, error, isLoading }. Remove manual AbortController and fetch logic. Handle data assignment safely.",
            "status": "done",
            "testStrategy": "Network tab verification: Single API call per component mount. Test loading/error states render correctly.",
            "parentId": "undefined",
            "updatedAt": "2026-01-02T21:05:27.957Z"
          },
          {
            "id": 4,
            "title": "Implement useIsMounted for State Updates and Cleanup",
            "description": "Wrap all side-effect state updates in auth components with useIsMountedEffect to prevent updates on unmounted components.",
            "dependencies": [1, 3],
            "details": "Import useIsMountedEffect from hooks/index.ts. Wrap useEffect callbacks that set state: useIsMountedEffect(() => { if (data) setUser(data.user); }); Remove custom mounted flags.",
            "status": "done",
            "testStrategy": "Unmount during async operation: Verify no React warnings about setState on unmounted component.",
            "parentId": "undefined",
            "updatedAt": "2026-01-02T21:05:27.974Z"
          },
          {
            "id": 5,
            "title": "Remove Custom Implementations and Verify Completeness",
            "description": "Delete all custom timeout/AbortController/mounted logic. Perform final audit and update tests.",
            "dependencies": [2, 3, 4],
            "details": "Remove redundant code. Ensure hooks/index.ts provides all functionality. Run code review checklist. Update component tests to verify hooks prevent memory leaks per original test strategy.",
            "status": "done",
            "testStrategy": "Full code review: No custom timeout/AbortController/useEffect cleanup remains. Component tests pass. E2E: Verify auth flow works without regressions.",
            "parentId": "undefined",
            "updatedAt": "2026-01-02T21:05:27.991Z"
          }
        ],
        "updatedAt": "2026-01-02T21:05:27.991Z"
      },
      {
        "id": "203",
        "title": "USER-TEST-1: User Validation Checkpoint 1",
        "description": "Manually test functionality from Tasks 187-191 (Foundation & Critical Fixes)",
        "details": "",
        "testStrategy": "",
        "status": "deferred",
        "dependencies": ["191"],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-02T20:33:24.037Z"
      },
      {
        "id": "204",
        "title": "USER-TEST-2: User Validation Checkpoint 2",
        "description": "Manually test functionality from Tasks 192-196 (httpOnly Cookie Implementation)",
        "details": "",
        "testStrategy": "",
        "status": "deferred",
        "dependencies": ["196"],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-02T20:33:24.055Z"
      },
      {
        "id": "205",
        "title": "USER-TEST-3: User Validation Checkpoint 3",
        "description": "Manually test functionality from Tasks 197-199 (Comprehensive Testing)",
        "details": "",
        "testStrategy": "",
        "status": "deferred",
        "dependencies": ["199"],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-02T20:33:24.070Z"
      },
      {
        "id": "206",
        "title": "USER-TEST-4: User Validation Checkpoint 4",
        "description": "Manually test functionality from Tasks 200-202 (Polish & Optimization)",
        "details": "",
        "testStrategy": "",
        "status": "deferred",
        "dependencies": ["202"],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-02T20:33:24.086Z"
      },
      {
        "id": "207",
        "title": "Install Project Dependencies",
        "description": "Install new libraries required for the multi-agent system integration including LangChain, LangGraph, BullMQ, and Pino.",
        "details": "Execute 'npm install @langchain/core @langchain/langgraph @langchain/ollama @langchain/google-genai @langchain/groq bullmq pino'. Update package.json to ensure versions align with PRD specifications (LangGraph 0.2.x, BullMQ 5.x). Ensure 'engines' field in package.json is compatible with these libraries.",
        "testStrategy": "Run 'npm list' for each package to verify correct version installation. Run a smoke test by importing LangGraph in a script.",
        "priority": "high",
        "dependencies": [],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:39.618Z"
      },
      {
        "id": "208",
        "title": "Ollama Infrastructure Setup Script",
        "description": "Create a shell script to automate the provisioning of the Ollama server and download required models.",
        "details": "Create a script 'scripts/setup-ollama.sh' that: 1. Checks if Ollama is installed. 2. Pulls llama3.2:8b, mistral:7b, and phi3:mini. 3. Configures environment variables for OLLAMA_HOST and model aliases. Implement a health check utility to verify Ollama accessibility.",
        "testStrategy": "Execute the script on a development machine and verify using 'ollama list' that all three models are present and the health check utility returns 200.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:12:04.488Z"
      },
      {
        "id": "209",
        "title": "LangGraph Workflow Framework Skeleton",
        "description": "Initialize the core LangGraph structure and state management for the document processing pipeline.",
        "details": "Define the 'DocumentState' interface in 'src/multiagent/state.ts' including fields for document metadata, extracted data, classification, confidence scores, and processing logs. Create a base StateGraph instance in 'src/multiagent/workflow.ts'.",
        "testStrategy": "Unit test 'state.ts' to ensure state updates follow LangGraph immutability patterns using basic transition functions.",
        "priority": "high",
        "dependencies": ["207"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:21.189Z"
      },
      {
        "id": "210",
        "title": "Database Schema Extension for Multi-Agent State",
        "description": "Update the Prisma schema to support persistence for the multi-agent system, A/B testing, and shadow mode.",
        "details": "Add models to 'schema.prisma': MultiAgentProcessing (link to job ID, status), Checkpoint (binary state storage for LangGraph), ABTestAssignment (userId, variant, timestamp), UserFeedback (rating, comments), and ProcessingComparison (legacy vs multi-agent field diffs). Run 'prisma migrate dev'.",
        "testStrategy": "Verify database tables exist in PostgreSQL using 'prisma studio' and check the generated Prisma client for the new models.",
        "priority": "high",
        "dependencies": [],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:52.571Z"
      },
      {
        "id": "211",
        "title": "Feature Flag System Implementation",
        "description": "Implement a robust feature flag service to handle gradual rollout phases (Shadow, A/B, Primary).",
        "details": "Create 'src/services/FeatureFlagService.ts'. Implement logic to evaluate flags based on user context or random sampling: 'shadow-mode', 'multiagent-ab-test', 'multiagent-primary'. Use Prisma to store/retrieve flag configurations for runtime overrides.",
        "testStrategy": "Unit test FeatureFlagService to ensure 'multiagent-ab-test' returns true/false according to defined percentages and remains sticky for the same user.",
        "priority": "high",
        "dependencies": ["210"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:21.206Z"
      },
      {
        "id": "212",
        "title": "Migrate PoC Code to Main Repository",
        "description": "Refactor and move existing PoC agent logic into the quikadmin/src/multiagent directory.",
        "details": "Copy agent logic from PoC. Refactor to use current project logging (Pino) and error handling patterns. Update import paths to match 'quikadmin' structure. Resolve any TypeScript 'any' types introduced during PoC.",
        "testStrategy": "Run 'tsc' to ensure no compilation errors in the newly migrated files. Execute basic unit tests for individual agent utility functions.",
        "priority": "high",
        "dependencies": ["207", "209"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:39.636Z"
      },
      {
        "id": "213",
        "title": "BullMQ Multi-Agent Queue Initialization",
        "description": "Configure a new BullMQ instance to handle high-complexity multi-agent processing jobs separate from the legacy queue.",
        "details": "Create 'src/queues/multiagent.queue.ts'. Initialize BullMQ with the existing Upstash Redis connection. Configure worker options including concurrency limits (based on VRAM availability) and advanced retry strategies (exponential backoff).",
        "testStrategy": "Verify the queue connects to Redis using the BullMQ dashboard or by checking Redis keys 'bull:multiagent:*' via redis-cli.",
        "priority": "high",
        "dependencies": ["210"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:21.222Z"
      },
      {
        "id": "214",
        "title": "Document Classification Agent (Phi-3)",
        "description": "Implement the classification node using the Phi-3 Mini model for fast document type identification.",
        "details": "Implement 'classifyNode' in 'src/multiagent/nodes/classifier.ts'. Use @langchain/ollama to prompt Phi-3 with document snippets. Logic should output high-level categories (e.g., Invoice, ID, Contract). Set a confidence threshold for auto-routing.",
        "testStrategy": "Pass five different document text samples to the classifier and verify 100% accuracy for standard types.",
        "priority": "high",
        "dependencies": ["212"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:39.651Z"
      },
      {
        "id": "215",
        "title": "Extraction and Mapping Agents (Llama 8B / Mistral)",
        "description": "Implement extraction nodes using Llama 3.2 8B and field mapping nodes using Mistral 7B.",
        "details": "Create 'extractNode' and 'mapNode'. Extraction node uses Llama 8B for raw JSON output from OCR text. Mapping node uses Mistral to align extracted keys with the standard Prisma schema. Use JSON mode in LLM calls for structured output.",
        "testStrategy": "Compare extraction output against a ground truth JSON for a sample invoice and verify mapping accuracy.",
        "priority": "high",
        "dependencies": ["212"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:39.665Z"
      },
      {
        "id": "216",
        "title": "QA and Error Recovery Agents",
        "description": "Implement the QA agent (Llama 8B) for validation and Error Recovery agent for self-correction.",
        "details": "'qaNode' validates extraction against business rules (e.g., date formats, total sum math). 'errorRecoverNode' identifies specific failures and modifies prompts to re-attempt extraction/mapping. Integrate loop-back logic in LangGraph.",
        "testStrategy": "Inject a deliberate extraction error (e.g., mismatched total) and verify the QA node catches it and triggers the Recovery node.",
        "priority": "high",
        "dependencies": ["212"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:39.682Z"
      },
      {
        "id": "217",
        "title": "LangGraph Orchestrator Workflow Assembly",
        "description": "Assemble all agent nodes into a functional directed graph with conditional routing.",
        "details": "In 'src/multiagent/workflow.ts', connect nodes: classifier -> extractor -> mapper -> qa. Add conditional edges based on QA results (pass to finish, fail to errorRecover). Implement persistence using the Prisma-backed Checkpoint model.",
        "testStrategy": "Trace a full execution from classification to finish using a mock document and ensure all nodes are visited in order.",
        "priority": "high",
        "dependencies": ["214", "215", "216"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:21.237Z"
      },
      {
        "id": "218",
        "title": "Multi-Agent Queue Worker Service",
        "description": "Implement the BullMQ worker that executes the LangGraph workflow for each job.",
        "details": "Create 'src/workers/multiagent.worker.ts'. On job receive: 1. Fetch document from DB. 2. Initialize LangGraph state. 3. Execute workflow. 4. Update job progress in Redis/DB. 5. Emit 'processing:complete' event via RealtimeService.",
        "testStrategy": "Manually add a job to the multiagent queue and monitor logs to ensure the workflow completes and updates the database record.",
        "priority": "high",
        "dependencies": ["213", "217"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:39.697Z"
      },
      {
        "id": "219",
        "title": "Shadow Mode Logic Implementation",
        "description": "Hook into the existing document upload process to trigger the multi-agent pipeline in parallel with legacy processing.",
        "details": "In the main document controller, check 'shadow-mode' flag. If enabled, fire a non-blocking request to the multiagent-queue after the legacy queue job is dispatched. Do not wait for response to ensure zero latency impact on legacy path.",
        "testStrategy": "Upload a document and verify that two separate jobs are created: one in the Bull (Legacy) queue and one in the BullMQ (Multi-Agent) queue.",
        "priority": "medium",
        "dependencies": ["211", "218"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:21.253Z"
      },
      {
        "id": "220",
        "title": "Comparison Analytics Service",
        "description": "Develop a service to compare extraction results between legacy and multi-agent pipelines for accuracy validation.",
        "details": "Create 'src/services/ComparisonService.ts'. Logic should: 1. Wait for both pipelines to finish. 2. Fetch results. 3. Perform field-by-field diffing. 4. Calculate confidence delta. 5. Store report in 'ProcessingComparison' table.",
        "testStrategy": "Trigger a dual-process run and verify that a record is created in 'ProcessingComparison' with populated diff JSON.",
        "priority": "medium",
        "dependencies": ["219"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:21.267Z"
      },
      {
        "id": "221",
        "title": "A/B Test Routing Engine",
        "description": "Implement the logic to route a percentage of live traffic to the multi-agent system as the primary source of truth.",
        "details": "Modify document processing entry point. If 'multiagent-ab-test' is active and user is assigned to 'variant-b', skip the legacy pipeline and route exclusively to the multi-agent queue. Include fallback logic to legacy if the multi-agent system fails or times out.",
        "testStrategy": "Simulate 100 requests with a 10% A/B split and verify that approximately 10 requests are routed to the Multi-Agent pipeline.",
        "priority": "medium",
        "dependencies": ["211"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:21.282Z"
      },
      {
        "id": "222",
        "title": "Admin Control and Stats Endpoints",
        "description": "Create API endpoints for managing feature flags and viewing performance metrics.",
        "details": "Implement GET/PUT '/api/admin/ab-test/config' to update percentages. Implement GET '/api/admin/ab-test/stats' to aggregate data from 'ProcessingComparison' and 'UserFeedback' models. Restricted to 'admin' role.",
        "testStrategy": "Test endpoints with an admin JWT and verify they successfully update feature flag configurations in the database.",
        "priority": "medium",
        "dependencies": ["221"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:21.297Z"
      },
      {
        "id": "223",
        "title": "Cloud LLM Fallback Mechanism",
        "description": "Implement automatic failover to Gemini or Groq APIs when the local Ollama server is unavailable or slow.",
        "details": "Wrap Ollama calls in a 'ReliableLLM' service. Implement a circuit breaker pattern. If Ollama fails, switch to @langchain/google-genai or @langchain/groq using environment-stored API keys. Ensure identical prompt formatting across models.",
        "testStrategy": "Shut down the local Ollama service and verify that document processing continues using the Gemini API as a fallback.",
        "priority": "medium",
        "dependencies": ["207"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:52.586Z"
      },
      {
        "id": "224",
        "title": "Observability and Structured Logging",
        "description": "Integrate Pino logging and custom metrics for deep visibility into agent performance.",
        "details": "Implement structured logging with correlation IDs across all nodes. Export metrics for 'processing_time_per_node', 'llm_token_count', and 'agent_retry_count'. Configure Pino to omit any PII from logs.",
        "testStrategy": "Examine log output in the console to ensure structured JSON format and confirm no sensitive data (like user names/emails) is logged.",
        "priority": "medium",
        "dependencies": ["207"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:52.602Z"
      },
      {
        "id": "225",
        "title": "User Feedback Collection API",
        "description": "Implement endpoints to collect and store user feedback on processing accuracy for A/B testing evaluation.",
        "details": "Create POST '/api/feedback/processing' endpoint. Schema: jobId, accuracyRating (1-5), isCorrect (bool), userComments. Associate feedback with the 'ABTestAssignment' to differentiate between legacy and multi-agent satisfaction.",
        "testStrategy": "Submit a mock feedback request and verify the record is correctly linked to the processing job and test variant in the database.",
        "priority": "low",
        "dependencies": ["210"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:21.313Z"
      },
      {
        "id": "226",
        "title": "Final Integration and E2E Testing",
        "description": "Perform comprehensive end-to-end testing of the entire multi-agent pipeline under load.",
        "details": "Write Playwright/Jest E2E tests simulating document uploads across all phases (Shadow, A/B). Conduct a load test to ensure '100 concurrent jobs' requirement is met without VRAM exhaustion. Verify fallback logic triggers correctly.",
        "testStrategy": "Run the full suite of E2E tests in a staging environment. Verify that the final 'Success Metrics' (latency <30s) are met during a 50-document burst.",
        "priority": "medium",
        "dependencies": ["218", "223"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:55:07.779Z"
      },
      {
        "id": "227",
        "title": "Security: Remove Authentication Bypass in MultiAgent-PoC",
        "description": "Remove the hardcoded authentication bypass in the PoC middleware to ensure all requests are authenticated before processing.",
        "details": "Locate 'IntelliFill-MultiAgent-PoC/src/server/middleware/apiKeyAuth.ts'. Identify the logic on lines 37-41 that returns 'next()' regardless of API key validity. Remove this block to enforce a 'fail-closed' security posture. \n\nPseudo-code:\n// Before\nif (process.env.NODE_ENV === 'development') { return next(); }\n// After\nif (!apiKey || !isValid(apiKey)) { return res.status(401).send('Unauthorized'); }",
        "testStrategy": "Attempt to access PoC endpoints without an API key or with an invalid key. Verify that the server returns a 401 Unauthorized status instead of proceeding.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-02T19:06:23.355Z"
      },
      {
        "id": "228",
        "title": "Security: Implement Prompt Injection Sanitization Strategy",
        "description": "Add a sanitization utility function for document text before it is interpolated into LLM prompts to prevent prompt injection attacks. Create a simple, single-function solution (~10 lines) without Strategy pattern, interfaces, or classes.",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "details": "SIMPLIFIED PER PRD v2.0: Create a single utility function in 'quikadmin/src/utils/sanitizeLLMInput.ts'.\n\nImplementation:\n```typescript\n/**\n * Sanitizes user-provided text before interpolating into LLM prompts.\n * Removes template injections, bracket injections, and prompt override attempts.\n */\nexport function sanitizeLLMInput(input: string): string {\n  if (!input || typeof input !== 'string') return '';\n  \n  return input\n    // Remove template injection patterns ({{...}}, {%...%}, ${...})\n    .replace(/\\{\\{[^}]*\\}\\}/g, '')\n    .replace(/\\{%[^%]*%\\}/g, '')\n    .replace(/\\$\\{[^}]*\\}/g, '')\n    // Remove XML-style bracket injections (<system>, </system>, etc.)\n    .replace(/<\\/?\\s*(system|user|assistant|prompt|instruction)[^>]*>/gi, '')\n    // Remove common prompt override phrases (case-insensitive)\n    .replace(/ignore\\s+(all\\s+)?(previous|prior|above)\\s+(instructions?|prompts?)/gi, '')\n    .replace(/disregard\\s+(all\\s+)?(previous|prior|above)\\s+(instructions?|prompts?)/gi, '')\n    .replace(/forget\\s+(all\\s+)?(previous|prior|above)\\s+(instructions?|prompts?)/gi, '')\n    // Clean up extra whitespace\n    .replace(/\\s+/g, ' ')\n    .trim();\n}\n```\n\nFile location: quikadmin/src/utils/sanitizeLLMInput.ts\n\nIntegration points:\n- Used by multiagent workflow nodes in quikadmin/src/multiagent/workflow.ts before passing document text to LLM prompts\n- Follows existing utility pattern in quikadmin/src/utils/ (similar to piiSanitizer.ts but simpler)\n- NO Strategy pattern, NO interface, NO class - just ONE exported function",
        "testStrategy": "Create unit tests in quikadmin/src/utils/__tests__/sanitizeLLMInput.test.ts:\n\n1. Template injection tests:\n   - '{{system}}' → ''\n   - 'Hello {{ignore}}' → 'Hello'\n   - 'Text ${variable} more' → 'Text more'\n   - '{%template%}' → ''\n\n2. Bracket injection tests:\n   - '<system>override</system>' → 'override'\n   - '<SYSTEM>bypass</SYSTEM>' → 'bypass'\n   - '</assistant>' → ''\n   - '<prompt>' → ''\n\n3. Prompt override tests:\n   - 'Ignore previous instructions' → ''\n   - 'IGNORE ALL PRIOR PROMPTS' → ''\n   - 'disregard above instructions' → ''\n   - 'forget previous prompt' → ''\n\n4. Edge cases:\n   - null/undefined → ''\n   - Empty string → ''\n   - Normal text 'Hello world' → 'Hello world'\n   - Mixed: 'Valid {{inject}} text <system>bad</system>' → 'Valid text bad'\n\n5. Whitespace normalization:\n   - 'Multiple   spaces' → 'Multiple spaces'",
        "subtasks": [
          {
            "id": 1,
            "title": "Create sanitizeLLMInput.ts utility file",
            "description": "Create the sanitizeLLMInput.ts file in quikadmin/src/utils/ with the sanitizeLLMInput function",
            "dependencies": [],
            "details": "Create quikadmin/src/utils/sanitizeLLMInput.ts with a single exported function that:\n1. Handles null/undefined/non-string input by returning empty string\n2. Removes template injections: {{...}}, {%...%}, ${...}\n3. Removes XML bracket injections: <system>, </system>, <user>, <assistant>, <prompt>, <instruction>\n4. Removes prompt override phrases: 'ignore previous instructions', 'disregard prior prompts', etc.\n5. Normalizes whitespace and trims\n\nKeep it simple - approximately 10-15 lines of actual logic.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Write unit tests for sanitizeLLMInput",
            "description": "Create comprehensive unit tests in quikadmin/src/utils/__tests__/sanitizeLLMInput.test.ts",
            "dependencies": [],
            "details": "Test all sanitization patterns:\n- Template injections ({{...}}, {%...%}, ${...})\n- Bracket injections (<system>, </system>, <user>, etc.)\n- Prompt override phrases (ignore previous, disregard, forget)\n- Edge cases (null, undefined, empty string, normal text)\n- Whitespace normalization\n- Combined attack patterns\n\nFollow existing test patterns in quikadmin/src/utils/__tests__/piiSanitizer.test.ts",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Document usage and integration points",
            "description": "Add JSDoc comments to the function and document integration with multiagent workflow",
            "dependencies": [],
            "details": "Add clear JSDoc documentation explaining:\n- Purpose: Prevent prompt injection attacks\n- When to use: Before interpolating user/document text into LLM prompts\n- Integration: Used by multiagent workflow nodes (classifier, extractor, mapper, qa)\n- Example usage in workflow.ts nodes\n\nNote: Actual integration into workflow.ts is a separate task - this just documents how it should be used.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T19:41:00.776Z"
      },
      {
        "id": "229",
        "title": "Dependency Alignment: Express Downgrade and Tesseract Upgrade",
        "description": "Align Express and Tesseract versions across the project to ensure compatibility with the existing IntelliFill environment.",
        "details": "1. Downgrade PoC package.json Express from 5.x to 4.18.x. \n2. Upgrade Tesseract.js in both PoC and target codebase to 7.x. \n3. Update 'quikadmin/package.json' and 'IntelliFill-MultiAgent-PoC/package.json'. \n4. Audit async error handlers in PoC code since Express 4 doesn't support async errors by default (wrap in try-catch/next).",
        "testStrategy": "Run 'npm install' and ensure no peer dependency conflicts. Verify Tesseract 7 initialization in a small script.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-02T19:34:27.561Z"
      },
      {
        "id": "230",
        "title": "Database Schema: MultiAgentProcessingRecord Model",
        "description": "Add a new Prisma model to track the status and results of multi-agent document processing tasks.",
        "details": "Update 'schema.prisma' with the 'MultiAgentProcessingRecord' model as specified in the PRD. \n\nPseudo-code:\nmodel MultiAgentProcessingRecord {\n  id String @id @default(uuid())\n  documentId String\n  userId String\n  status String // pending, processing, completed, failed\n  extractedData Json?\n  processingTimeMs Int?\n  error String?\n  createdAt DateTime @default(now())\n  completedAt DateTime?\n  @@index([documentId])\n  @@index([userId])\n}",
        "testStrategy": "Run 'prisma migrate dev' to apply changes. Verify table creation in the database using a GUI or Prisma Studio.",
        "priority": "medium",
        "dependencies": ["229"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:21.329Z"
      },
      {
        "id": "231",
        "title": "Core Integration: Define MultiAgent Interfaces",
        "description": "Create the core interfaces for document processing following the program-to-interfaces principle.",
        "details": "Create 'quikadmin/src/services/multiagent/interfaces.ts'. \n\nPseudo-code:\nexport interface IProcessingResult { success: boolean; data?: any; error?: string; }\nexport interface IDocumentProcessor {\n  process(documentId: string, userId: string): Promise<IProcessingResult>;\n}",
        "testStrategy": "No execution. Static type check using TypeScript compiler.",
        "priority": "medium",
        "dependencies": [],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:21.345Z"
      },
      {
        "id": "232",
        "title": "Service: Create MultiAgentAdapter Implementation",
        "description": "Implement the Adapter pattern to bridge the MultiAgent-PoC logic with the IntelliFill IDocumentProcessor interface.",
        "details": "Location: 'quikadmin/src/services/multiagent/MultiAgentAdapter.ts'. This service will wrap the PoC's main entry point, converting its output format into the IntelliFill format.\n\nPseudo-code:\nclass MultiAgentAdapter implements IDocumentProcessor {\n  async process(docId: string, userId: string) {\n    const pocResult = await pocRunner.run(docId);\n    return { success: true, data: this.mapToStandard(pocResult) };\n  }\n  private mapToStandard(pocData: any) { /* mapping logic */ }\n}",
        "testStrategy": "Unit test 'process' method with mocked PoC runner to ensure it returns correctly mapped data objects.",
        "priority": "medium",
        "dependencies": ["231", "228"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:21.360Z"
      },
      {
        "id": "233",
        "title": "Service: Implement ProcessingService with Strategy Pattern",
        "description": "Create a ProcessingService that allows switching between legacy and multi-agent processing strategies.",
        "details": "Location: 'quikadmin/src/services/ProcessingService.ts'. \n\nPseudo-code:\nclass ProcessingService {\n  private strategy: IDocumentProcessor;\n  constructor(strategy: IDocumentProcessor) { this.strategy = strategy; }\n  setStrategy(strategy: IDocumentProcessor) { this.strategy = strategy; }\n  async execute(docId: string, userId: string) { return this.strategy.process(docId, userId); }\n}",
        "testStrategy": "Verify that swapping strategies at runtime changes the execution path using unit tests.",
        "priority": "medium",
        "dependencies": ["232"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T18:42:21.374Z"
      },
      {
        "id": "234",
        "title": "Queue: Register multiAgentProcess Job Type",
        "description": "Update the existing knowledgeQueue to support the new multi-agent processing job type.",
        "details": "Modify 'quikadmin/src/queues/knowledgeQueue.ts'. \n1. Add 'multiAgentProcess' to the KnowledgeJobType union. \n2. Add a helper function 'addMultiAgentProcessJob(data)' using the Bull queue instance.\n\nPseudo-code:\nexport type KnowledgeJobType = 'single' | 'batch' | 'multiAgentProcess';\nexport const addMultiAgentProcessJob = (data: any) => knowledgeQueue.add('multiAgentProcess', data);",
        "testStrategy": "Call 'addMultiAgentProcessJob' in a test script and verify that the job appears in the Bull queue (e.g., via Bull-Board or Redis CLI).",
        "priority": "medium",
        "dependencies": ["233"],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-02T20:10:33.654Z"
      },
      {
        "id": "235",
        "title": "Worker: MultiAgent Queue Processor",
        "description": "Add inline queue processor to multiagentQueue.ts that handles 'multiAgentProcess' jobs using the LangGraph processDocument workflow and updates the Document model.",
        "status": "done",
        "dependencies": ["234"],
        "priority": "medium",
        "details": "**SIMPLIFIED PER PRD v2.0**: No separate worker file, no Command pattern.\n\n**Location**: `quikadmin/src/queues/multiagentQueue.ts` (existing file)\n\n**Implementation**:\n1. Add a BullMQ Worker directly in `multiagentQueue.ts`\n2. Import `processDocument` from `../multiagent`\n3. Create inline processor that:\n   - Updates Document status to 'PROCESSING' on job start\n   - Calls `processDocument(job.data.documentId, job.data.userId, job.id, job.data.filePath, job.data.fileName, job.data.fileType, job.data.fileSize)`\n   - On success: Update Document with extracted data, confidence, processedAt, status='COMPLETED'\n   - On failure: Update Document status='FAILED' with error message\n\n**Code structure**:\n```typescript\n// In multiagentQueue.ts, after queue initialization\nimport { processDocument } from '../multiagent';\n\nlet multiagentWorker: Worker<MultiAgentProcessingJob, MultiAgentProcessingResult> | null = null;\n\nexport async function startMultiagentWorker(): Promise<void> {\n  if (!isMultiagentQueueAvailable()) {\n    logger.warn('Cannot start worker - queue not available');\n    return;\n  }\n\n  multiagentWorker = new Worker<MultiAgentProcessingJob, MultiAgentProcessingResult>(\n    'multiagent-processing',\n    async (job) => {\n      const { documentId, userId, filePath, fileName, fileType, fileSize } = job.data;\n      \n      // Update status to processing\n      await prisma.document.update({\n        where: { id: documentId },\n        data: { status: 'PROCESSING' },\n      });\n\n      try {\n        // Execute LangGraph workflow\n        const result = await processDocument(\n          documentId,\n          userId,\n          job.id || `job-${Date.now()}`,\n          filePath,\n          fileName,\n          fileType,\n          fileSize\n        );\n\n        // Update document with results\n        await prisma.document.update({\n          where: { id: documentId },\n          data: {\n            status: result.results.success ? 'COMPLETED' : 'FAILED',\n            extractedData: result.results.finalData,\n            confidence: result.results.confidence.overall,\n            processedAt: new Date(),\n          },\n        });\n\n        return {\n          documentId,\n          success: result.results.success,\n          extractedData: result.results.finalData,\n          confidence: result.results.confidence.overall,\n          processingTimeMs: result.results.processingTimeMs,\n        };\n      } catch (error) {\n        await prisma.document.update({\n          where: { id: documentId },\n          data: {\n            status: 'FAILED',\n            extractedData: { error: error instanceof Error ? error.message : 'Unknown error' },\n          },\n        });\n        throw error;\n      }\n    },\n    {\n      connection: redisConfig,\n      concurrency: 2, // Limit based on VRAM availability\n    }\n  );\n\n  multiagentWorker.on('completed', (job, result) => {\n    logger.info('Multi-agent job completed by worker', { jobId: job.id, documentId: result.documentId });\n  });\n\n  multiagentWorker.on('failed', (job, error) => {\n    logger.error('Multi-agent job failed', { jobId: job?.id, error: error.message });\n  });\n\n  logger.info('Multi-agent worker started');\n}\n```\n\n**Files to modify**:\n- `quikadmin/src/queues/multiagentQueue.ts` - Add Worker implementation inline\n\n**NO separate files needed**:\n- ~~`quikadmin/src/workers/multiAgentProcessor.ts`~~ (not needed per PRD v2.0)\n- ~~Command pattern~~ (not needed per PRD v2.0)\n- ~~MultiAgentProcessingRecord model~~ (use existing Document model)",
        "testStrategy": "1. Unit test: Mock the `processDocument` function and verify worker calls it with correct parameters\n2. Integration test: Add a job via `enqueueMultiagentProcessing()` and verify:\n   - Document status changes to 'PROCESSING' immediately\n   - `processDocument` is invoked with correct job data\n   - Document status changes to 'COMPLETED' with extractedData populated\n3. Error handling test: Simulate `processDocument` failure and verify Document status='FAILED'\n4. Concurrency test: Verify only 2 jobs process simultaneously",
        "subtasks": [
          {
            "id": 1,
            "title": "Import processDocument and Worker from dependencies",
            "description": "Add necessary imports to multiagentQueue.ts for the LangGraph workflow and BullMQ Worker",
            "dependencies": [],
            "details": "Add imports at top of multiagentQueue.ts:\n- `import { processDocument } from '../multiagent';`\n- Ensure `Worker` is imported from 'bullmq' (already imported but verify)\n- Add worker instance variable: `let multiagentWorker: Worker<...> | null = null;`",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement startMultiagentWorker function with inline processor",
            "description": "Create the worker function that processes multiagent jobs by calling processDocument and updating Document status",
            "dependencies": [],
            "details": "Implement `startMultiagentWorker()` function that:\n1. Creates BullMQ Worker with 'multiagent-processing' queue name\n2. Updates Document.status to 'PROCESSING' on job start\n3. Calls `processDocument(documentId, userId, jobId, filePath, fileName, fileType, fileSize)`\n4. On success: Updates Document with extractedData, confidence, processedAt, status='COMPLETED'\n5. On failure: Updates Document status='FAILED' with error in extractedData\n6. Uses concurrency: 2 to limit parallel processing",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add worker event handlers for logging",
            "description": "Attach event handlers to the worker for completed/failed job logging",
            "dependencies": [],
            "details": "Add event handlers to multiagentWorker:\n- `worker.on('completed', ...)` - Log success with jobId and documentId\n- `worker.on('failed', ...)` - Log error with jobId and error message\n- `worker.on('error', ...)` - Log worker-level errors",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add closeMultiagentWorker function for graceful shutdown",
            "description": "Implement cleanup function to gracefully close the worker on process termination",
            "dependencies": [],
            "details": "Add `closeMultiagentWorker()` function that:\n1. Calls `multiagentWorker.close()` if worker exists\n2. Sets `multiagentWorker = null`\n3. Update existing `closeMultiagentQueue()` to also call `closeMultiagentWorker()`\n4. Ensure SIGTERM/SIGINT handlers close both queue and worker",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Export worker functions from multiagentQueue.ts",
            "description": "Export the new worker functions for use in app initialization",
            "dependencies": [],
            "details": "Add exports:\n- `export { startMultiagentWorker, closeMultiagentWorker }`\n- Update module exports if needed for proper initialization flow\n- Document that `startMultiagentWorker()` should be called after `initializeMultiagentQueue()`",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-02T20:47:27.453Z"
      },
      {
        "id": "236",
        "title": "API: Implementation of MultiAgent Endpoints",
        "description": "Create the new API routes for initiating multi-agent processing and checking status.",
        "details": "Location: 'quikadmin/src/api/multiagent.routes.ts'. \n1. POST '/api/process/multiagent': Creates record, adds job to queue. \n2. GET '/api/process/multiagent/:jobId/status': Returns current DB record status.\n\nPseudo-code:\nrouter.post('/multiagent', async (req, res) => {\n  const record = await prisma.multiAgentProcessingRecord.create({ data: { ... } });\n  await addMultiAgentProcessJob({ recordId: record.id, ... });\n  res.json({ jobId: record.id });\n});",
        "testStrategy": "Use Postman or Curl to hit POST /api/process/multiagent. Verify 200 OK and receipt of jobId. Hit GET status endpoint with jobId to verify 'pending' state.",
        "priority": "medium",
        "dependencies": ["235"],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-02T20:51:03.900Z"
      },
      {
        "id": "237",
        "title": "Testing: Unit Tests for Integration Components",
        "description": "Write comprehensive unit tests for the Adapter, Strategy, and Sanitizer components.",
        "details": "Target 80% coverage. Focus on 'MultiAgentAdapter.ts' (mapping accuracy), 'Sanitizer.ts' (injection prevention), and 'ProcessingService.ts' (strategy switching logic). Use Jest or Mocha as per project standards.",
        "testStrategy": "Run 'npm run test:unit' and review the coverage report to ensure target percentage is met for the new files in 'quikadmin/src/services/multiagent'.",
        "priority": "medium",
        "dependencies": ["232", "233"],
        "status": "cancelled",
        "subtasks": [],
        "updatedAt": "2026-01-02T20:52:08.861Z"
      },
      {
        "id": "238",
        "title": "Testing: Integration and Smoke Tests",
        "description": "Perform end-to-end integration testing of the document processing pipeline using real document samples.",
        "details": "1. Run integration tests covering the Queue -> Worker -> DB flow. \n2. Perform smoke tests with three document types: passport, invoice, and ID card. \n3. Validate that processing time for P95 is under 30 seconds.",
        "testStrategy": "Trigger the full flow via API and monitor logs/database until completion. Use a timer to measure performance and verify extracted JSON accuracy for each document type.",
        "priority": "medium",
        "dependencies": ["236", "237"],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-02T20:56:54.777Z"
      },
      {
        "id": "239",
        "title": "Add multiAgentResult Column to Document Model",
        "description": "Add a single optional Json column `multiAgentResult` to the existing Document model in the Prisma schema to store multi-agent processing results alongside the legacy extractedData field.",
        "details": "## Implementation Steps\n\n### 1. Update Prisma Schema\nEdit `quikadmin/prisma/schema.prisma` and add the new column to the Document model (around line 315-316, after `extractedData`):\n\n```prisma\nmodel Document {\n  id                 String         @id @default(uuid())\n  userId             String\n  user               User           @relation(fields: [userId], references: [id], onDelete: Cascade)\n  fileName           String\n  fileType           String\n  fileSize           Int\n  storageUrl         String\n  status             DocumentStatus @default(PENDING)\n  extractedText      String?\n  extractedData      Json?\n  multiAgentResult   Json?          @map(\"multi_agent_result\")  // NEW: Multi-agent pipeline results\n  confidence         Float?\n  templateId         String?\n  template           Template?      @relation(fields: [templateId], references: [id])\n  processedAt        DateTime?\n  reprocessCount     Int            @default(0) @map(\"reprocess_count\")\n  lastReprocessedAt  DateTime?      @map(\"last_reprocessed_at\")\n  reprocessingHistory Json?         @map(\"reprocessing_history\")\n  createdAt          DateTime       @default(now())\n  updatedAt          DateTime       @updatedAt\n\n  @@map(\"documents\")\n}\n```\n\n### 2. Expected JSON Structure for multiAgentResult\nThe column should store data matching the `DocumentState.results` structure from `quikadmin/src/multiagent/types/state.ts`:\n\n```typescript\ninterface MultiAgentResult {\n  success: boolean;\n  finalData: Record<string, unknown>;  // Extracted fields\n  confidence: {\n    overall: number;  // 0-100\n    byField: Record<string, number>;\n  };\n  processingTimeMs: number;\n  needsReview: boolean;\n  reviewReasons: string[];\n  // Optional metadata\n  pipelineVersion?: string;\n  agentHistory?: Array<{\n    agent: string;\n    status: string;\n    processingTimeMs: number;\n  }>;\n}\n```\n\n### 3. Run Prisma Migration\nExecute the migration from the quikadmin directory:\n\n```bash\ncd quikadmin\nnpx prisma migrate dev --name add_multi_agent_result_to_document\n```\n\n### 4. Regenerate Prisma Client\nThe migration command automatically regenerates the client, but if needed:\n\n```bash\nnpx prisma generate\n```\n\n## Key Considerations\n\n- **Minimal Change**: This is a non-breaking additive change - existing code continues to work\n- **Column Mapping**: Use `@map(\"multi_agent_result\")` for snake_case in the database while keeping camelCase in TypeScript\n- **Nullable**: The `Json?` type ensures the column is nullable, so existing documents won't be affected\n- **No New Model**: Per requirements, this adds to the existing Document model rather than creating a new MultiAgentProcessingRecord model\n- **Relationship with Existing Models**: The `MultiAgentProcessing` model (line 650) already tracks job-level data separately - this column stores the final results directly on the Document for quick access",
        "testStrategy": "## Verification Steps\n\n### 1. Migration Success\n```bash\ncd quikadmin\nnpx prisma migrate dev --name add_multi_agent_result_to_document\n```\n- Confirm migration completes without errors\n- Check `.prisma/migrations/` for new migration file\n\n### 2. Database Verification\nUse Prisma Studio to verify:\n```bash\nnpx prisma studio\n```\n- Navigate to the `documents` table\n- Confirm `multi_agent_result` column exists\n- Verify column is nullable (NULL values allowed)\n- Verify column type is `jsonb` (PostgreSQL)\n\n### 3. TypeScript Type Check\n```bash\nnpm run typecheck\n# or\nnpx tsc --noEmit\n```\n- Ensure no TypeScript errors related to Prisma client\n- Verify `PrismaClient.document` type includes `multiAgentResult: Prisma.JsonValue | null`\n\n### 4. Test CRUD Operations\nCreate a simple test script or use Prisma Studio:\n```typescript\n// Test write\nawait prisma.document.update({\n  where: { id: 'test-doc-id' },\n  data: {\n    multiAgentResult: {\n      success: true,\n      finalData: { name: 'Test' },\n      confidence: { overall: 95, byField: {} },\n      processingTimeMs: 1500,\n      needsReview: false,\n      reviewReasons: []\n    }\n  }\n});\n\n// Test read\nconst doc = await prisma.document.findUnique({\n  where: { id: 'test-doc-id' },\n  select: { multiAgentResult: true }\n});\nconsole.log(doc?.multiAgentResult);\n```\n\n### 5. Existing Functionality Regression Test\n- Verify existing document upload/processing still works\n- Confirm `extractedData` field is unaffected\n- Run any existing document-related tests",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-02T19:47:25.245Z"
      },
      {
        "id": "240",
        "title": "Create MultiAgentService Thin Wrapper",
        "description": "Create a minimal MultiAgentService class in quikadmin/src/services/MultiAgentService.ts that sanitizes input and delegates to the multiagent PoC's CompatibilityLayer for document processing.",
        "details": "## Implementation Details\n\nCreate a thin wrapper service class (~30 lines) at `quikadmin/src/services/MultiAgentService.ts`:\n\n### File Structure\n```typescript\nimport { processDocument, DocumentState } from '../multiagent';\nimport { sanitizeLLMInput } from '../utils/sanitizeLLMInput';\n\nexport interface MultiAgentProcessInput {\n  documentId: string;\n  userId: string;\n  rawText: string;\n  jobId?: string;\n  filePath?: string;\n  fileName?: string;\n  fileType?: string;\n  fileSize?: number;\n}\n\nexport class MultiAgentService {\n  /**\n   * Process a document through the multi-agent pipeline.\n   * Sanitizes input before delegating to CompatibilityLayer.\n   */\n  async process(input: MultiAgentProcessInput): Promise<DocumentState> {\n    const sanitizedText = sanitizeLLMInput(input.rawText);\n    \n    return processDocument(\n      input.documentId,\n      input.userId,\n      input.jobId || `job-${Date.now()}`,\n      input.filePath || '',\n      input.fileName || 'unknown',\n      input.fileType || 'application/octet-stream',\n      input.fileSize || 0\n    );\n  }\n}\n```\n\n### Key Considerations\n\n1. **Import Path**: Use relative import from `../multiagent` which exports `processDocument` from `quikadmin/src/multiagent/index.ts`\n\n2. **Dependency on sanitizeLLMInput**: This utility must be created first (SEC-02 task) at `quikadmin/src/utils/sanitizeLLMInput.ts`\n\n3. **No Additional Abstractions**: Per the dev PRD, do NOT add:\n   - Strategy pattern\n   - Factory pattern\n   - Additional adapter layers\n   - Interface files (use types from multiagent module directly)\n\n4. **Type Reuse**: Import `DocumentState` from the multiagent module as the return type to maintain type safety without creating duplicate interfaces\n\n5. **Optional Fields**: The `jobId`, `filePath`, `fileName`, `fileType`, and `fileSize` parameters have sensible defaults for cases where only documentId, userId, and rawText are available\n\n### Why This Approach\n\n- **KISS Principle**: Single responsibility - sanitize and delegate\n- **YAGNI**: No unnecessary patterns or abstractions\n- **Uses Existing Infrastructure**: Leverages the already-implemented multiagent workflow\n- **Testable**: Easy to mock the `processDocument` function for unit testing",
        "testStrategy": "## Test Strategy\n\n### Unit Tests (quikadmin/src/services/__tests__/MultiAgentService.test.ts)\n\n1. **Input Sanitization Verification**\n   - Mock `sanitizeLLMInput` and `processDocument`\n   - Call `service.process()` with input containing injection patterns\n   - Verify `sanitizeLLMInput` was called with the raw text\n   - Verify `processDocument` received sanitized text\n\n2. **Delegation to processDocument**\n   - Mock `processDocument` to return a known `DocumentState`\n   - Call `service.process()` with valid input\n   - Verify all parameters are passed correctly to `processDocument`\n   - Verify the return value matches the mock result\n\n3. **Default Parameter Handling**\n   - Call `service.process()` with minimal input (only documentId, userId, rawText)\n   - Verify default values are used for optional fields\n\n4. **Error Propagation**\n   - Mock `processDocument` to throw an error\n   - Verify the error propagates correctly to the caller\n\n### Integration Tests\n\n1. **End-to-End Flow**\n   - Use real multiagent module (if Ollama is available in test environment)\n   - Process a small test document\n   - Verify DocumentState result structure\n\n### Test Commands\n```bash\n# Run unit tests\nnpm test -- --testPathPattern=\"MultiAgentService\"\n\n# Run with coverage\nnpm test -- --coverage --testPathPattern=\"MultiAgentService\"\n```\n\n### Expected Coverage: 90%+ for this service (it's a thin wrapper, so high coverage is easily achievable)",
        "status": "done",
        "dependencies": ["208"],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-02T19:51:36.976Z"
      },
      {
        "id": "241",
        "title": "Link MultiAgent-PoC as Local npm Package",
        "description": "Configure IntelliFill-MultiAgent-PoC as a local dependency in quikadmin/package.json using file: protocol or npm link, ensuring CompatibilityLayer is exported from the PoC package for import as @intellifill/multiagent-poc.",
        "details": "## Implementation Details\n\n### 1. Package Location Configuration\n\nThe MultiAgent-PoC must be accessible as a sibling directory to the IntelliFill project. Expected structure:\n```\nN:\\\n├── IntelliFill/\n│   └── quikadmin/\n│       └── package.json  ← Will reference PoC\n└── IntelliFill-MultiAgent-PoC/\n    ├── package.json      ← Must export CompatibilityLayer\n    └── src/\n        └── index.ts      ← Main entry with exports\n```\n\n### 2. Update PoC package.json\n\nEnsure the PoC package exports correctly:\n```json\n{\n  \"name\": \"@intellifill/multiagent-poc\",\n  \"version\": \"1.0.0\",\n  \"main\": \"dist/index.js\",\n  \"types\": \"dist/index.d.ts\",\n  \"exports\": {\n    \".\": {\n      \"import\": \"./dist/index.js\",\n      \"require\": \"./dist/index.js\",\n      \"types\": \"./dist/index.d.ts\"\n    }\n  }\n}\n```\n\n### 3. Create/Verify PoC Exports (src/index.ts)\n\nThe PoC must export CompatibilityLayer:\n```typescript\n// IntelliFill-MultiAgent-PoC/src/index.ts\nexport { CompatibilityLayer } from './compatibility/CompatibilityLayer';\nexport { DocumentState } from './types/state';\n// ... other needed exports\n```\n\n### 4. Add Local Dependency to quikadmin/package.json\n\n**Option A (Recommended): file: protocol**\n```json\n{\n  \"dependencies\": {\n    \"@intellifill/multiagent-poc\": \"file:../../IntelliFill-MultiAgent-PoC\"\n  }\n}\n```\n\n**Option B: npm link (development)**\n```bash\n# In PoC directory\ncd N:\\IntelliFill-MultiAgent-PoC\nnpm link\n\n# In quikadmin directory\ncd N:\\IntelliFill\\quikadmin\nnpm link @intellifill/multiagent-poc\n```\n\n### 5. Build PoC Before Linking\n\nThe PoC must be built before linking:\n```bash\ncd N:\\IntelliFill-MultiAgent-PoC\nnpm install\nnpm run build  # Generates dist/ with compiled JS\n```\n\n### 6. TypeScript Configuration\n\nUpdate quikadmin/tsconfig.json if needed:\n```json\n{\n  \"compilerOptions\": {\n    \"paths\": {\n      \"@intellifill/multiagent-poc\": [\"../../IntelliFill-MultiAgent-PoC/dist\"]\n    }\n  }\n}\n```\n\n### 7. Verify Import Works\n\nAfter linking, this import should work in quikadmin:\n```typescript\n// quikadmin/src/services/MultiAgentService.ts\nimport { CompatibilityLayer, DocumentState } from '@intellifill/multiagent-poc';\n```\n\n### 8. CompatibilityLayer Interface Requirements\n\nThe CompatibilityLayer class must expose:\n```typescript\nexport class CompatibilityLayer {\n  async processDocument(input: {\n    documentId: string;\n    userId: string;\n    rawText: string;\n  }): Promise<ProcessingResult>;\n}\n```\n\n### 9. Handling npm vs pnpm/bun\n\nSince quikadmin uses npm (per package.json scripts), use file: protocol which is npm-native. For bun-based frontend, ensure compatibility:\n```bash\n# In quikadmin\nnpm install  # Will resolve file: dependency\n```\n\n### 10. .gitignore Consideration\n\nAdd node_modules linking artifacts if using npm link:\n```gitignore\n# Local package links\n.pnp.*\n```",
        "testStrategy": "## Verification Steps\n\n### 1. Package Resolution Test\n```bash\ncd N:\\IntelliFill\\quikadmin\nnpm ls @intellifill/multiagent-poc\n```\nExpected: Shows local file path, no errors\n\n### 2. Import Verification\nCreate a test file:\n```typescript\n// quikadmin/src/__test_import__.ts\nimport { CompatibilityLayer } from '@intellifill/multiagent-poc';\nconst layer = new CompatibilityLayer();\nconsole.log('Import successful:', typeof layer.processDocument === 'function');\n```\nRun: `npx ts-node src/__test_import__.ts`\nExpected: \"Import successful: true\"\n\n### 3. TypeScript Compilation Check\n```bash\ncd N:\\IntelliFill\\quikadmin\nnpx tsc --noEmit\n```\nExpected: No errors related to @intellifill/multiagent-poc imports\n\n### 4. Build Verification\n```bash\nnpm run build\n```\nExpected: Build completes without module resolution errors\n\n### 5. Runtime Test\n```bash\nnpm run dev\n# In another terminal:\ncurl -X POST http://localhost:3002/api/health\n```\nExpected: Server starts without import errors\n\n### 6. Verify CompatibilityLayer Export\n```bash\nnode -e \"const pkg = require('@intellifill/multiagent-poc'); console.log('CompatibilityLayer:', typeof pkg.CompatibilityLayer)\"\n```\nExpected: \"CompatibilityLayer: function\"\n\n### 7. Clean Install Test\n```bash\nrm -rf node_modules\nnpm install\nnpm run build\n```\nExpected: Fresh install correctly resolves local package",
        "status": "done",
        "dependencies": ["208"],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-02T20:05:08.556Z"
      },
      {
        "id": "242",
        "title": "Establish Test Fixture Infrastructure",
        "description": "Create and organize the physical files and mock data structures required for comprehensive testing across unit and E2E layers.",
        "details": "Populate e2e/fixtures/ with test-passport.pdf (with MRZ), test-emirates-id.jpg, test-trade-license.pdf, test-visa.pdf, test-corrupted.pdf, and visa-application-template.pdf. Ensure large-document-50pages.pdf is optimized for performance tests. Create a mock document generator utility for dynamic field injection in unit tests.",
        "testStrategy": "Verify file existence and readability using a pre-test script. Validate that the corrupted PDF actually triggers parsing errors in a basic node-pdf-reader script.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize Directory Structure and Static Image/PDF Fixtures",
            "description": "Create the fixture directory and populate it with standard binary test files for passports and identity cards.",
            "dependencies": [],
            "details": "Create the 'e2e/fixtures' directory. Populate it with 'test-passport.pdf' (containing a valid MRZ string), 'test-emirates-id.jpg' (high-resolution sample), and 'test-trade-license.pdf'. Ensure these files follow standard naming conventions for automated retrieval.",
            "status": "pending",
            "testStrategy": "Verify the presence of files using a filesystem check and validate file headers (magic numbers) to ensure they are valid PDF/JPG files.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Generate Specialized PDF Templates and Performance Documents",
            "description": "Create fillable PDF forms and large multi-page documents to test form-filling logic and processing performance.",
            "dependencies": [1],
            "details": "Create 'visa-application-template.pdf' with fillable form fields (Name, Date, Checkboxes). Generate 'large-document-50pages.pdf' containing approximately 50 pages of mixed text/images for OCR benchmarking. Create 'test-corrupted.pdf' by intentionally damaging the PDF trailer or xref table.",
            "status": "pending",
            "testStrategy": "Use a PDF inspector tool or library like pdf-lib to verify that 'visa-application-template.pdf' contains interactive form fields and that 'test-corrupted.pdf' fails to open in a standard parser.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Mock Document Generator Utility",
            "description": "Develop a TypeScript utility to programmatically generate dynamic mock text and document structures for unit tests.",
            "dependencies": [],
            "details": "Create 'quikadmin/src/test/utils/MockDocGenerator.ts'. Implement methods to generate text blocks with specific patterns: names, international phone numbers, and passport-style MRZ lines. This utility will be used by DataExtractor and DocumentDetection tests to simulate various OCR outputs.",
            "status": "pending",
            "testStrategy": "Unit test the generator utility to ensure it produces strings that correctly match the requested regex patterns used in the actual extractor logic.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Develop Fixture Integrity and Accessibility Validation Script",
            "description": "Write a validation script to ensure all required test assets are accessible and functional before running the test suite.",
            "dependencies": [1, 2],
            "details": "Create 'scripts/validate-test-fixtures.ts'. The script should iterate through the 'e2e/fixtures' directory, check for existence of all files defined in Task 242, and perform a basic read operation on each. It should also verify that 'test-corrupted.pdf' correctly triggers an exception when parsed.",
            "status": "pending",
            "testStrategy": "Execute the script via 'ts-node' and confirm it returns a non-zero exit code if any fixture is missing or if the corrupted file is unexpectedly parsed as valid.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-03T08:31:54.554Z"
      },
      {
        "id": "243",
        "title": "Implement DataExtractor Unit Tests",
        "description": "Develop comprehensive unit tests for the DataExtractor logic, focusing on regex patterns and confidence scoring.",
        "details": "Create quikadmin/src/extractors/__tests__/DataExtractor.test.ts. Use Jest to test extraction of emails, US/intl phones, names with titles, and complex addresses. Implementation: describe('DataExtractor', () => { it('should extract US phone formats', () => { expect(extractor.extract(text)).toContain('555-0123'); }); }). Test confidence logic using scenarios with varying OCR quality.",
        "testStrategy": "Execute tests with 'npm test -- DataExtractor.test.ts'. Ensure 100% coverage of regex branches.",
        "priority": "high",
        "dependencies": ["242"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Setup Test Suite and Initial Infrastructure for DataExtractor",
            "description": "Create the test file and initialize the DataExtractor instance with necessary mocks.",
            "dependencies": [],
            "details": "Create the file quikadmin/src/extractors/__tests__/DataExtractor.test.ts. Set up the Jest describe block and instantiate the DataExtractor class. Ensure all necessary dependencies for the extractor are mocked if required.\n<info added on 2026-01-03T08:36:08.847Z>\nInitial test file created at quikadmin/src/extractors/__tests__/DataExtractor.test.ts with comprehensive test cases for email and phone number extraction. The suite includes required Jest setup, logger mocks, and class instantiation. Note: A Jest dependency issue is currently blocking execution, but the implementation logic is complete.\n</info added on 2026-01-03T08:36:08.847Z>",
            "status": "pending",
            "testStrategy": "Run 'npm test -- DataExtractor.test.ts' to ensure the test suite is correctly discovered and passes with a dummy test.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Email and Phone Number Extraction Test Cases",
            "description": "Develop unit tests for validating regex patterns against various email and phone number formats.",
            "dependencies": [1],
            "details": "Add test cases for US phone formats (e.g., 555-0123, (555) 555-5555), international phone formats, and diverse email address structures. Use expect(extractor.extract(text)).toContain() or similar matchers.",
            "status": "pending",
            "testStrategy": "Verify that all phone and email variations are correctly identified by the regex engine.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Name and Professional Title Extraction Test Cases",
            "description": "Verify the extraction logic for personal names including those with professional titles and suffixes.",
            "dependencies": [2],
            "details": "Create test scenarios for names like 'Dr. John Doe', 'Jane Smith, MD', and 'Mr. Robert Brown'. Ensure the regex correctly handles prefixes and suffixes without losing the core name data.",
            "status": "pending",
            "testStrategy": "Assert that the returned name object contains the expected first, last, and title components where applicable.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement Complex Address Extraction Test Cases",
            "description": "Add tests for multi-line addresses, apartment numbers, and varying zip code formats.",
            "dependencies": [3],
            "details": "Provide input strings containing complex address layouts including street, suite numbers, city, state, and zip codes (5-digit and ZIP+4). Ensure the extraction logic handles line breaks within address blocks.",
            "status": "pending",
            "testStrategy": "Verify that address components are accurately parsed and that the full address string matches expected fixtures.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement Confidence Scoring and OCR Quality Logic Tests",
            "description": "Test the confidence calculation logic by simulating varying levels of OCR quality and character ambiguity.",
            "dependencies": [4],
            "details": "Develop tests that provide 'clean' vs 'noisy' OCR text (e.g., substituting '0' for 'O' or '|' for 'I'). Verify that the DataExtractor's confidence scoring algorithm returns values that correlate with the input quality.",
            "status": "pending",
            "testStrategy": "Assert that confidence scores fall within expected ranges (0.0 to 1.0) and that low-confidence flags are triggered for ambiguous data.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-03T08:36:28.874Z"
      },
      {
        "id": "244",
        "title": "Implement FormFiller Unit Tests",
        "description": "Create unit tests for PDF form filling logic including field mapping and flattening.",
        "details": "Create quikadmin/src/fillers/__tests__/FormFiller.test.ts. Mock the PDF library (e.g., pdf-lib). Test fillPDFForm() for checkboxes (yes/no/1/true), radio buttons, and text truncation. Test Unicode character rendering and handling of FLATTEN_FORMS env variable. Use fixtures/visa-application-template.pdf for structural validation.",
        "testStrategy": "Verify that filled fields match input data in mock calls. Ensure corrupted input files throw the expected Error objects.",
        "priority": "high",
        "dependencies": ["242"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize Test Suite and pdf-lib Mocks",
            "description": "Create the test file structure and mock the core PDF library dependencies for isolated unit testing.",
            "dependencies": [],
            "details": "Create quikadmin/src/fillers/__tests__/FormFiller.test.ts. Use jest.mock('pdf-lib') to mock PDFDocument, PDFForm, and field classes like PDFTextField and PDFCheckBox.",
            "status": "pending",
            "testStrategy": "Verify that the test suite loads and the pdf-lib mocks are correctly applied by checking jest.isMockFunction on imported classes.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Test Text Field Filling and Truncation Logic",
            "description": "Verify that text fields are correctly populated and long strings are truncated according to field limits.",
            "dependencies": [1],
            "details": "Implement tests for fillPDFForm that call setText on mocked PDFTextFields. Include cases for empty strings, standard text, and text exceeding character limits to verify truncation logic.",
            "status": "pending",
            "testStrategy": "Assert that mock PDFTextField.setText is called with the expected (possibly truncated) string values.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Validate Checkbox and Radio Button Mapping",
            "description": "Ensure various input formats (yes/no, 1/0, boolean) correctly map to PDF checkbox and radio button actions.",
            "dependencies": [1],
            "details": "Test checkbox logic using inputs like 'yes', 'true', and 1 to trigger check() and 'no', 'false', or 0 to trigger uncheck(). Test radio group selection using select() with specific option keys.",
            "status": "pending",
            "testStrategy": "Assert that mock PDFCheckBox.check/uncheck and PDFRadioGroup.select are called based on the input mapping table.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Verify Unicode Rendering and Fixture Loading",
            "description": "Test the handling of non-ASCII characters and ensure the filler correctly interacts with the template fixture.",
            "dependencies": [1],
            "details": "Mock font embedding for Unicode characters. Load the fixtures/visa-application-template.pdf using fs.readFileSync and pass the buffer to the fillPDFForm function to verify structural integrity.",
            "status": "pending",
            "testStrategy": "Check that PDFDocument.embedFont is called when Unicode characters are present in the input data.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Test Form Flattening and Env Variable Control",
            "description": "Verify that the PDF form is flattened only when the FLATTEN_FORMS environment variable is enabled.",
            "dependencies": [1],
            "details": "Toggle process.env.FLATTEN_FORMS between 'true' and 'false' in tests. Assert that PDFForm.flatten() is called when enabled and skipped when disabled or unset.",
            "status": "pending",
            "testStrategy": "Use jest.spyOn(process.env, 'FLATTEN_FORMS', 'get') to simulate environment configurations and verify the flatten() method call count.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-03T08:36:32.762Z"
      },
      {
        "id": "245",
        "title": "Implement mergeToClientProfile Logic Tests",
        "description": "Test the core profile aggregation logic, ensuring data integrity and manual edit protection.",
        "details": "Create quikadmin/src/api/__tests__/client-documents.routes.test.ts. Focus on the mergeToClientProfile function. Mock the database layer to test: 1. Creation of new profile if missing. 2. Merge into existing. 3. Skip fields where manuallyEdited is true. 4. Field source tracking. Use Transactional rollbacks in tests to ensure clean state.",
        "testStrategy": "Test concurrent merge calls using Promise.all to check for race conditions. Assert that manuallyEdited fields remain unchanged after a mock OCR merge.",
        "priority": "high",
        "dependencies": ["243"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Setup Test Environment and Database Mocks",
            "description": "Create the initial test file structure and mock the database interaction layer to isolate the merge logic.",
            "dependencies": [],
            "details": "Create the file quikadmin/src/api/__tests__/client-documents.routes.test.ts. Use Jest to mock the Prisma client or database service layer. Configure mocks to return consistent responses for profile lookups and updates.",
            "status": "pending",
            "testStrategy": "Run 'npm test' to verify the test file is correctly picked up by Jest and that mocks are initialized without throwing errors.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Test Profile Initialization and Basic Merging",
            "description": "Verify that the system creates a new client profile if it does not exist and correctly merges document fields.",
            "dependencies": [1],
            "details": "Implement test cases that call mergeToClientProfile with a non-existent clientId. Assert that the database 'create' method is called with the expected schema. Verify that fields from the source document are mapped correctly to the new profile.",
            "status": "pending",
            "testStrategy": "Execute the test suite and verify that the 'create' mock receives the correct data payload for a missing profile scenario.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Test Manual Edit Protection and Source Tracking",
            "description": "Ensure fields marked as manually edited remain untouched and verify field source tracking logic.",
            "dependencies": [2],
            "details": "Create a test case where a profile field has manuallyEdited set to true. Trigger a merge and assert that the field remains unchanged. Verify that for fields that are updated, the sourceDocumentId is correctly updated to the current document's ID.",
            "status": "pending",
            "testStrategy": "Assert that the update payload sent to the database does not include fields flagged with manuallyEdited: true.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Test Concurrent Merges and Transaction Integrity",
            "description": "Validate that the merge logic handles simultaneous requests without data corruption using Promise.all.",
            "dependencies": [3],
            "details": "Use Promise.all to trigger multiple concurrent calls to mergeToClientProfile. Mock database delays to simulate race conditions. Ensure that the logic uses transactions or version checks to maintain data integrity across parallel executions.",
            "status": "pending",
            "testStrategy": "Verify that after concurrent merge calls, the final profile state is consistent and that no data from one call accidentally overwrites a more recent update.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-03T08:45:31.320Z"
      },
      {
        "id": "246",
        "title": "Client Profile API Integration Tests",
        "description": "Develop integration tests for the /api/clients/:clientId/profile routes.",
        "details": "Create quikadmin/src/api/__tests__/client-profile.routes.test.ts. Use supertest to hit GET/PUT/PATCH/DELETE endpoints. Verify that categorized structure (Identity, Contact, etc.) is returned. Ensure PUT requests automatically set 'manuallyEdited: true' for updated fields. Test security by attempting to access a profile with an unauthorized user token.",
        "testStrategy": "Check HTTP status codes and response body schemas. Validate that DELETE operations successfully clear data in the test DB.",
        "priority": "high",
        "dependencies": ["245"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Setup Test Environment and GET Integration Tests",
            "description": "Initialize the test file quikadmin/src/api/__tests__/client-profile.routes.test.ts and implement tests for the GET /api/clients/:clientId/profile endpoint.",
            "dependencies": [],
            "details": "Setup supertest with the application instance. Create mock authentication helpers to simulate a valid session. Verify the GET response schema includes categorized sections like Identity, Contact, and Employment with correct HTTP 200 status codes.",
            "status": "pending",
            "testStrategy": "Use supertest to assert 200 OK and validate the JSON response structure matches the Profile interface using JEST matchers.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Test PUT and PATCH Profile Updates with Manual Edit Logic",
            "description": "Implement integration tests for updating profile fields via PUT and PATCH, ensuring the 'manuallyEdited' flag is correctly persisted.",
            "dependencies": [1],
            "details": "Send PUT/PATCH requests to update specific nested profile fields. Assert that the response and subsequent database state show 'manuallyEdited: true' for updated fields. Ensure that non-targeted fields remain unchanged and retain their original metadata.",
            "status": "pending",
            "testStrategy": "Perform a PUT request, then a GET request to verify the field-level 'manuallyEdited' boolean is true for the modified path.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Test DELETE Profile Data and Cleanup",
            "description": "Implement integration tests for the DELETE /api/clients/:clientId/profile endpoint to ensure data is properly cleared or archived.",
            "dependencies": [1],
            "details": "Send a DELETE request for a specific client profile. Verify the HTTP 200 or 204 status code is returned. Query the database or execute a follow-up GET request to confirm the profile data has been reset to an empty or default state.",
            "status": "pending",
            "testStrategy": "Sequence: GET (exists) -> DELETE -> GET (empty/null) to ensure end-to-end data removal from the persistence layer.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Test Security and Cross-Tenant Data Isolation",
            "description": "Implement tests to verify that unauthorized users or users from different tenants cannot access or modify profiles they do not own.",
            "dependencies": [1, 2, 3],
            "details": "Attempt to GET, PUT, and DELETE a profile using a valid token belonging to a different client or an unauthorized user role. Assert that the API returns 403 Forbidden or 401 Unauthorized, and verify no data was modified in the process.",
            "status": "pending",
            "testStrategy": "Test with multiple JWT tokens representing different user scopes to ensure granular access control is enforced at the route level.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-03T08:48:03.291Z"
      },
      {
        "id": "247",
        "title": "Document Detection Service Unit Tests",
        "description": "Validate the logic used to classify document types (Passport, Emirates ID, etc.).",
        "details": "Create quikadmin/src/services/__tests__/DocumentDetectionService.test.ts. Test classify() method against various text snippets and metadata blocks. Verify confidence scoring and fallback to 'unknown' when keywords are missing. Implementation: use test data representing Passport MRZ vs Trade License headers.",
        "testStrategy": "Run unit tests with 10+ mock document signatures. Assert that detection confidence stays above the required threshold for known types.",
        "priority": "medium",
        "dependencies": ["242"],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-03T08:36:32.710Z"
      },
      {
        "id": "248",
        "title": "R2 Storage Service Unit Tests",
        "description": "Test cloud storage operations including uploads, downloads, and presigned URL generation.",
        "details": "Create quikadmin/src/services/__tests__/r2Storage.service.test.ts. Use aws-sdk-client-mock to simulate S3/R2 responses. Test uploadFile, getDownloadUrl, and deleteFile. Implement retry logic tests by mocking network timeouts (ECONNRESET).",
        "testStrategy": "Verify that service methods call the S3 client with correct bucket names and keys. Check error propagation for failed deletes.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-03T08:38:14.944Z"
      },
      {
        "id": "249",
        "title": "MultiAgent Workflow Node Tests",
        "description": "Test individual LangGraph nodes for document processing.",
        "details": "Create quikadmin/src/multiagent/__tests__/workflow.test.ts. Test classifyNode, extractNode, mapNode, and qaNode independently. Mock AI provider responses to verify routing logic (routeAfterQA). Ensure state objects are updated correctly after each node execution.",
        "testStrategy": "Pass a document state through nodes in isolation. Assert that the 'next' value in the workflow matches the routing logic for pass/fail/retry scenarios.",
        "priority": "medium",
        "dependencies": ["243"],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-03T08:56:06.722Z"
      },
      {
        "id": "250",
        "title": "IntelliFillService Orchestration Tests",
        "description": "Unit tests for the top-level orchestration service that ties profile data to form filling.",
        "details": "Create quikadmin/src/services/__tests__/IntelliFillService.test.ts. Mock ProfileService and FormFiller. Test logic for template selection and partial data mapping warnings. Verify confidence indicators are aggregated correctly for the frontend.",
        "testStrategy": "Assert that mapProfileToForm returns correct missingFields array when the profile is incomplete.",
        "priority": "medium",
        "dependencies": ["244", "245"],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-03T08:57:23.079Z"
      },
      {
        "id": "251",
        "title": "Worker Processor Integration Tests",
        "description": "Test OCR and Knowledge processor workers in a simulated queue environment.",
        "details": "Create quikadmin/src/workers/__tests__/ocrProcessor.test.ts and knowledgeProcessor.test.ts. Use a local Redis/BullMq mock or actual container if available in CI. Test job status updates from 'processing' to 'completed/failed'. Mock RealtimeService to verify WebSocket notifications are sent on completion.",
        "testStrategy": "Inject a job into the processor and wait for DB status update. Verify job progress events (e.g., 25%, 50%, 100%) are emitted.",
        "priority": "medium",
        "dependencies": ["247", "248"],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-03T08:58:18.854Z"
      },
      {
        "id": "252",
        "title": "E2E: Profile Aggregation Flow",
        "description": "End-to-end test for uploading multiple documents and verifying the merged profile.",
        "details": "Create e2e/tests/profile-aggregation.spec.ts. Use Playwright. Flow: 1. Login. 2. Upload Passport PDF. 3. Wait for 'EXTRACTED' status. 4. Upload Emirates ID. 5. Verify Client Profile contains fields from both (Passport No + ID No). Verify fieldSources metadata contains both document IDs.",
        "testStrategy": "Verify UI displays 'Extracted' labels and that the database contains the correctly aggregated categorizedData object.",
        "priority": "high",
        "dependencies": ["242", "246"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize Playwright Test and Authentication Setup",
            "description": "Create the E2E test file and implement the authentication logic to reach the dashboard.",
            "dependencies": [],
            "details": "Create e2e/tests/profile-aggregation.spec.ts. Implement a beforeAll or beforeEach hook that logs into the application using test credentials. Ensure the test reaches the 'Documents' or 'Client' view where uploads are initiated.",
            "status": "pending",
            "testStrategy": "Verify that the browser successfully redirects to the dashboard and the session cookie/token is set.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Passport PDF Upload and Extraction Verification",
            "description": "Automate the upload of the first document (Passport) and wait for the extraction process to complete.",
            "dependencies": [1],
            "details": "Use the Playwright fileChooser to upload a passport PDF fixture. Implement a polling mechanism or use Playwright's locator assertions to wait until the document status badge displays 'EXTRACTED'.",
            "status": "pending",
            "testStrategy": "Assert that the status 'EXTRACTED' appears in the document list for the specific uploaded file.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Emirates ID Upload and Verification",
            "description": "Automate the upload of the second document (Emirates ID) to trigger the profile aggregation logic.",
            "dependencies": [2],
            "details": "Upload the Emirates ID PDF fixture for the same client context. Ensure the UI handles the concurrent or sequential document processing without errors and that the second document also reaches 'EXTRACTED' status.",
            "status": "pending",
            "testStrategy": "Confirm that both documents are listed under the client's document history with successful extraction statuses.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Verify Aggregated Client Profile and Field Source Metadata",
            "description": "Assert that the client profile view displays merged data from both uploaded documents and tracks sources correctly.",
            "dependencies": [3],
            "details": "Navigate to the Client Profile details page. Verify that the Passport Number (from doc 1) and Emirates ID Number (from doc 2) are both populated. Inspect the UI or underlying API response to ensure 'fieldSources' contains both document IDs.",
            "status": "pending",
            "testStrategy": "Validate that the 'Identity' section of the profile contains data from both documents and that the source metadata is correctly rendered in the UI.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-03T08:45:25.406Z"
      },
      {
        "id": "253",
        "title": "E2E: Manual Edit Protection",
        "description": "Ensure manual edits are never overwritten by subsequent OCR processes.",
        "details": "Create e2e/tests/manual-edit-protection.spec.ts. 1. Extract data from a document. 2. Manually edit 'First Name' in the UI/API. 3. Re-upload the same document. 4. Verify 'First Name' still holds the manual value. 5. Clear 'manuallyEdited' flag and re-run OCR to verify it now updates.",
        "testStrategy": "Inspect the 'manuallyEdited' property in the API response after each step. Check UI visual indicators (e.g., 'Locked' icon).",
        "priority": "high",
        "dependencies": ["252"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Setup E2E Test Scaffold and Initial OCR Extraction",
            "description": "Create the E2E test file and implement the first step of extracting data from a sample document.",
            "dependencies": [],
            "details": "Create e2e/tests/manual-edit-protection.spec.ts. Use Playwright or the existing E2E framework to upload a sample document and trigger the OCR process. Store the initial extracted 'First Name' value for comparison.",
            "status": "pending",
            "testStrategy": "Run the test to ensure the file is correctly picked up and the initial OCR extraction completes successfully.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Manual Field Edit and Validation",
            "description": "Simulate a manual edit of the 'First Name' field and verify the state of the 'manuallyEdited' flag.",
            "dependencies": [1],
            "details": "Programmatically or via UI interaction, update the 'First Name' field. Verify via API response or UI state that the field now has the 'manuallyEdited' metadata set to true.",
            "status": "pending",
            "testStrategy": "Assert that the field value matches the manual entry and the 'manuallyEdited' flag is true.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Verify Protection During Document Re-upload",
            "description": "Re-upload the same document and verify that the manually edited field remains unchanged despite new OCR results.",
            "dependencies": [2],
            "details": "Trigger a re-upload or re-processing of the same document. Ensure the backend/UI does not overwrite the 'First Name' field. Check that the UI displays any 'Locked' or 'Edited' indicators.",
            "status": "pending",
            "testStrategy": "Assert that 'First Name' still equals the manual value and is not reverted to the original OCR value.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Verify Data Overwrite After Clearing Protection Flag",
            "description": "Reset the 'manuallyEdited' flag and verify that a subsequent OCR process now updates the field.",
            "dependencies": [3],
            "details": "Reset the 'manuallyEdited' flag for the 'First Name' field through the API. Re-run the OCR process and verify that the field is now updated with the value from the OCR engine.",
            "status": "pending",
            "testStrategy": "Assert that the field value has changed back to the OCR-extracted value and the 'manuallyEdited' flag is false.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-03T08:45:15.855Z"
      },
      {
        "id": "254",
        "title": "E2E: Security and Data Isolation",
        "description": "Verify that users cannot access documents or profiles belonging to other tenants/clients.",
        "details": "Create e2e/tests/security.spec.ts. Create two test users. User A uploads a doc. User B attempts to GET the doc/profile by ID. Assert 404 or 403 response. Test path traversal on document download endpoints.",
        "testStrategy": "Use multi-browser context in Playwright to simulate two sessions. Assert rejection on cross-client API calls.",
        "priority": "high",
        "dependencies": ["246"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Setup Security E2E Scaffolding and Multi-User Contexts",
            "description": "Initialize the security E2E test file and configure Playwright to handle multiple authenticated sessions for distinct tenants.",
            "dependencies": [],
            "details": "Create 'e2e/tests/security.spec.ts'. Implement logic to authenticate two separate users (User A and User B) representing different tenants. Use Playwright browser contexts to maintain isolation between these sessions. Define a helper function to upload a document using User A's credentials and return the resulting resource ID.",
            "status": "pending",
            "testStrategy": "Verify that two independent sessions are successfully established by checking the auth state in each Playwright context.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Cross-Tenant Resource Isolation Tests",
            "description": "Write test cases to verify that User B cannot access documents or profile data belonging to User A.",
            "dependencies": [1],
            "details": "Using the ID of a document uploaded by User A, perform API requests (GET, PUT, DELETE) from User B's context. Specifically target '/api/documents/:id' and '/api/profiles/:id'. Assert that the API returns a 403 Forbidden or 404 Not Found response, ensuring no data leakage between tenants.",
            "status": "pending",
            "testStrategy": "Execute the security spec and confirm that attempts by User B to access User A's document ID result in failure responses.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Path Traversal Security Tests",
            "description": "Add test cases to ensure document download endpoints are protected against path traversal attacks.",
            "dependencies": [1],
            "details": "Attempt to access files outside the authorized storage directory using manipulated strings such as '../../etc/passwd', '..\\..\\config.json', or encoded variants in document download endpoints. Assert that the server rejects these requests with 400 Bad Request or 403 Forbidden and does not expose file system contents.",
            "status": "pending",
            "testStrategy": "Fuzz the document download endpoint with common traversal payloads and verify that only valid, tenant-owned IDs are processed.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-03T08:54:39.798Z"
      },
      {
        "id": "255",
        "title": "E2E: Form Filling Workflow",
        "description": "Verify the end-to-end flow from profile data to a filled PDF template.",
        "details": "Create e2e/tests/form-filling.spec.ts. 1. Populate a profile. 2. Trigger form fill for visa-application-template.pdf. 3. Download generated PDF. 4. Verify PDF contains expected fields using a PDF parsing utility in the test. 5. Check UI for confidence indicators.",
        "testStrategy": "Validate the presence of 'missingFields' warnings in the UI when profile data is intentionally withheld.",
        "priority": "medium",
        "dependencies": ["250", "252"],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-03T09:04:03.214Z"
      },
      {
        "id": "256",
        "title": "E2E: Error Handling and Recovery",
        "description": "Test system resilience against malformed inputs and service failures.",
        "details": "Create e2e/tests/error-handling.spec.ts. Upload test-corrupted.pdf. Verify UI shows 'Extraction Failed'. Test behavior when OCR worker is down (simulate timeout). Verify that the profile remains in a consistent state (no partial/corrupt merges).",
        "testStrategy": "Assert error message strings in the UI match those defined in the backend ErrorHandler. Verify retry button triggers a new job.",
        "priority": "medium",
        "dependencies": ["252"],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-03T09:04:56.347Z"
      },
      {
        "id": "257",
        "title": "Frontend Store Unit Tests",
        "description": "Test Zustand stores for document state management and profile aggregation.",
        "details": "Create quikadmin-web/src/stores/__tests__/documentStore.test.ts and profileStore.test.ts. Mock API calls using msw (Mock Service Worker). Verify that fetching a profile updates the state correctly. Test 'reset' actions and local caching logic.",
        "testStrategy": "Assert store state after calling actions. Use 'waitFor' to handle async state transitions in Vitest/Jest.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-03T08:37:38.082Z"
      },
      {
        "id": "258",
        "title": "Edge Case Refinement: OCR & Field Mapping",
        "description": "Extend tests for internationalization, large inputs, and fuzzy matching.",
        "details": "Update existing tests in DataExtractor and FieldMapper. Add cases for: Unicode characters in names, international phone formats (e.g., +971), and extremely long field names. Test Levenshtein distance logic in FieldMapper for fuzzy name matching (e.g., 'Passport Number' vs 'Passport No.').",
        "testStrategy": "Ensure unit tests cover the new test vectors and that the Levenshtein threshold correctly accepts/rejects mappings.",
        "priority": "low",
        "dependencies": ["243", "244"],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-03T09:07:31.253Z"
      },
      {
        "id": "259",
        "title": "Performance and Bulk Benchmarking",
        "description": "Execute performance tests for large files and concurrent operations.",
        "details": "Create e2e/tests/performance.spec.ts. Test upload of large-document-50pages.pdf and verify it processes under 10 minutes. Run 5 concurrent document uploads for the same client to verify DB locking and merge consistency.",
        "testStrategy": "Use performance.now() to measure processing time. Verify no Deadlock errors occur in backend logs during concurrent merge operations.",
        "priority": "low",
        "dependencies": ["252"],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-03T09:02:41.062Z"
      },
      {
        "id": "260",
        "title": "Extract Shared Redis Configuration",
        "description": "Create a centralized Redis configuration utility to eliminate code duplication across multiple queue files.",
        "details": "Create 'quikadmin/src/utils/redisConfig.ts'. Export a function 'getRedisConfig()' that returns the Redis connection options and a 'defaultBullSettings' object containing standard Bull queue options. Replace local 'getRedisConfig' implementations in 'ocrQueue.ts', 'documentQueue.ts', and 'multiagentQueue.ts' with this shared utility.",
        "testStrategy": "Verify that all three queue files import the configuration correctly and can still connect to Redis upon initialization. Run unit tests to ensure configuration consistency.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create centralized Redis configuration utility",
            "description": "Create the file 'quikadmin/src/utils/redisConfig.ts' and implement the core configuration logic.",
            "dependencies": [],
            "details": "Implement and export the 'getRedisConfig' function to return connection options (host, port, password) and the 'defaultBullSettings' object for standard Bull queue behavior. Ensure it uses environment variables for configuration.",
            "status": "pending",
            "testStrategy": "Create a unit test to verify that 'getRedisConfig' returns the expected object structure and correctly reads environment variables.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Refactor ocrQueue.ts to use shared utility",
            "description": "Remove the local implementation of 'getRedisConfig' in 'ocrQueue.ts' and integrate the shared utility.",
            "dependencies": [1],
            "details": "Import 'getRedisConfig' and 'defaultBullSettings' from '../utils/redisConfig'. Update the Bull constructor to use these imported values instead of local definitions.",
            "status": "pending",
            "testStrategy": "Verify that the OCR queue initializes without connection errors and processes jobs using the new configuration.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Refactor documentQueue.ts to use shared utility",
            "description": "Remove the local implementation of 'getRedisConfig' in 'documentQueue.ts' and integrate the shared utility.",
            "dependencies": [1],
            "details": "Replace the local Redis configuration logic in 'documentQueue.ts' with the exported functions from the utility module. Update initialization calls accordingly.",
            "status": "pending",
            "testStrategy": "Verify that the document queue successfully connects to Redis and maintains existing functionality.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Refactor multiagentQueue.ts to use shared utility",
            "description": "Remove the local implementation of 'getRedisConfig' in 'multiagentQueue.ts' and integrate the shared utility.",
            "dependencies": [1],
            "details": "Standardize 'multiagentQueue.ts' by importing the shared Redis configuration. Ensure any queue-specific settings still merge correctly with 'defaultBullSettings'.",
            "status": "pending",
            "testStrategy": "Ensure the multiagent queue starts and that LLM-related jobs are still correctly queued and executed.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Perform global Redis connectivity validation",
            "description": "Conduct a final check to ensure all refactored queues are operating consistently with the centralized configuration.",
            "dependencies": [2, 3, 4],
            "details": "Run the application in a staging environment. Inspect logs to confirm all three queues (OCR, Document, Multiagent) successfully connect to the Redis instance using the shared utility.",
            "status": "pending",
            "testStrategy": "Analyze application logs for 'Queue ready' events and perform a sample task for each queue to ensure end-to-end connectivity.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-04T02:38:39.893Z"
      },
      {
        "id": "261",
        "title": "Define Constants and TypeScript Interfaces",
        "description": "Establish a single source of truth for queue configurations and explicit return types to improve code quality and maintainability.",
        "details": "Define 'OCR_QUEUE_CONFIG' at the top of 'ocrQueue.ts' containing keys like 'CONCURRENCY', 'MAX_ATTEMPTS', and 'BACKOFF_DELAY'. Export interfaces 'QueueHealthStatus' and 'OCRJobStatus' to be used as return types for health checks and status queries. Replace all magic numbers in the queue setup with these constants.",
        "testStrategy": "Ensure the project compiles with strict TypeScript checks. Verify that IDE autocompletion works for the exported interfaces and constants.",
        "priority": "medium",
        "dependencies": ["260"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define OCR_QUEUE_CONFIG object",
            "description": "Establish the central configuration object for the OCR queue in ocrQueue.ts.",
            "dependencies": [],
            "details": "Add a constant named OCR_QUEUE_CONFIG at the top of the file containing CONCURRENCY, MAX_ATTEMPTS, and BACKOFF_DELAY properties.",
            "status": "pending",
            "testStrategy": "Verify that the constants are correctly defined and accessible within the file context.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Define QueueHealthStatus Interface",
            "description": "Create a reusable TypeScript interface for monitoring queue health.",
            "dependencies": [1],
            "details": "Export the QueueHealthStatus interface with fields for job counts like active, waiting, completed, and failed status counts.",
            "status": "pending",
            "testStrategy": "Check for correct property naming and types in the interface definition using the TypeScript compiler.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Define OCRJobStatus Interface",
            "description": "Create a reusable TypeScript interface for reporting individual job status.",
            "dependencies": [1],
            "details": "Export the OCRJobStatus interface including state, progress percentage, and potential error messages or job result data fields.",
            "status": "pending",
            "testStrategy": "Ensure the interface captures all necessary state information for an OCR job tracking system.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Refactor Queue Setup with Constants",
            "description": "Replace hardcoded values in the queue and worker configuration with OCR_QUEUE_CONFIG properties.",
            "dependencies": [1],
            "details": "Locate the Bull queue constructor and worker options; replace numeric literals with OCR_QUEUE_CONFIG properties to eliminate magic numbers.",
            "status": "pending",
            "testStrategy": "Confirm that the queue still initializes correctly and behaves as expected with the new constant values.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Apply Interfaces to Function Signatures",
            "description": "Update the return types of existing queue management functions to use the new interfaces.",
            "dependencies": [2, 3],
            "details": "Modify functions like getOCRJobStatus and getQueueHealth to explicitly return OCRJobStatus and QueueHealthStatus types respectively.",
            "status": "pending",
            "testStrategy": "Run the TypeScript compiler to ensure there are no type mismatches in the function return statements.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-04T07:19:36.297Z"
      },
      {
        "id": "262",
        "title": "Implement Robust Input Validation for OCR Jobs",
        "description": "Prevent invalid data processing and security risks like SSRF and path traversal by validating job data before processing.",
        "details": "Create a validation function for OCR job data. Ensure 'documentId' is a valid UUID. Validate 'filePath' to ensure it starts with allowed domains (e.g., R2 storage) or is within an approved local directory. Use this validation in 'enqueueDocumentForOCR', 'enqueueDocumentForReprocessing', and at the start of the job processor. Throw descriptive errors for invalid inputs.",
        "testStrategy": "Unit tests passing invalid UUIDs, local file paths (traversal attempts), and unauthorized URLs to ensure the validation logic correctly rejects them with the expected error messages.",
        "priority": "high",
        "dependencies": ["261"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define OCR Job Validation Schema and Rules",
            "description": "Establish the validation rules for OCR job data, specifically for 'documentId' and 'filePath' fields.",
            "dependencies": [],
            "details": "Create a validation module using a library like 'zod' or custom logic. Define a UUID regex for 'documentId'. For 'filePath', define a whitelist of allowed domains (e.g., R2 storage endpoints) and a base local directory path to prevent unauthorized access.",
            "status": "pending",
            "testStrategy": "Verify schema constants and regex patterns against known valid and invalid samples in isolation.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement validateOcrJobData Utility Function",
            "description": "Develop a centralized utility function that enforces security constraints and throws descriptive errors on failure.",
            "dependencies": [1],
            "details": "Implement logic to check for SSRF by verifying 'filePath' URLs against allowed domains. Prevent path traversal by resolving file paths and ensuring they reside within the approved local subdirectory. Throw specific error types like 'InvalidInputError' or 'SecurityError' for better error handling downstream.",
            "status": "pending",
            "testStrategy": "Unit test the utility with valid UUIDs, malicious '..' path segments, and unauthorized external URLs.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate Validation in Enqueueing Functions",
            "description": "Update the functions responsible for adding jobs to the OCR queue to validate data at the entry point.",
            "dependencies": [2],
            "details": "Modify 'enqueueDocumentForOCR' and 'enqueueDocumentForReprocessing' in the queue management service. Insert calls to 'validateOcrJobData' before 'queue.add()' is executed. This prevents invalid jobs from entering the Bull queue.",
            "status": "pending",
            "testStrategy": "Mock the queue and assert that 'queue.add' is never called when provided with invalid document IDs or file paths.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add Defensive Validation to Job Processor",
            "description": "Ensure the background processor validates data again before execution as a secondary defense layer.",
            "dependencies": [2, 3],
            "details": "Locate the 'ocrQueue.process' callback. Invoke 'validateOcrJobData' using the job data payload at the very start of the process. If validation fails, mark the job as failed with a detailed error message in the job results.",
            "status": "pending",
            "testStrategy": "Simulate a job payload with a malicious path and verify the processor catches the error before initiating OCR or network requests.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement Comprehensive Validation Integration Tests",
            "description": "Create integration tests that verify the entire validation flow from API/service entry to the background processor.",
            "dependencies": [4],
            "details": "Write tests in 'src/services/__tests__/ocr-validation.test.ts'. Use a variety of edge cases: invalid UUID formats, local paths attempting to escape the app root, and URLs from untrusted domains. Ensure that descriptive errors are logged and jobs are correctly rejected.",
            "status": "pending",
            "testStrategy": "Run 'npm test' specifically for the new validation test file and ensure 100% coverage of the validation logic branches.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-04T07:26:38.712Z"
      },
      {
        "id": "263",
        "title": "Fix IDOR Vulnerability in getOCRJobStatus",
        "description": "Secure the job status endpoint to ensure users can only access their own document processing status.",
        "details": "Update the signature of 'getOCRJobStatus' to include 'requestingUserId'. Before returning job data, verify that 'job.data.userId === requestingUserId'. If the check fails, return null. Ensure sensitive internal fields like 'filePath' are omitted from the returned status object.",
        "testStrategy": "Integration test where User A attempts to query the status of User B's job ID. Verify that the response is null or unauthorized, and ensure User A can successfully query their own jobs.",
        "priority": "high",
        "dependencies": ["261"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Update getOCRJobStatus Signature in Service Layer",
            "description": "Modify the service function signature to accept a requestingUserId parameter for authorization checks.",
            "dependencies": [],
            "details": "Locate the getOCRJobStatus function (likely in a service file such as src/services/ocr/jobService.ts). Update its definition to include requestingUserId: string as a required argument.",
            "status": "pending",
            "testStrategy": "Unit test verifying that the function signature correctly accepts the new parameter and propagates it through the logic.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Ownership Verification Logic",
            "description": "Add a conditional check within the getOCRJobStatus function to compare the job owner with the requester.",
            "dependencies": [1],
            "details": "Inside getOCRJobStatus, after fetching the job data, add a check: if (job.data.userId !== requestingUserId) { return null; }. This ensures that a user can only see metadata for jobs they initiated.",
            "status": "pending",
            "testStrategy": "Unit test where a mock job with userId 'user_A' is queried by 'user_B', asserting that the return value is null.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Filter Sensitive Internal Fields from Job Status",
            "description": "Mask or remove internal system paths and sensitive metadata from the job status object before returning it to the client.",
            "dependencies": [2],
            "details": "Create a sanitization step that clones the job status object and deletes the 'filePath' property and any other internal metadata (e.g., local storage paths, internal worker IDs) before returning it to the caller.",
            "status": "pending",
            "testStrategy": "Unit test checking that the returned object does not contain the 'filePath' key, even if it exists in the raw job data.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Update API Controllers and Route Handlers",
            "description": "Pass the authenticated user's ID from the request context to the updated getOCRJobStatus service function.",
            "dependencies": [1],
            "details": "Update the controller/route handler (e.g., src/api/routes/ocr.ts) to extract the userId from the decoded JWT/session (req.user.id) and pass it as the second argument to getOCRJobStatus.",
            "status": "pending",
            "testStrategy": "Manual verification using an API client to ensure that valid requests still return status data when the user ID matches.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Create Security Integration Tests for IDOR Prevention",
            "description": "Develop automated integration tests to verify that cross-user status requests are blocked.",
            "dependencies": [3, 4],
            "details": "Add a new test file tests/security/ocrIdor.test.ts. Create two users, have User A create a job, and then have User B attempt to query that job ID. Assert that the response is either a 404, 403, or returns null data as per requirements.",
            "status": "pending",
            "testStrategy": "Execute the newly created integration tests using the test runner (e.g., Vitest or Jest) and ensure all security assertions pass.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-04T07:31:47.860Z"
      },
      {
        "id": "264",
        "title": "Implement Try-Finally Pattern for OCRService Cleanup",
        "description": "Prevent memory leaks by ensuring Tesseract workers and temporary files are always cleaned up, regardless of job outcome.",
        "details": "Refactor the 'ocrQueue.process' callback. Wrap the 'ocrService.process()' logic in a try-finally block. In the 'finally' block, call 'await ocrService.cleanup()'. Add a catch block within the finally block specifically for the cleanup call to log warnings without crashing the processor.",
        "testStrategy": "Simulate a forced failure within the OCR processing logic and verify via logs or memory profiler that 'ocrService.cleanup()' was still executed.",
        "priority": "high",
        "dependencies": ["262"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Locate and audit current OCR processing logic",
            "description": "Identify the exact file and line where 'ocrQueue.process' is defined and how 'ocrService.process()' is invoked.",
            "dependencies": [],
            "details": "Search for 'ocrQueue.process' and 'ocrService.process' within the 'src' directory to determine the current execution flow and identify existing error handling structures.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Refactor ocrQueue processor with try-finally block",
            "description": "Wrap the call to 'ocrService.process()' in a try-finally block within the queue processor callback.",
            "dependencies": [1],
            "details": "Modify the processor function (likely in a file like 'ocr.worker.ts' or 'ocr.service.ts') to ensure that execution enters a finally block regardless of whether the processing succeeds or throws an error.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate ocrService.cleanup() in finally block",
            "description": "Ensure the 'cleanup()' method is called in the finally block to release Tesseract workers and delete temporary files.",
            "dependencies": [2],
            "details": "Invoke 'await ocrService.cleanup()' inside the finally block. This ensures that resources are freed even if the main processing logic encounters an unhandled exception or a timeout.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement safe error handling for the cleanup call",
            "description": "Add a localized try-catch block around the cleanup call to prevent cleanup failures from masking original processing errors.",
            "dependencies": [3],
            "details": "Wrap 'await ocrService.cleanup()' in its own try-catch block. Log any errors occurring during cleanup as warnings using the system logger (e.g., Winston) but do not rethrow, so the original job outcome is preserved.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Verify cleanup execution with failure simulation",
            "description": "Create a test case that forces an error during OCR processing and verifies that cleanup is still invoked.",
            "dependencies": [4],
            "details": "Mock 'ocrService.process' to throw an error. Use a spy on 'ocrService.cleanup' to assert it was called exactly once. Verify that temporary files are removed and worker instances are terminated in the test environment.",
            "status": "pending",
            "testStrategy": "Execute unit tests using Jest/Mocha. Use 'jest.spyOn(ocrService, 'cleanup')' to verify the method call after a simulated exception.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-04T07:34:43.804Z"
      },
      {
        "id": "265",
        "title": "Set Concurrency Limits and Fix Error Handler Promise Rejections",
        "description": "Manage resource usage by limiting concurrent jobs and prevent unhandled promise rejections in the queue's error handler.",
        "details": "Update 'ocrQueue.process' to use a concurrency value from 'process.env.OCR_CONCURRENCY' (defaulting to 1). In the 'ocrQueue.on('error')' handler, wrap the dynamic import of the health check or logger in a try-catch block to ensure the handler itself never throws an unhandled exception.",
        "testStrategy": "Load test by enqueuing 10 jobs simultaneously and verifying only the specified number of jobs run at once. Trigger an error and verify no 'unhandledRejection' warnings appear in the logs.",
        "priority": "high",
        "dependencies": ["264"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define and Export OCR_CONCURRENCY Configuration",
            "description": "Add OCR_CONCURRENCY to the centralized environment configuration or .env loading logic.",
            "dependencies": [],
            "details": "Update the configuration loader to read OCR_CONCURRENCY from process.env, parse it as an integer, and provide a default value of 1.",
            "status": "pending",
            "testStrategy": "Unit test the configuration loader with various environment variable scenarios to ensure correct parsing and defaults.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Apply Concurrency Limit to OCR Queue Processor",
            "description": "Update the ocrQueue.process method call to use the configured concurrency limit.",
            "dependencies": [1],
            "details": "Locate the ocrQueue.process call site and pass the parsed concurrency value as the first argument to the processor function.",
            "status": "pending",
            "testStrategy": "Enqueue multiple jobs and log their start/end times to verify the number of overlapping executions matches the configuration.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Wrap Queue Error Handler in Try-Catch Block",
            "description": "Ensure the ocrQueue.on('error') listener does not throw unhandled exceptions by wrapping its logic in a try-catch block.",
            "dependencies": [],
            "details": "Refactor the error event listener for the ocrQueue to wrap all logic inside a try-catch block, preventing the Node.js process from crashing on secondary errors.",
            "status": "pending",
            "testStrategy": "Simulate an error within the error handler logic during a test run and ensure the process does not terminate.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Safeguard Dynamic Imports in Error Handler",
            "description": "Specifically handle potential promise rejections from dynamic imports inside the error handler.",
            "dependencies": [3],
            "details": "Wrap any 'await import(...)' calls within the 'error' handler in a nested try-catch block to ensure logging or health check failures do not cause unhandled rejections.",
            "status": "pending",
            "testStrategy": "Mock the dynamic import modules to fail and verify that the queue error handler logs the failure instead of throwing an unhandled rejection.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Validate Concurrency and Error Handler Resilience",
            "description": "Perform end-to-end testing of the concurrency and error handling mechanisms for the OCR queue.",
            "dependencies": [2, 4],
            "details": "Execute a load test with 10 jobs and concurrency set to 2. Verify only 2 jobs run at once. Manually trigger queue errors and verify no 'unhandledRejection' warnings occur.",
            "status": "pending",
            "testStrategy": "Automated integration test using a test Redis instance to observe queue behavior and ensure process stability under error conditions.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-04T07:36:18.002Z"
      },
      {
        "id": "266",
        "title": "Implement Job Deduplication Logic",
        "description": "Prevent redundant processing of the same document by using unique job IDs.",
        "details": "Modify 'enqueueDocumentForOCR' to pass a 'jobId' in the Bull 'JobOptions'. Use the format 'ocr-${documentId}'. Ensure that attempts to add a duplicate job are handled gracefully, returning the existing job object and logging the event.",
        "testStrategy": "Attempt to enqueue the same 'documentId' twice in rapid succession. Verify that the queue only contains one job for that ID and the log confirms a duplicate was detected.",
        "priority": "medium",
        "dependencies": ["261"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Identify enqueueDocumentForOCR location",
            "description": "Locate the function responsible for adding documents to the OCR queue.",
            "dependencies": [],
            "details": "Search through the codebase, specifically in services or queue controllers, to find where documents are enqueued for processing using the Bull library.",
            "status": "pending",
            "testStrategy": "Manual verification of the file path and function signature.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Inject jobId into JobOptions",
            "description": "Modify the queue addition logic to use a deterministic jobId.",
            "dependencies": [1],
            "details": "Update the 'enqueueDocumentForOCR' function to pass { jobId: `ocr-${documentId}` } within the Bull JobOptions parameter of the add method.",
            "status": "pending",
            "testStrategy": "Unit test verifying that the add method of the queue is called with the correct jobId format.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement duplicate handling logic",
            "description": "Ensure the function handles existing job IDs and returns the relevant job.",
            "dependencies": [2],
            "details": "Adjust the logic to catch or handle the return value when a jobId collision occurs, ensuring the method still returns a job object as per requirements.",
            "status": "pending",
            "testStrategy": "Integration test attempting to add the same job twice and checking the return value.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add deduplication event logging",
            "description": "Log an informational message when a duplicate job submission is detected.",
            "dependencies": [3],
            "details": "Add a logger statement (e.g., logger.info) that triggers when the queue detects an existing job with the same ID, noting the documentId involved.",
            "status": "pending",
            "testStrategy": "Inspect application logs during a duplicate submission test case.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Final verification and regression testing",
            "description": "Perform comprehensive testing to ensure deduplication works without affecting existing OCR flows.",
            "dependencies": [4],
            "details": "Execute the full OCR pipeline for a document multiple times and verify that processing only occurs once and no errors are thrown for duplicates.",
            "status": "pending",
            "testStrategy": "Automated integration test using a mock Redis environment or a development queue instance.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-04T07:40:02.215Z"
      },
      {
        "id": "267",
        "title": "Enhance Reprocessing with Document Checks",
        "description": "Improve the reliability of document reprocessing by verifying document existence before queuing.",
        "details": "In 'enqueueDocumentForReprocessing', add an explicit null check after calling 'prisma.document.findUnique'. If the document does not exist, throw a descriptive error including the 'documentId' instead of proceeding with potentially undefined data.",
        "testStrategy": "Call the reprocessing function with a non-existent UUID and verify it throws the correct error and does not add a job to the queue.",
        "priority": "medium",
        "dependencies": ["262"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Locate enqueueDocumentForReprocessing implementation",
            "description": "Identify the file and exact line where enqueueDocumentForReprocessing is defined and called within the service layer.",
            "dependencies": [],
            "details": "Search the codebase (likely in src/services or src/queues) for the function definition using grep to identify where the Prisma query resides.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Prisma result validation",
            "description": "Add an explicit null check for the document returned by the prisma.document.findUnique call.",
            "dependencies": [1],
            "details": "Update the logic to assign the result of the Prisma query to a variable and check if it is falsy before proceeding with queue logic.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add descriptive error handling",
            "description": "Throw a custom error containing the documentId when a document is not found.",
            "dependencies": [2],
            "details": "Use a template string to include the documentId in the error message, ensuring it matches the expected error format for the application's error handling middleware.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Refactor queue logic to prevent execution on failure",
            "description": "Ensure the BullMQ/Queue logic is only executed if the document exists and the check passes.",
            "dependencies": [3],
            "details": "Restructure the function flow so that the 'add' or 'enqueue' call to the job queue is unreachable if the document existence check fails.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Create unit test for non-existent document",
            "description": "Write a test case that passes a non-existent UUID to the reprocessing function and asserts the error.",
            "dependencies": [4],
            "details": "Use Jest to mock the Prisma client to return null, call the function, and expect it to throw an error while verifying the queue 'add' method was never called.",
            "status": "pending",
            "testStrategy": "Execute npm test or jest for the newly created test file and verify the error message matches the documentId.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-04T07:41:38.819Z"
      },
      {
        "id": "268",
        "title": "Standardize Return Types Across Exported Functions",
        "description": "Apply the previously defined TypeScript interfaces to all exported functions to ensure type safety for consumers.",
        "details": "Update 'getOCRQueueHealth', 'getOCRJobStatus', 'enqueueDocumentForOCR', and 'enqueueDocumentForReprocessing' with explicit return type annotations (e.g., Promise<OCRJobStatus | null>). Ensure any internal helper functions also have defined types.",
        "testStrategy": "Run 'tsc --noEmit' to ensure the entire codebase is type-compatible with the new explicit return types.",
        "priority": "medium",
        "dependencies": ["261", "263", "267"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Import and Integrate TypeScript Interfaces in OCR Module",
            "description": "Ensure the interfaces defined in previous tasks (261) are correctly imported into the OCR queue implementation file.",
            "dependencies": [],
            "details": "Open 'ocrQueue.ts' and add import statements for 'QueueHealthStatus' and 'OCRJobStatus'. Verify that these interfaces are exported from their source file as established in Task 261.",
            "status": "pending",
            "testStrategy": "Verify that the IDE resolves the imported interfaces without errors.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Annotate Health Check and Job Status Query Functions",
            "description": "Apply explicit Promise return types to the health check and status query exported functions.",
            "dependencies": [1],
            "details": "Update 'getOCRQueueHealth' to return 'Promise<QueueHealthStatus>' and 'getOCRJobStatus' to return 'Promise<OCRJobStatus | null>'. Ensure that the return statements in these functions conform to the interface structures.",
            "status": "pending",
            "testStrategy": "Use 'tsc --noEmit' to check for type mismatches between the function bodies and the new return type signatures.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Annotate Document Enqueueing Exported Functions",
            "description": "Update the main document processing entry points with standardized return types.",
            "dependencies": [1, 2],
            "details": "Modify 'enqueueDocumentForOCR' and 'enqueueDocumentForReprocessing' to explicitly return 'Promise<OCRJobStatus>'. Ensure that any error paths throw typed errors rather than returning mixed types.",
            "status": "pending",
            "testStrategy": "Run unit tests for these functions to ensure that mock return values are updated to match the interface requirements.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Standardize Types for Internal Helper Functions",
            "description": "Identify and type-annotate all non-exported helper functions within the OCR service module.",
            "dependencies": [1, 2, 3],
            "details": "Audit 'ocrQueue.ts' for private/internal functions like job processors or configuration loaders. Add explicit return type annotations to prevent 'any' type leakage and improve internal code maintainability.",
            "status": "pending",
            "testStrategy": "Enable 'noImplicitAny' in tsconfig.json temporarily if not already enabled to catch missing types.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Final Type Validation and Documentation Update",
            "description": "Perform a full codebase type check and update JSDoc comments to match the new TypeScript annotations.",
            "dependencies": [1, 2, 3, 4],
            "details": "Run 'npm run type-check' (or 'tsc --noEmit') across the entire project to ensure consumers of these functions are properly handling the new types. Update any associated JSDoc '@returns' tags for consistency.",
            "status": "pending",
            "testStrategy": "Ensure the build pipeline completes successfully with no TypeScript errors related to the OCR module.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-04T07:44:35.846Z"
      },
      {
        "id": "269",
        "title": "Refactor Peripheral Queues for Consistency",
        "description": "Apply the shared Redis configuration and magic number removal patterns to other queue modules.",
        "details": "Update 'documentQueue.ts' and 'multiagentQueue.ts' to use the 'getRedisConfig' from 'quikadmin/src/utils/redisConfig.ts'. Remove their local duplicate logic and ensure they follow the same configuration pattern established for the OCR queue.",
        "testStrategy": "Verify that document and multiagent processing still function correctly in a local environment. Confirm no regression in connection handling.",
        "priority": "low",
        "dependencies": ["260"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Refactor documentQueue.ts to use shared Redis config",
            "description": "Update documentQueue.ts to utilize the getRedisConfig utility and remove magic numbers.",
            "dependencies": [],
            "details": "Import getRedisConfig from quikadmin/src/utils/redisConfig.ts. Replace local Redis connection logic and standardize retry strategies based on the OCR queue pattern.",
            "status": "pending",
            "testStrategy": "Verify successful Redis connection and job processing in documentQueue using local tests.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Refactor multiagentQueue.ts to use shared Redis config",
            "description": "Update multiagentQueue.ts to utilize the getRedisConfig utility and remove magic numbers.",
            "dependencies": [],
            "details": "Import getRedisConfig from quikadmin/src/utils/redisConfig.ts. Replace redundant connection logic and ensure configuration consistency across peripheral queues.",
            "status": "pending",
            "testStrategy": "Verify successful Redis connection and job processing in multiagentQueue using local tests.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Validate connection stability and queue processing",
            "description": "Perform regression testing on document and multiagent queues to ensure proper functionality.",
            "dependencies": [1, 2],
            "details": "Trigger jobs for both queues and monitor logs for connection stability and successful execution. Ensure no regressions were introduced by the shared configuration.",
            "status": "pending",
            "testStrategy": "End-to-end integration test of the document and multiagent workflows in a development environment.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-04T07:49:00.408Z"
      },
      {
        "id": "270",
        "title": "Relocate and Centralize Global Process Handlers",
        "description": "Remove process-level error handlers from individual modules to prevent redundant or conflicting handlers.",
        "details": "Remove 'process.on('unhandledRejection')' and 'process.on('uncaughtException')' from 'ocrQueue.ts'. Verify they are correctly implemented in the main entry point (e.g., 'quikadmin/src/index.ts'). If missing, add them there with centralized logging logic.",
        "testStrategy": "Trigger an uncaught exception in a development script and verify it is caught by the central handler rather than the local queue module.",
        "priority": "low",
        "dependencies": ["265"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Remove redundant process handlers in ocrQueue.ts",
            "description": "Identify and remove 'process.on('unhandledRejection')' and 'process.on('uncaughtException')' blocks from the OCR queue module.",
            "dependencies": [],
            "details": "Locate 'quikadmin/src/queues/ocrQueue.ts' and delete the local event listeners for process errors. This ensures that the module does not try to handle global errors independently of the main application lifecycle.",
            "status": "pending",
            "testStrategy": "Examine 'ocrQueue.ts' to ensure no 'process.on' calls remain for these specific events.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement centralized process handlers in index.ts",
            "description": "Ensure 'quikadmin/src/index.ts' has global error handlers for unhandled rejections and uncaught exceptions with centralized logging.",
            "dependencies": [1],
            "details": "Add or update 'process.on' listeners in the main entry point. Implement logic that logs the error stack trace using the application's logging utility. Ensure that for 'uncaughtException', the process is terminated with an exit code of 1 after logging.",
            "status": "pending",
            "testStrategy": "Check logs for consistent formatting when errors occur and verify that the application entry point is the sole source of these logs.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Validate global error handler execution",
            "description": "Trigger artificial process-level errors to verify that the centralized handler in the entry point correctly captures and logs them.",
            "dependencies": [2],
            "details": "Use a temporary development script or a hidden route to throw a 'new Error()' outside a try-catch block and to reject a promise without a '.catch()'. Verify in the console/log files that the central handler in 'index.ts' caught the event.",
            "status": "pending",
            "testStrategy": "Trigger an uncaught exception in a development script and verify it is caught by the central handler rather than any local queue module.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-04T07:51:13.864Z"
      },
      {
        "id": "271",
        "title": "Enhance Shutdown Signals and Graceful Exit",
        "description": "Improve development experience and resource cleanup by handling SIGINT (Ctrl+C) and adding timeouts to queue closure.",
        "details": "In the queue cleanup logic, add a handler for 'SIGINT' using 'process.once'. When shutting down, call 'queue.close()' with a timeout (e.g., 10 seconds). Log a warning if the queue fails to close within the timeout period.",
        "testStrategy": "Run the application and press Ctrl+C. Verify in the logs that the queue begins a graceful shutdown and completes (or times out) as expected.",
        "priority": "low",
        "dependencies": ["270"],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement SIGINT signal handler for graceful shutdown",
            "description": "Add a process.once listener for the SIGINT signal to trigger the graceful shutdown sequence.",
            "dependencies": [],
            "details": "Locate the main entry point or the background worker initialization file. Use process.once('SIGINT', handler) to ensure the signal is caught and initiates the cleanup logic instead of immediate termination.",
            "status": "pending",
            "testStrategy": "Manually send a SIGINT signal (Ctrl+C) to the running process and verify that the shutdown handler is triggered.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Update queue closure with timeout and error handling",
            "description": "Implement a timeout for the queue.close() operation and handle potential timeout errors.",
            "dependencies": [1],
            "details": "Within the shutdown handler, call queue.close(). Use a Promise-based timeout (e.g., 10 seconds) that races against the close operation. Ensure the process exits properly after closure or timeout.",
            "status": "pending",
            "testStrategy": "Simulate a slow queue closure and verify that the application waits for the specified timeout before forcing an exit or logging a warning.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add logging for shutdown status and timeout warnings",
            "description": "Implement descriptive logging to track the progress of the shutdown and warn if the timeout is exceeded.",
            "dependencies": [2],
            "details": "Log 'Initiating graceful shutdown...' when SIGINT is received. If the queue closure exceeds the 10-second timeout, log a warning: 'Queue failed to close within timeout period. Forcing exit.' otherwise log 'Shutdown complete.'",
            "status": "pending",
            "testStrategy": "Check the console output during process termination to confirm all lifecycle logs and potential warnings are appearing as expected.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-04T07:54:05.405Z"
      },
      {
        "id": "272",
        "title": "Enforce Required Security Environment Variables",
        "description": "Remove hardcoded JWT secret fallbacks and implement mandatory environment variable validation at startup.",
        "details": "Update 'quikadmin/src/utils/supabase.ts' to remove the fallback string for JWT_SECRET. Modify 'quikadmin/src/config/index.ts' to include a validateSecurityConfig function that checks for JWT_SECRET and JWT_REFRESH_SECRET. Ensure JWT_SECRET has a minimum length of 64 characters. If any are missing or weak, throw a fatal error to prevent the server from starting in an insecure state.",
        "testStrategy": "Unit test for the validation function. Manual test attempting to start the server without environment variables defined, expecting a crash with a clear error message.",
        "priority": "high",
        "dependencies": [],
        "status": "in-progress",
        "subtasks": [
          {
            "id": 1,
            "title": "Remove hardcoded JWT secret fallback in supabase.ts",
            "description": "Locate and remove the default string value used when JWT_SECRET environment variable is missing in the Supabase utility file.",
            "dependencies": [],
            "details": "Analyze 'quikadmin/src/utils/supabase.ts'. Identify where the JWT secret is initialized. Remove any logical fallback like '|| \"default_secret\"' to ensure the code relies solely on the environment variable.",
            "status": "pending",
            "testStrategy": "Manual inspection of the code to ensure no fallback strings exist. Verify that the build fails or linter flags undefined variables if types aren't handled.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement validateSecurityConfig function in config/index.ts",
            "description": "Create a function to check for the presence of mandatory security environment variables during the configuration initialization phase.",
            "dependencies": [1],
            "details": "In 'quikadmin/src/config/index.ts', implement 'validateSecurityConfig'. It should check for 'JWT_SECRET' and 'JWT_REFRESH_SECRET' in process.env. If any are undefined or empty, throw a Fatal Error with a message explaining that security variables are missing.",
            "status": "pending",
            "testStrategy": "Unit test the function by mocking process.env to simulate missing keys and verifying that an Error is thrown.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add complexity validation for JWT_SECRET",
            "description": "Enhance the validation logic to enforce a minimum length of 64 characters for the JWT_SECRET to ensure cryptographic strength.",
            "dependencies": [2],
            "details": "Update the 'validateSecurityConfig' function in 'quikadmin/src/config/index.ts' to include a check: 'if (process.env.JWT_SECRET.length < 64)'. Throw a descriptive error if the secret is too weak, preventing insecure server startup.",
            "status": "pending",
            "testStrategy": "Unit test where process.env.JWT_SECRET is set to a short string (e.g., 32 chars) and verify the validation function throws an error.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate validation into application entry point",
            "description": "Ensure the validateSecurityConfig function is executed immediately upon application start before any services are initialized.",
            "dependencies": [3],
            "details": "Import and call 'validateSecurityConfig' at the top level of the main entry file (likely where the server starts or the config is first loaded). Ensure it runs before any DB connections or middleware setups are performed.",
            "status": "pending",
            "testStrategy": "Manual test: Attempt to start the server with an invalid or missing .env file. Confirm the process exits immediately with the expected error message in the console.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Update environment documentation and templates",
            "description": "Update any .env.example files or documentation to reflect the new mandatory requirements and minimum length for secrets.",
            "dependencies": [3],
            "details": "Locate '.env.example' or 'README.md' sections regarding environment setup. Update the descriptions for JWT_SECRET and JWT_REFRESH_SECRET to mark them as 'REQUIRED' and note the 64-character minimum length.",
            "status": "pending",
            "testStrategy": "Manual verification of the .env.example file and relevant documentation for clarity and accuracy.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-04T10:55:08.370Z"
      },
      {
        "id": "273",
        "title": "Implement Content Security Policy (CSP) Middleware",
        "description": "Create and apply CSP headers for development and production environments to prevent XSS and data exfiltration.",
        "details": "Create 'quikadmin/src/middleware/csp.ts'. Define devCSP (allowing 'unsafe-inline' and 'unsafe-eval' for Vite HMR) and prodCSP (strict, no unsafe scripts). Use cryptographic nonces for production scripts. Apply the middleware to the main Express app. Include 'frame-ancestors: none' and 'form-action: self' in the policy.",
        "testStrategy": "Inspect HTTP response headers in browser dev tools for 'Content-Security-Policy'. Verify that inline scripts without a nonce are blocked in a simulated production build.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create CSP Utility and Nonce Generator",
            "description": "Initialize the CSP middleware file and implement a utility to generate cryptographic nonces for script tags.",
            "dependencies": [],
            "details": "Create the file 'quikadmin/src/middleware/csp.ts'. Implement a helper function using 'crypto.randomBytes(16).toString(\"base64\")' to generate a unique nonce for every request to be stored in 'res.locals.nonce'.",
            "status": "pending",
            "testStrategy": "Verify that the nonce generator returns a unique, random 24-character base64 string on each call via a unit test.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Define CSP Policy Configurations",
            "description": "Define the policy directives for development and production environments in the middleware.",
            "dependencies": [1],
            "details": "In 'csp.ts', define 'devCSP' allowing 'unsafe-inline' and 'unsafe-eval' for Vite compatibility. Define 'prodCSP' with strict settings: 'default-src: self', 'frame-ancestors: none', 'form-action: self', and a placeholder for the script nonce.",
            "status": "pending",
            "testStrategy": "Confirm both configuration objects contain the mandatory 'frame-ancestors' and 'form-action' directives as per requirements.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement CSP Express Middleware Function",
            "description": "Create the middleware function that selects and applies the correct CSP header based on NODE_ENV.",
            "dependencies": [2],
            "details": "Implement an Express middleware that checks 'process.env.NODE_ENV'. For production, it must inject the generated nonce into the 'script-src' directive of 'prodCSP' before setting the 'Content-Security-Policy' header.",
            "status": "pending",
            "testStrategy": "Unit test the middleware function by mocking 'req', 'res', and 'next' to ensure 'res.setHeader' is called with the expected policy string for both 'development' and 'production' environments.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Register CSP Middleware in main Express Application",
            "description": "Import and register the CSP middleware in the main application entry point to protect all routes.",
            "dependencies": [3],
            "details": "Locate the Express app initialization (likely in 'quikadmin/src/server.ts' or 'quikadmin/src/app.ts') and add 'app.use(cspMiddleware)' before any route definitions or static file serving.",
            "status": "pending",
            "testStrategy": "Start the server and perform a curl request to verify that the 'Content-Security-Policy' header is present in the response.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Validate CSP Enforcement and Vite HMR Compatibility",
            "description": "Perform end-to-end verification of the CSP headers in development and simulated production modes.",
            "dependencies": [4],
            "details": "In development, ensure Vite's Hot Module Replacement (HMR) still functions. In production, verify that inline scripts without a matching nonce are blocked by the browser and logged as CSP violations in the console.",
            "status": "pending",
            "testStrategy": "Manual inspection of the 'Network' tab in browser dev tools for 'Content-Security-Policy' headers and verifying zero console errors related to CSP in development mode.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": "274",
        "title": "Develop CSP Violation Reporting Endpoint",
        "description": "Create an API endpoint to receive and log CSP violation reports from client browsers.",
        "details": "Add a POST route at '/api/csp-report'. Implement rate limiting (100 reports/min) to prevent DoS via reporting. The handler should log the violation JSON body to the security event log for later analysis. Ensure the endpoint does not require authentication to allow initial violations from blocked users to be reported.",
        "testStrategy": "Manually trigger a CSP violation by injecting a script and verify the browser sends a report to /api/csp-report and that it appears in the server logs.",
        "priority": "medium",
        "dependencies": ["273"],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "275",
        "title": "Configure and Apply CORS Middleware",
        "description": "Restrict cross-origin requests to authorized domains only and secure credential handling.",
        "details": "In 'quikadmin/src/index.ts', use the 'cors' package. Implement a dynamic origin check against an environment-based whitelist (CORS_ORIGINS). Set 'credentials: true', define allowed methods (GET, POST, PUT, DELETE, PATCH, OPTIONS), and expose headers like 'X-Request-ID' and 'RateLimit-Remaining'. Ensure 403 status code for unauthorized origins.",
        "testStrategy": "Use Postman or cURL to send requests with various 'Origin' headers. Verify that whitelisted origins get a 200/204 while unknown origins receive a 403 Forbidden.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Install CORS and Type Definitions",
            "description": "Add 'cors' and '@types/cors' to the quikadmin project dependencies.",
            "dependencies": [],
            "details": "Navigate to the 'quikadmin' directory and execute 'npm install cors' followed by 'npm install --save-dev @types/cors' to provide the necessary library and TypeScript definitions for CORS management.",
            "status": "pending",
            "testStrategy": "Check quikadmin/package.json to confirm 'cors' is listed in dependencies and '@types/cors' is in devDependencies.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Configure CORS Origin Whitelist Parsing",
            "description": "Implement logic to parse the CORS_ORIGINS environment variable.",
            "dependencies": [1],
            "details": "In 'quikadmin/src/index.ts' or a dedicated config file, retrieve 'process.env.CORS_ORIGINS'. Split the comma-separated string into an array and ensure it handles whitespace and empty values gracefully.",
            "status": "pending",
            "testStrategy": "Log the resulting array during server startup to verify that 'http://localhost:3000, https://app.example.com' correctly becomes ['http://localhost:3000', 'https://app.example.com'].",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Define CORS Options Object",
            "description": "Set up the configuration object for the CORS middleware including methods and headers.",
            "dependencies": [2],
            "details": "Define a configuration object with 'credentials: true', 'methods' set to ['GET', 'POST', 'PUT', 'DELETE', 'PATCH', 'OPTIONS'], and 'exposedHeaders' containing 'X-Request-ID' and 'RateLimit-Remaining'.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate Dynamic CORS Middleware",
            "description": "Apply the 'cors' middleware to the Express application in 'quikadmin/src/index.ts'.",
            "dependencies": [3],
            "details": "Initialize the CORS middleware using 'app.use(cors(options))'. Implement the 'origin' callback function to check the incoming request origin against the parsed whitelist from subtask 2.",
            "status": "pending",
            "testStrategy": "Use cURL or Postman to send a request with a valid 'Origin' header and verify that 'Access-Control-Allow-Origin' matches the request origin in the response.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement 403 Error Handling for Rejected Origins",
            "description": "Ensure unauthorized origins receive a 403 Forbidden status code.",
            "dependencies": [4],
            "details": "Add or update the global error handling middleware in 'quikadmin/src/index.ts' to catch errors thrown by the CORS middleware. If the error message indicates a CORS rejection, return a 403 status code instead of the default 500.",
            "status": "pending",
            "testStrategy": "Execute 'curl -v -H \"Origin: https://malicious-site.com\" http://localhost:port' and verify that the response status code is exactly 403 Forbidden.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": "276",
        "title": "Create Security Event Logging Service",
        "description": "Build a specialized service to log security-sensitive events with standardized metadata.",
        "details": "Implement 'SecurityEventService' in 'quikadmin/src/services/SecurityEventService.ts'. Define enums for event types (AUTH_FAILED, TOKEN_INVALID, CSRF_BLOCKED, etc.) and severity levels. Log IP, User-Agent, UserId (if available), and event details. Integrate this service with existing audit middleware to capture failed auth attempts and rate limit breaches.",
        "testStrategy": "Trigger specific security failures (e.g., bad login) and verify that the database or log file contains the standardized SecurityEvent entry.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Security Event Enums and Interfaces",
            "description": "Define the core data structures for security event logging in the new service file.",
            "dependencies": [],
            "details": "Create 'quikadmin/src/services/SecurityEventService.ts'. Define 'SecurityEventType' enum (AUTH_FAILED, TOKEN_INVALID, CSRF_BLOCKED, RATE_LIMIT_EXCEEDED, PRIVILEGE_ESCALATION) and 'SecuritySeverity' enum (LOW, MEDIUM, HIGH, CRITICAL). Define 'ISecurityEvent' interface including ip, userAgent, userId, timestamp, and details object.",
            "status": "pending",
            "testStrategy": "Verify that the TypeScript types and enums compile correctly and cover all specified security event scenarios.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement SecurityEventService Core Class",
            "description": "Develop the primary service class to handle asynchronous logging of security events.",
            "dependencies": [1],
            "details": "Implement the 'SecurityEventService' class with a static 'logEvent' method. This method should accept the event type, severity, and request context. It should aggregate the metadata (IP, User-Agent) and write the event to the system log or database. Ensure error handling so logging failures do not crash the main application flow.",
            "status": "pending",
            "testStrategy": "Unit test the logEvent method by mocking the database/logger output and asserting that the metadata is correctly formatted.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate with Authentication Flow",
            "description": "Hook the SecurityEventService into authentication handlers to capture failed login attempts.",
            "dependencies": [2],
            "details": "Locate the login and token validation logic (likely in 'quikadmin/src/controllers/auth.ts'). Add calls to 'SecurityEventService.logEvent' inside the catch blocks or failure conditions for incorrect passwords, expired tokens, and invalid signatures, passing the relevant userId and IP address.",
            "status": "pending",
            "testStrategy": "Perform a manual test by attempting to log in with incorrect credentials and verify a 'AUTH_FAILED' entry appears in the logs with the correct metadata.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate with Security Middleware",
            "description": "Update existing middleware to log CSRF and Rate Limit violations via the SecurityEventService.",
            "dependencies": [2],
            "details": "Identify the CSRF protection and Rate Limiting middleware. In the rejection handlers of these middlewares, call 'SecurityEventService.logEvent' with 'CSRF_BLOCKED' or 'RATE_LIMIT_EXCEEDED' types. Ensure the severity is set appropriately (e.g., HIGH for CSRF, MEDIUM for Rate Limits).",
            "status": "pending",
            "testStrategy": "Simulate a CSRF attack or trigger a rate limit breach and check that the SecurityEventService captures the event with the attacker's IP and User-Agent.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Verify Metadata Persistence and Severity Filtering",
            "description": "Finalize the service with robust metadata capture and optional severity-based filtering.",
            "dependencies": [3, 4],
            "details": "Refine the 'logEvent' logic to automatically extract IP and User-Agent from the request object if provided. Implement an optional environment variable check (e.g., MIN_LOG_LEVEL) to filter out low-severity events in production environments if needed.",
            "status": "pending",
            "testStrategy": "Verify through integration tests that events with severity below the MIN_LOG_LEVEL are ignored, while CRITICAL events are always recorded and formatted as valid JSON.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": "277",
        "title": "Migrate Access Token to In-Memory Storage",
        "description": "Refactor frontend storage to keep access tokens in JavaScript memory instead of localStorage to mitigate XSS risks.",
        "details": "Modify 'quikadmin-web/src/stores/backendAuthStore.ts' to exclude 'tokens.accessToken' from the partialize persistence configuration. Create 'quikadmin-web/src/lib/tokenManager.ts' as a singleton to store the token variable. Update the Axios interceptor in 'quikadmin-web/src/services/api.ts' to pull the token from this manager.",
        "testStrategy": "Log in to the application, then check browser 'LocalStorage'. Verify the access token is not present. Refresh the page and confirm the token is gone from memory (necessitating the next task).",
        "priority": "high",
        "dependencies": ["275"],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create In-Memory Token Manager Utility",
            "description": "Implement a singleton to store and manage the access token in JavaScript memory.",
            "dependencies": [],
            "details": "Create 'quikadmin-web/src/lib/tokenManager.ts'. This module should expose getter and setter methods for a private 'accessToken' variable. It must be accessible across the frontend application without being persisted to any browser storage.",
            "status": "pending",
            "testStrategy": "Unit test the getter and setter to ensure the value is correctly stored in memory and returned, and that it does not persist across global scope resets in a test environment.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Exclude Access Token from Store Persistence",
            "description": "Modify the Zustand store configuration to prevent the access token from being saved to localStorage.",
            "dependencies": [1],
            "details": "Edit 'quikadmin-web/src/stores/backendAuthStore.ts'. Update the 'partialize' option within the 'persist' middleware configuration to explicitly exclude 'tokens.accessToken' or the entire 'tokens' object if necessary, ensuring only non-sensitive state is persisted.",
            "status": "pending",
            "testStrategy": "Trigger a state change in the store and inspect the 'localStorage' in browser DevTools to confirm that 'accessToken' is no longer present in the persisted JSON object.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate Token Manager with Auth Store Actions",
            "description": "Update login and logout actions in the backendAuthStore to sync with the in-memory manager.",
            "dependencies": [2],
            "details": "Update the 'setTokens' and 'clearAuth' actions in 'quikadmin-web/src/stores/backendAuthStore.ts'. When tokens are received, call 'tokenManager.setToken()'. On logout or error, call 'tokenManager.setToken(null)' to clear memory.",
            "status": "pending",
            "testStrategy": "Perform a login and verify via console logs that 'tokenManager' receives the token while the Zustand store persistence remains clean.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Update Axios Interceptor for In-Memory Retrieval",
            "description": "Refactor the API service to pull the Authorization header from the tokenManager instead of the store.",
            "dependencies": [3],
            "details": "Modify 'quikadmin-web/src/services/api.ts'. Locate the request interceptor and replace the logic that reads the token from 'backendAuthStore' (or localStorage) with a call to 'tokenManager.getToken()'.",
            "status": "pending",
            "testStrategy": "Monitor the Network tab in browser DevTools for outgoing API requests. Verify that the 'Authorization: Bearer <token>' header is correctly populated for authenticated endpoints.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Verify Security and Volatility Requirements",
            "description": "Final validation to ensure the token is volatile on refresh and hidden from persistent storage.",
            "dependencies": [4],
            "details": "Perform a full end-to-end check. Log in, verify 'localStorage' is empty of access tokens, then refresh the page. The app should lose the access token (confirming it was only in memory), which validates the success of this migration task.",
            "status": "pending",
            "testStrategy": "Manual verification: 1. Login. 2. Check LocalStorage (must be empty of token). 3. Refresh (app should require refresh/re-auth as per Task 278 requirements later).",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": "278",
        "title": "Implement Silent Token Refresh Flow",
        "description": "Enable seamless user sessions by using an httpOnly refresh cookie to restore the in-memory access token on page refresh.",
        "details": "Update the frontend app initialization to check 'isAuthenticated'. If true but 'tokenManager' is empty, call a 'silentRefresh' function. This function must hit the '/api/auth/refresh' endpoint which uses the httpOnly refresh cookie. On success, update the 'tokenManager' with the new access token.",
        "testStrategy": "Log in, refresh the browser page. The user should remain logged in without re-entering credentials. Inspect network tab to see the refresh request succeed.",
        "priority": "high",
        "dependencies": ["277"],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Refresh API Client Method",
            "description": "Create a function in the API service layer to call the backend refresh endpoint.",
            "dependencies": [],
            "details": "Add a POST request to /api/auth/refresh in the authentication service. It is crucial to set the withCredentials flag to true to ensure the browser sends the httpOnly refresh cookie stored in the client.",
            "status": "pending",
            "testStrategy": "Use browser developer tools to verify that the /api/auth/refresh request includes the Cookie header with the refresh token.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Develop Silent Refresh Service Logic",
            "description": "Implement the core silentRefresh function to manage the token update process.",
            "dependencies": [1],
            "details": "Define the silentRefresh function within the Auth provider. This function will call the refresh API and, upon a successful response, update the in-memory state with the new access token.",
            "status": "pending",
            "testStrategy": "Unit test the silentRefresh function by mocking the API response and asserting that the Auth state is updated correctly.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate Refresh Flow into App Initialization",
            "description": "Update the application's root component to trigger token restoration on load.",
            "dependencies": [2],
            "details": "Modify the application's startup logic to detect if a session exists without an active token. If isAuthenticated is set in persistent storage but the tokenManager is empty, initiate the silentRefresh flow.",
            "status": "pending",
            "testStrategy": "Manually refresh the browser page while logged in and verify that the silentRefresh call is triggered automatically before the main UI renders.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Update Token Manager for In-Memory Persistence",
            "description": "Ensure the tokenManager correctly stores and provides the refreshed access token.",
            "dependencies": [2],
            "details": "Configure the tokenManager to accept the new access token and ensure that the HTTP client (e.g., Axios) is updated with the new Authorization header for all subsequent backend requests.",
            "status": "pending",
            "testStrategy": "Verify that subsequent API calls after a silent refresh include the new access token in the Authorization header.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Handle Refresh Failures and Session Cleanup",
            "description": "Add logic to handle cases where the refresh token is invalid or expired.",
            "dependencies": [3],
            "details": "Implement a catch block for the silentRefresh call. If the refresh fails due to an expired or invalid cookie, the system must clear the isAuthenticated flag and redirect the user to the login screen.",
            "status": "pending",
            "testStrategy": "Mock a 401 error for the refresh endpoint and verify that the user is redirected to the login page and local storage is cleared.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": "279",
        "title": "Implement Refresh Token Rotation and Theft Detection",
        "description": "Enhance backend security by rotating refresh tokens on every use and invalidating sessions if a reused token is detected.",
        "details": "Modify the refresh endpoint to implement 'token families'. When a refresh token is used, issue a new one and mark the old one as used in Redis with a TTL. If a 'used' token is presented, invalidate the entire family (all tokens for that session). Include family UUID and generation counter in the JWT payload.",
        "testStrategy": "Perform a refresh, then attempt to use the previous refresh token again. Verify that the second request fails and subsequent requests with the 'new' token also fail due to family invalidation.",
        "priority": "high",
        "dependencies": ["276"],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Update JWT Payload Schema for Token Families",
            "description": "Modify the JWT signing utility to include family UUID (fid) and generation counter (gen) in refresh tokens.",
            "dependencies": [],
            "details": "Update the authentication service or utility to add 'fid' and 'gen' fields to the refresh token payload. Ensure 'gen' starts at 1 for new sessions and 'fid' is a unique UUID generated during initial login.",
            "status": "pending",
            "testStrategy": "Unit test the token generation function to assert that 'fid' is a valid UUID and 'gen' is an integer in the decoded payload.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Redis Storage for Token Status Tracking",
            "description": "Create Redis keys and service methods to track used refresh tokens and revoked token families.",
            "dependencies": [1],
            "details": "Implement methods to store used refresh tokens with a TTL matching the token's remaining life. Create a 'revoked_families' set or key-value store in Redis to flag compromised family IDs.",
            "status": "pending",
            "testStrategy": "Verify Redis keys are correctly set and retrieved with expected TTL using a Redis client or mock.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Refactor Refresh Endpoint for Token Rotation",
            "description": "Update the refresh controller to issue a new refresh token with an incremented generation counter upon every use.",
            "dependencies": [2],
            "details": "Modify the refresh logic to extract the current 'fid' and 'gen', verify the token, and issue a new refresh token with 'gen + 1'. The old token must be added to the used tokens list in Redis immediately.",
            "status": "pending",
            "testStrategy": "Submit a valid refresh token and verify that the response contains a new refresh token with an incremented 'gen' value.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement Theft Detection and Family Revocation Logic",
            "description": "Add logic to detect reused refresh tokens and invalidate the entire session family if reuse is detected.",
            "dependencies": [3],
            "details": "In the refresh handler, check if the provided token exists in the 'used' list in Redis. If it does, mark its 'fid' as revoked in Redis. Before processing any refresh, check if the 'fid' is already in the revoked list.",
            "status": "pending",
            "testStrategy": "Attempt to use a refresh token twice. Verify that the first request succeeds and the second request results in a 401/403 and invalidates all future refreshes for that fid.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Integrate Family Revocation Check in Authentication Guard",
            "description": "Ensure the authentication middleware or guard checks the family status for all refresh requests.",
            "dependencies": [4],
            "details": "Update the JWT validation guard to query Redis for the 'fid' revocation status. If the family is revoked, reject the request even if the JWT signature and expiration are valid.",
            "status": "pending",
            "testStrategy": "Perform an end-to-end test where a family is revoked manually in Redis, then attempt a refresh with a 'valid' (non-used) token from that family to confirm it is rejected.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": "280",
        "title": "Enforce HSTS and Secure Cookies Across Environments",
        "description": "Configure HTTP Strict Transport Security (HSTS) headers and ensure cookies are marked as 'Secure' even in development.",
        "details": "In 'quikadmin/src/middleware/security.ts', set 'Strict-Transport-Security' header with environment-specific max-age (1 year for prod, 1 hour for dev). Ensure cookie 'secure' flag is true unless in 'test' environment. Update Vite and backend configs to support local HTTPS (e.g., using mkcert).",
        "testStrategy": "Verify the HSTS header presence in browser dev tools for dev/staging/prod environments. Verify 'Secure' flag on cookies in the 'Application' tab of dev tools.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Environment-Aware HSTS Headers",
            "description": "Update the security middleware to apply the Strict-Transport-Security header based on the current environment.",
            "dependencies": [],
            "details": "In 'quikadmin/src/middleware/security.ts', implement logic to set the 'Strict-Transport-Security' header. Use a max-age of 31536000 (1 year) for 'production' and 3600 (1 hour) for 'development'. Ensure includeSubDomains and preload options are included for production security compliance.",
            "status": "pending",
            "testStrategy": "Use curl or browser dev tools to inspect response headers in local and staging environments, verifying the max-age value changes according to NODE_ENV.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Enforce Secure Cookie Flag across Environments",
            "description": "Configure the application to ensure all cookies are marked as 'Secure' regardless of the environment, except during automated testing.",
            "dependencies": [1],
            "details": "Update the session configuration and any manual res.cookie calls in 'quikadmin/src/middleware/security.ts' or relevant auth files. Set the 'secure' attribute to true. Add a conditional check to set it to false only if NODE_ENV is strictly 'test'.",
            "status": "pending",
            "testStrategy": "Inspect the 'Application' tab in browser dev tools while running locally over HTTPS to ensure the 'Secure' column is checked for all application cookies.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Configure Vite for Local HTTPS Development",
            "description": "Update the Vite configuration to serve the frontend via HTTPS to support secure cookie testing.",
            "dependencies": [],
            "details": "Modify 'quikadmin/vite.config.ts' to enable the 'https' server option. Configure it to point to 'localhost.pem' and 'localhost-key.pem' files. Add instructions to the README regarding the generation of these certificates using mkcert for local developers.",
            "status": "pending",
            "testStrategy": "Run 'npm run dev' and verify the application is accessible via https://localhost and that the browser recognizes the certificate if mkcert is installed.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Enable HTTPS for Local Backend Development",
            "description": "Modify the backend server initialization to support SSL/TLS connections during development.",
            "dependencies": [3],
            "details": "Update the backend entry point (e.g., 'quikadmin/src/app.ts') to use the Node.js 'https' module instead of 'http' when in development. Load the mkcert certificates. Ensure internal API calls and redirect URIs in environment files are updated to use 'https://' protocols.",
            "status": "pending",
            "testStrategy": "Verify that the backend API responds correctly to HTTPS requests from the Vite frontend and that session cookies are successfully persisted over the secure connection.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": "281",
        "title": "Build Global Input Validation Middleware",
        "description": "Standardize request validation using Joi to prevent injection and malformed data entry.",
        "details": "Create 'quikadmin/src/middleware/validation.ts' with a 'validateBody' factory. Create 'quikadmin/src/schemas/common.ts' containing reusable schemas for emails, UUIDs, and pagination. Apply these to all POST/PUT routes. Ensure 'stripUnknown: true' is set to prevent mass-assignment vulnerabilities.",
        "testStrategy": "Send a request to a validated endpoint with extra fields and invalid data types. Verify that unknown fields are removed and invalid data returns 400 Bad Request with details.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Reusable Validation Schemas",
            "description": "Create a centralized file for common Joi validation schemas like email, UUID, and pagination parameters.",
            "dependencies": [],
            "details": "Create the file 'quikadmin/src/schemas/common.ts'. Define and export Joi schemas for email strings, UUID v4 format, and pagination objects including page and limit parameters.",
            "status": "pending",
            "testStrategy": "Verify that schemas correctly validate and invalidate sample inputs via unit tests.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Global Validation Middleware Factory",
            "description": "Develop a generic validation middleware factory that uses Joi to validate request bodies.",
            "dependencies": [1],
            "details": "Create 'quikadmin/src/middleware/validation.ts'. Implement a 'validateBody' function that returns an Express middleware. Configure Joi options with 'stripUnknown: true' and 'abortEarly: false'.",
            "status": "pending",
            "testStrategy": "Unit test the middleware function with a mock schema to ensure it calls next() on success and passes the error on failure.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Apply Validation Middleware to POST and PUT Routes",
            "description": "Integrate the validation middleware into existing routes to enforce data integrity and security.",
            "dependencies": [2],
            "details": "Locate POST and PUT endpoints in the router files. Import the 'validateBody' factory and apply it with specific schemas to the route definitions to sanitize incoming data.",
            "status": "pending",
            "testStrategy": "Perform integration tests on a validated endpoint by sending malformed JSON and ensuring the server rejects it.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Standardize Validation Error Responses",
            "description": "Ensure that Joi validation errors are caught and returned to the client in a consistent JSON format.",
            "dependencies": [2, 3],
            "details": "Update the central error handler or the validation middleware to catch Joi errors specifically, format the error messages into a readable array, and return a 400 Bad Request status code.",
            "status": "pending",
            "testStrategy": "Send invalid requests to the API and verify that the response body contains a clear 'errors' array and a 400 HTTP status.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": "282",
        "title": "Create CSP Violation Aggregation and Monitoring",
        "description": "Store and aggregate CSP reports in the database to identify and alert on potential XSS attacks.",
        "details": "Create a database schema for 'csp_reports'. Update the reporting endpoint to save incoming reports. Implement a simple aggregation logic to count violations by 'blocked-uri' and 'document-uri'. Set up a basic alert if violations for a specific URI exceed a threshold within a time window.",
        "testStrategy": "Simulate multiple CSP violations and check the database for aggregated records. Verify that an internal alert or log entry is generated when the spike threshold is met.",
        "priority": "medium",
        "dependencies": ["274"],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "283",
        "title": "Implement Dual-Key JWT Verification",
        "description": "Allow for zero-downtime secret rotation by supporting both current and previous JWT secrets during verification.",
        "details": "Update the JWT verification logic in the auth middleware. Attempt verification with 'JWT_SECRET'. If it fails with a signature error and 'JWT_SECRET_OLD' exists in environment variables, attempt verification with 'JWT_SECRET_OLD'. This enables seamless transition during secret rotation.",
        "testStrategy": "Sign a token with an 'old' secret, update the server with a 'new' primary secret but keep the 'old' as secondary. Verify the token is still accepted. Then remove the secondary secret and verify the token is rejected.",
        "priority": "medium",
        "dependencies": ["272"],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Update environment configuration for legacy secret support",
            "description": "Expose JWT_SECRET_OLD in the application configuration and ensure it is available to the auth middleware.",
            "dependencies": [],
            "details": "Update the central configuration file (likely in quikadmin/src/config/index.ts or equivalent) to read JWT_SECRET_OLD from process.env. If a validation schema like Joi or Zod is used, update it to allow JWT_SECRET_OLD as an optional string.",
            "status": "pending",
            "testStrategy": "Verify that config.JWT_SECRET_OLD correctly reflects the environment variable when set and defaults to null/undefined when absent.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Refactor JWT verification to support fallback logic",
            "description": "Modify the authentication middleware to attempt verification with the primary secret and fallback to the old secret on failure.",
            "dependencies": [1],
            "details": "In the auth middleware (e.g., quikadmin/src/middleware/auth.middleware.ts), wrap the jwt.verify call in a try/catch block. If verification fails with a 'JsonWebTokenError' related to the signature, and JWT_SECRET_OLD is configured, attempt a second verification using the old secret.",
            "status": "pending",
            "testStrategy": "Manually test with a token generated using a secondary secret while both secrets are configured.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Develop unit tests for dual-key verification scenarios",
            "description": "Create a comprehensive test suite in Jest to validate various rotation scenarios.",
            "dependencies": [2],
            "details": "Create or update quikadmin/src/middleware/__tests__/auth.test.ts. Implement tests for: 1. Token valid with current secret. 2. Token valid with old secret. 3. Token invalid with both. 4. Token valid with old secret but JWT_SECRET_OLD is not set (should fail).",
            "status": "pending",
            "testStrategy": "Run 'npm test' specifically for the auth middleware and ensure 100% coverage of the fallback branches.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement rotation flow integration test",
            "description": "Simulate a live secret rotation to ensure zero-downtime behavior.",
            "dependencies": [3],
            "details": "Write an integration test that performs the following sequence: Sign a token with SecretA; Update app config so JWT_SECRET=SecretB and JWT_SECRET_OLD=SecretA; Verify the token is still accepted; Update config to remove JWT_SECRET_OLD; Verify the token is now rejected.",
            "status": "pending",
            "testStrategy": "Verify the response status codes (200 vs 401) during each phase of the simulated rotation.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": "284",
        "title": "Expand Rate Limiting and Standardize Headers",
        "description": "Apply rate limits to sensitive endpoints (password reset, downloads) and expose standardized limit headers.",
        "details": "Identify missing rate limits on password reset (5/hr) and file downloads (50/hr). Integrate headers into the response (RateLimit-Limit, RateLimit-Remaining, RateLimit-Reset). Implement adaptive logic: if 'SecurityEventService' detects suspicious activity for an IP, temporarily lower its rate limits.",
        "testStrategy": "Flood the password reset endpoint and verify a 429 status code after 5 attempts. Check headers on a normal request to ensure the limit and remaining counts are visible and accurate.",
        "priority": "medium",
        "dependencies": ["276"],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Standardized Rate Limit Headers",
            "description": "Configure the rate-limiting middleware to expose standardized headers in response objects.",
            "dependencies": [],
            "details": "Update the rate limiter configuration to include headers: 'RateLimit-Limit', 'RateLimit-Remaining', and 'RateLimit-Reset'. If using express-rate-limit, enable 'standardHeaders: true' and customize the 'legacyHeaders' property to false. Ensure these headers are consistently applied across all throttled endpoints.",
            "status": "pending",
            "testStrategy": "Verify response headers using a tool like curl or Postman to ensure all three standardized headers are present on a successful request to a rate-limited route.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Apply Rate Limits to Sensitive Endpoints",
            "description": "Configure and attach specific rate limiting middleware to password reset and file download routes.",
            "dependencies": [1],
            "details": "Locate auth and file controller routes. Define two new rate limit instances: one for password reset (windowMs: 1 hour, max: 5) and one for file downloads (windowMs: 1 hour, max: 50). Apply these middleware instances to 'POST /api/auth/reset-password' and 'GET /api/files/download/:id'.",
            "status": "pending",
            "testStrategy": "Execute 6 requests to the password reset endpoint within one minute and verify the 6th request receives a 429 Too Many Requests status code. Repeat with 51 requests for the download endpoint.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate SecurityEventService for Adaptive Throttling",
            "description": "Implement dynamic limit adjustment based on suspicious activity detected by SecurityEventService.",
            "dependencies": [],
            "details": "Modify the rate limiter's 'max' property to be a function that queries 'SecurityEventService.hasRecentSuspiciousActivity(ip)'. If suspicious activity is detected for the requesting IP, reduce the allowed limit by 50% or set it to a strict minimum (e.g., 1 request per hour).",
            "status": "pending",
            "testStrategy": "Manually inject a suspicious event into the database/service for a specific IP. Verify that the 'RateLimit-Limit' header reflects the reduced value for that IP immediately.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Verification and Integration Testing",
            "description": "Develop comprehensive integration tests to ensure limits, headers, and adaptive logic function together.",
            "dependencies": [3],
            "details": "Write integration tests in the test suite using supertest. Test cases should include: 1. Normal limit enforcement, 2. Header presence/accuracy, 3. Adaptive limit reduction after triggering a security event, 4. Reset window functionality to ensure limits refresh correctly after one hour.",
            "status": "pending",
            "testStrategy": "Run 'npm test' or the specific integration test file to verify all assertions regarding status codes (429), header values, and adaptive logic transitions pass.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": "285",
        "title": "Develop Security Audit Dashboard Backend",
        "description": "Expose security event metrics and reports for administrative review and compliance.",
        "details": "Create endpoints for the admin panel to retrieve security metrics: failed auth counts over time, recent CSP violations, and blocked IPs. Implement an export feature to generate CSV/JSON reports of security events filtered by date range and type, aligned with SOC 2 requirements.",
        "testStrategy": "Query the metrics endpoint and verify the JSON data matches the events triggered in earlier tasks. Perform an export and verify the file content contains the expected security event fields.",
        "priority": "low",
        "dependencies": ["276", "282"],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "286",
        "title": "Security Documentation and Rotation Procedures",
        "description": "Formalize the security operations manual including secrets rotation and incident response logging.",
        "details": "Create a 'SECURITY.md' or similar document detailing the exact steps to rotate JWT secrets using the dual-key mechanism. Document the HSTS setup and local development requirements (HTTPS). List all security events logged and their meanings for compliance audits (GDPR/SOC 2).",
        "testStrategy": "Manual review of documentation by a non-primary developer to ensure the rotation steps are clear and executable without prior context.",
        "priority": "low",
        "dependencies": ["283"],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-01-04T10:55:08.372Z",
      "taskCount": 100,
      "completedCount": 57,
      "tags": ["master"]
    }
  }
}
